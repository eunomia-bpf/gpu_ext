# NVIDIA UVM é¢„å–æœºåˆ¶è¯¦è§£ä¸ç­–ç•¥æ›¿æ¢æŒ‡å—

## ç›®å½•
1. [Prefetch æœºåˆ¶è¯¦è§£](#1-prefetch-æœºåˆ¶è¯¦è§£)
2. [Eviction Policy æ›¿æ¢æ–¹æ¡ˆ](#2-eviction-policy-æ›¿æ¢æ–¹æ¡ˆ)
3. [å®ç° FIFO ç¤ºä¾‹](#3-å®ç°-fifo-ç¤ºä¾‹)
4. [æœ€å°ä¾µå…¥ä¿®æ”¹ç‚¹](#4-æœ€å°ä¾µå…¥ä¿®æ”¹ç‚¹)

---

## 1. Prefetch æœºåˆ¶è¯¦è§£

### 1.1 æ ¸å¿ƒæ•°æ®ç»“æ„

#### Bitmap Tree (uvm_perf_prefetch.h:41-50)

```c
typedef struct {
    uvm_page_mask_t pages;       // æ¯ä¸ª bit è¡¨ç¤ºä¸€ä¸ª page æ˜¯å¦å­˜åœ¨
    uvm_page_index_t offset;     // åç§»é‡ï¼ˆç”¨äºå¯¹é½ big pageï¼‰
    NvU16 leaf_count;            // å¶å­èŠ‚ç‚¹æ•°é‡ï¼ˆé¡µæ•°ï¼‰
    NvU8 level_count;            // æ ‘çš„å±‚æ•°
} uvm_perf_prefetch_bitmap_tree_t;
```

**æ ‘ç»“æ„**:
- **æ»¡äºŒå‰æ ‘**: å±‚æ•° = `log2(roundup_pow_of_two(leaf_count)) + 1`
- **å¶å­èŠ‚ç‚¹**: æ¯ä¸ªå¶å­å¯¹åº”ä¸€ä¸ª 4KB é¡µé¢
- **å†…éƒ¨èŠ‚ç‚¹**: æ¯ä¸ªèŠ‚ç‚¹ç»´æŠ¤å­æ ‘çš„"é¡µé¢å­˜åœ¨è®¡æ•°"

#### Prefetch Hint (uvm_perf_prefetch.h:31-36)

```c
typedef struct {
    uvm_page_mask_t prefetch_pages_mask;  // å»ºè®®é¢„å–çš„é¡µé¢æ©ç 
    uvm_processor_id_t residency;         // é¢„å–ç›®æ ‡å¤„ç†å™¨
} uvm_perf_prefetch_hint_t;
```

### 1.2 ç®—æ³•æµç¨‹

#### å®Œæ•´è°ƒç”¨é“¾

```
uvm_va_block_get_prefetch_hint()                    [uvm_va_block.c:11828]
  â””â”€> uvm_perf_prefetch_get_hint_va_block()         [uvm_perf_prefetch.c:447]
      â”œâ”€> uvm_perf_prefetch_prenotify_fault_migrations() [line 327]
      â”‚   â”œâ”€> init_bitmap_tree_from_region()        [line 222] â† åˆå§‹åŒ–æ ‘
      â”‚   â”‚   â””â”€> level_count = ilog2(roundup_pow_of_two(leaf_count)) + 1
      â”‚   â”œâ”€> update_bitmap_tree_from_va_block()    [line 240] â† æ›´æ–°æ ‘
      â”‚   â”‚   â””â”€> grow_fault_granularity()          [line 164]
      â”‚   â”‚       â””â”€> grow_fault_granularity_if_no_thrashing() [line 148]
      â”‚   â””â”€> compute_prefetch_mask()               [line 299]
      â”‚       â””â”€> compute_prefetch_region()         [line 102] â† æ ¸å¿ƒç®—æ³•
      â”‚           â””â”€> traverse tree with 51% threshold
      â””â”€> check min_faults threshold                [line 477]
```

#### æ ¸å¿ƒç®—æ³•: compute_prefetch_region() (Line 102-146)

**è¾“å…¥**:
- `page_index`: å‘ç”Ÿ fault çš„é¡µé¢ç´¢å¼•
- `bitmap_tree`: å½“å‰ VA block çš„ bitmap tree
- `max_prefetch_region`: å…è®¸é¢„å–çš„æœ€å¤§åŒºåŸŸ

**ç®—æ³•æ­¥éª¤**:

```c
static uvm_va_block_region_t compute_prefetch_region(
    uvm_page_index_t page_index,
    uvm_perf_prefetch_bitmap_tree_t *bitmap_tree,
    uvm_va_block_region_t max_prefetch_region)
{
    NvU16 counter;
    uvm_perf_prefetch_bitmap_tree_iter_t iter;
    uvm_va_block_region_t prefetch_region = uvm_va_block_region(0, 0);

    // ä»å¶å­èŠ‚ç‚¹å‘ä¸Šéå†
    uvm_perf_prefetch_bitmap_tree_traverse_counters(
        counter, bitmap_tree,
        page_index - max_prefetch_region.first + bitmap_tree->offset,
        &iter)
    {
        uvm_va_block_region_t subregion =
            uvm_perf_prefetch_bitmap_tree_iter_get_range(bitmap_tree, &iter);
        NvU16 subregion_pages = uvm_va_block_region_num_pages(subregion);

        // ğŸ”‘ å…³é”®: é˜ˆå€¼åˆ¤æ–­ (é»˜è®¤ 51%)
        // counter = å­åŒºåŸŸä¸­å·²å­˜åœ¨çš„é¡µæ•°
        // å¦‚æœ occupancy > thresholdï¼Œé€‰æ‹©è¿™ä¸ªå­åŒºåŸŸ
        if (counter * 100 > subregion_pages * g_uvm_perf_prefetch_threshold)
            prefetch_region = subregion;
    }

    // è£å‰ªåˆ°å®é™…å¯ç”¨èŒƒå›´
    return clamp(prefetch_region, max_prefetch_region);
}
```

**é€»è¾‘è§£é‡Š**:
1. **è‡ªåº•å‘ä¸Šéå†**: ä» fault page å¯¹åº”çš„å¶å­èŠ‚ç‚¹å¼€å§‹ï¼Œå‘ä¸Šéå†åˆ°æ ¹èŠ‚ç‚¹
2. **è®¡ç®— occupancy**: æ¯å±‚è®¡ç®— `counter` (å·²å­˜åœ¨é¡µæ•°) / `subregion_pages` (æ€»é¡µæ•°)
3. **é˜ˆå€¼åˆ¤æ–­**: å¦‚æœ occupancy > 51%ï¼Œè®°å½•è¿™ä¸ªå­åŒºåŸŸ
4. **é€‰æ‹©æœ€å¤§å­åŒºåŸŸ**: å› ä¸ºä»ä¸‹å¾€ä¸Šéå†ï¼Œæœ€åè®°å½•çš„æ˜¯**æ»¡è¶³é˜ˆå€¼çš„æœ€å¤§å­åŒºåŸŸ**

**ç¤ºä¾‹**:
```
å‡è®¾ 2MB block (512 pages), å‘ç”Ÿ fault çš„é¡µåœ¨ index 128
                Root [256 pages exist / 512 total] â†’ 50% âœ—
                /                              \
           L1 [200/256] â†’ 78% âœ“          L1 [56/256] â†’ 21% âœ—
          /           \
   L2 [150/128] âœ“  L2 [50/128] âœ—

å‘ä¸Šéå†ç»“æœ:
- å¶å­å±‚ (L3): 1/1 = 100% âœ“ â†’ prefetch_region = [128, 129)
- L2å·¦å­æ ‘: 150/128 > 51% âœ“ â†’ prefetch_region = [0, 128)
- L1å·¦å­æ ‘: 200/256 > 51% âœ“ â†’ prefetch_region = [0, 256)
- Root: 256/512 = 50% âœ— â†’ ä¸æ›´æ–°

æœ€ç»ˆé¢„å–: [0, 256) å³å·¦åŠä¸ª 2MB block
```

### 1.3 Thrashing æ£€æµ‹é›†æˆ

#### ä¸ Prefetch çš„äº¤äº’ç‚¹

**Point 1**: æ’é™¤ thrashing é¡µé¢ (Line 377-381)
```c
// ä¸è®¡ç®— thrashing é¡µé¢çš„é¢„å–åŒºåŸŸ
if (thrashing_pages)
    uvm_page_mask_andnot(&scratch_page_mask, faulted_pages, thrashing_pages);
else
    uvm_page_mask_copy(&scratch_page_mask, faulted_pages);

compute_prefetch_mask(faulted_region, max_prefetch_region,
                      bitmap_tree, &scratch_page_mask, prefetch_pages);
```

**Point 2**: å»é™¤å·²æ ‡è®°çš„ thrashing é¡µé¢ (Line 406-408)
```c
// é¿å…é¢„å–æ­£åœ¨ thrashing çš„é¡µé¢
if (thrashing_pages)
    uvm_page_mask_andnot(prefetch_pages, prefetch_pages, thrashing_pages);
```

**Point 3**: å¢å¤§é thrashing åŒºåŸŸçš„é¢„å–ç²’åº¦ (Line 148-162)
```c
static void grow_fault_granularity_if_no_thrashing(
    uvm_perf_prefetch_bitmap_tree_t *bitmap_tree,
    uvm_va_block_region_t region,
    uvm_page_index_t first,
    const uvm_page_mask_t *faulted_pages,
    const uvm_page_mask_t *thrashing_pages)
{
    // å¦‚æœè¿™ä¸ªåŒºåŸŸæœ‰ fault ä¸”æ²¡æœ‰ thrashing
    if (!uvm_page_mask_region_empty(faulted_pages, region) &&
        (!thrashing_pages || uvm_page_mask_region_empty(thrashing_pages, region))) {
        // æ ‡è®°æ•´ä¸ªåŒºåŸŸçš„é¡µé¢ä¸ºå­˜åœ¨ï¼Œå¢åŠ  occupancy
        uvm_page_mask_region_fill(&bitmap_tree->pages, region);
    }
}
```

### 1.4 ç‰¹æ®Šä¼˜åŒ–

#### First-touch å…¨å¡«å…… (Line 361-366)

```c
// å¦‚æœæ˜¯é¦–æ¬¡è®¿é—®ä¸”ç›®æ ‡æ˜¯ preferred locationï¼Œç›´æ¥å¡«å……æ•´ä¸ªåŒºåŸŸ
if (uvm_processor_mask_empty(&va_block->resident) &&
    uvm_id_equal(new_residency, policy->preferred_location)) {
    uvm_page_mask_region_fill(prefetch_pages, max_prefetch_region);
}
```

**åœºæ™¯**: åº”ç”¨é¦–æ¬¡è®¿é—®ä¸€ä¸ª managed memory åŒºåŸŸï¼Œä¸”è®¿é—®çš„æ˜¯ preferred location (å¦‚ GPU)
**ç­–ç•¥**: ç›´æ¥é¢„å–æ•´ä¸ª VA block (æœ€å¤š 2MB)ï¼Œé¿å…åç»­å¤§é‡ page faults

#### Big Page å¯¹é½ (Line 271-285)

```c
// è°ƒæ•´ bitmap tree ä»¥é€‚åº” big page è¾¹ç•Œ
if (big_pages_region.first - max_prefetch_region.first > 0) {
    bitmap_tree->offset = big_page_size / PAGE_SIZE -
                          (big_pages_region.first - max_prefetch_region.first);
    bitmap_tree->leaf_count = uvm_va_block_region_num_pages(max_prefetch_region) +
                              bitmap_tree->offset;

    // å·¦ç§» page mask ä»¥å¯¹é½
    uvm_page_mask_shift_left(&bitmap_tree->pages, &bitmap_tree->pages, bitmap_tree->offset);

    bitmap_tree->level_count = ilog2(roundup_pow_of_two(bitmap_tree->leaf_count)) + 1;
}
```

**ç›®çš„**: ç¡®ä¿é¢„å–åŒºåŸŸå¯¹é½åˆ° big page (64KB/2MB) è¾¹ç•Œï¼Œæé«˜ TLB æ•ˆç‡

---

## 2. Eviction Policy æ›¿æ¢æ–¹æ¡ˆ

### 2.1 å½“å‰ LRU å®ç°åˆ†æ

#### æ•°æ®ç»“æ„ (uvm_pmm_gpu.h:355)

```c
struct {
    struct list_head va_block_used;    // LRU åˆ—è¡¨: å¤´éƒ¨=æœ€ä¹…æœªç”¨ï¼Œå°¾éƒ¨=æœ€è¿‘ä½¿ç”¨
    struct list_head va_block_unused;  // æœªä½¿ç”¨çš„ chunk åˆ—è¡¨
    struct list_head va_block_lazy_free; // å»¶è¿Ÿé‡Šæ”¾åˆ—è¡¨
} root_chunks;
```

#### å…³é”®å‡½æ•°

| å‡½æ•° | ä½ç½® | åŠŸèƒ½ |
|------|------|------|
| `pick_root_chunk_to_evict()` | uvm_pmm_gpu.c:1460 | é€‰æ‹©è¦é©±é€çš„ chunk |
| `chunk_update_lists_locked()` | uvm_pmm_gpu.c:627 | æ›´æ–° LRU ä½ç½® |
| `uvm_pmm_gpu_unpin_allocated()` | uvm_pmm_gpu.c:677 | åˆ†é…åè°ƒç”¨ï¼Œè§¦å‘ LRU æ›´æ–° |

### 2.2 ç­–ç•¥æ›¿æ¢çš„ä¸‰ä¸ªå±‚æ¬¡

#### Level 1: ä»…ä¿®æ”¹é€‰æ‹©é€»è¾‘ (æœ€å°ä¾µå…¥)

**ä¿®æ”¹ç‚¹**: `pick_root_chunk_to_evict()` å‡½æ•°
**ä½ç½®**: `kernel-open/nvidia-uvm/uvm_pmm_gpu.c:1460-1500`

**åŸæœ‰é€»è¾‘**:
```c
static uvm_gpu_root_chunk_t *pick_root_chunk_to_evict(uvm_pmm_gpu_t *pmm)
{
    uvm_gpu_chunk_t *chunk;
    uvm_spin_lock(&pmm->list_lock);

    // ä¼˜å…ˆçº§1: Free list
    chunk = list_first_chunk(find_free_list(pmm, ...));

    // ä¼˜å…ˆçº§2: Unused list
    if (!chunk)
        chunk = list_first_chunk(&pmm->root_chunks.va_block_unused);

    // ä¼˜å…ˆçº§3: LRU (ä»å¤´éƒ¨å–æœ€ä¹…æœªç”¨)
    if (!chunk)
        chunk = list_first_chunk(&pmm->root_chunks.va_block_used);

    if (chunk)
        chunk_start_eviction(pmm, chunk);

    uvm_spin_unlock(&pmm->list_lock);
    return chunk ? root_chunk_from_chunk(pmm, chunk) : NULL;
}
```

**FIFO ä¿®æ”¹** (åªæ”¹ç¬¬3ä¼˜å…ˆçº§):
```c
// ä¼˜å…ˆçº§3: FIFO (ä»å¤´éƒ¨å–æœ€æ—©åˆ†é…)
// LRU: list_first_chunk() å–å¤´éƒ¨ = æœ€ä¹…æœªè®¿é—®
// FIFO: list_first_chunk() å–å¤´éƒ¨ = æœ€æ—©åˆ†é…
// â†’ æ•°æ®ç»“æ„ä¸å˜ï¼Œåªéœ€ä¿®æ”¹æ›´æ–°ç­–ç•¥ï¼
if (!chunk)
    chunk = list_first_chunk(&pmm->root_chunks.va_block_used);
```

**å…³é”®**: LRU å’Œ FIFO åœ¨å½“å‰å®ç°ä¸‹**é€‰æ‹©é€»è¾‘å®Œå…¨ç›¸åŒ**ï¼ŒåŒºåˆ«åœ¨äº**ä½•æ—¶æ›´æ–°é“¾è¡¨ä½ç½®**

#### Level 2: ä¿®æ”¹æ›´æ–°ç­–ç•¥ (ä¸­ç­‰ä¾µå…¥)

**ä¿®æ”¹ç‚¹**: `chunk_update_lists_locked()` å‡½æ•°
**ä½ç½®**: `kernel-open/nvidia-uvm/uvm_pmm_gpu.c:627-651`

**LRU æ›´æ–°ç­–ç•¥** (å½“å‰å®ç°):
```c
static void chunk_update_lists_locked(uvm_pmm_gpu_t *pmm, uvm_gpu_chunk_t *chunk)
{
    uvm_gpu_root_chunk_t *root_chunk = root_chunk_from_chunk(pmm, chunk);

    if (uvm_gpu_chunk_is_user(chunk)) {
        if (!chunk_is_root_chunk_pinned(pmm, chunk) &&
            root_chunk->chunk.state != UVM_PMM_GPU_CHUNK_STATE_FREE) {
            // æ¯æ¬¡åˆ†é…åç§»åˆ°å°¾éƒ¨ (Most Recently Used)
            list_move_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
        }
    }
}
```

**FIFO æ›´æ–°ç­–ç•¥** (ä¿®æ”¹):
```c
static void chunk_update_lists_locked(uvm_pmm_gpu_t *pmm, uvm_gpu_chunk_t *chunk)
{
    uvm_gpu_root_chunk_t *root_chunk = root_chunk_from_chunk(pmm, chunk);

    if (uvm_gpu_chunk_is_user(chunk)) {
        if (!chunk_is_root_chunk_pinned(pmm, chunk) &&
            root_chunk->chunk.state != UVM_PMM_GPU_CHUNK_STATE_FREE) {
            // FIFO: ä¸ç§»åŠ¨ä½ç½®ï¼ä¿æŒåˆ†é…é¡ºåº
            // åªåœ¨é¦–æ¬¡åˆ†é…æ—¶åŠ åˆ°é“¾è¡¨å°¾éƒ¨
            if (list_empty(&root_chunk->chunk.list)) {
                list_add_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
            }
            // å¦åˆ™ä¸æ›´æ–°ä½ç½®
        }
    }
}
```

#### Level 3: æ·»åŠ æ–°çš„æ•°æ®ç»“æ„ (é«˜ä¾µå…¥)

**åœºæ™¯**: å®ç°éœ€è¦é¢å¤–å…ƒæ•°æ®çš„ç­–ç•¥ï¼ˆå¦‚ LFU, Clock, LIRS ç­‰ï¼‰

**æ–¹æ³•**:
1. åœ¨ `uvm_gpu_root_chunk_t` ä¸­æ·»åŠ å­—æ®µ (uvm_pmm_gpu.h)
2. åœ¨ `uvm_pmm_gpu_t` ä¸­æ·»åŠ è¾…åŠ©æ•°æ®ç»“æ„
3. ä¿®æ”¹ `pick_root_chunk_to_evict()` ä½¿ç”¨æ–°æ•°æ®ç»“æ„

**ç¤ºä¾‹: Clock ç®—æ³•**

åœ¨ `uvm_pmm_gpu.h` æ·»åŠ :
```c
struct uvm_gpu_root_chunk_struct {
    uvm_gpu_chunk_t chunk;
    uvm_tracker_t tracker;

    // æ–°å¢: Clock ç®—æ³•çš„ reference bit
    bool referenced;
};

struct uvm_pmm_gpu_struct {
    // ...
    struct {
        struct list_head va_block_used;
        // æ–°å¢: Clock æŒ‡é’ˆ
        struct list_head *clock_hand;
    } root_chunks;
};
```

åœ¨ `uvm_pmm_gpu.c` å®ç°:
```c
static uvm_gpu_root_chunk_t *pick_root_chunk_to_evict_clock(uvm_pmm_gpu_t *pmm)
{
    uvm_gpu_chunk_t *chunk;
    struct list_head *pos = pmm->root_chunks.clock_hand;

    if (!pos)
        pos = pmm->root_chunks.va_block_used.next;

    // Clock æ‰«æ
    while (true) {
        if (pos == &pmm->root_chunks.va_block_used) {
            pos = pos->next;  // è·³è¿‡é“¾è¡¨å¤´
            continue;
        }

        chunk = list_entry(pos, uvm_gpu_chunk_t, list);
        uvm_gpu_root_chunk_t *root = root_chunk_from_chunk(pmm, chunk);

        if (root->referenced) {
            root->referenced = false;  // æ¸…é™¤ reference bit
            pos = pos->next;
        } else {
            pmm->root_chunks.clock_hand = pos->next;
            chunk_start_eviction(pmm, chunk);
            return root;
        }
    }
}
```

---

## 3. å®ç° FIFO ç¤ºä¾‹

### 3.1 æœ€å°ä¿®æ”¹æ–¹æ¡ˆ (æ¨è)

**æ–‡ä»¶**: `kernel-open/nvidia-uvm/uvm_pmm_gpu.c`

#### æ­¥éª¤1: æ·»åŠ æ¡ä»¶ç¼–è¯‘å¼€å…³

```c
// åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
#define UVM_EVICTION_POLICY_FIFO 1  // 0=LRU, 1=FIFO

#if UVM_EVICTION_POLICY_FIFO
#define UVM_EVICTION_POLICY_NAME "FIFO"
#else
#define UVM_EVICTION_POLICY_NAME "LRU"
#endif
```

#### æ­¥éª¤2: ä¿®æ”¹ chunk_update_lists_locked()

åœ¨ **Line 627** é™„è¿‘:

```c
static void chunk_update_lists_locked(uvm_pmm_gpu_t *pmm, uvm_gpu_chunk_t *chunk)
{
    uvm_gpu_root_chunk_t *root_chunk = root_chunk_from_chunk(pmm, chunk);

    uvm_assert_spinlock_locked(&pmm->list_lock);

    if (uvm_gpu_chunk_is_user(chunk)) {
        if (chunk_is_root_chunk_pinned(pmm, chunk)) {
            UVM_ASSERT(root_chunk->chunk.state == UVM_PMM_GPU_CHUNK_STATE_IS_SPLIT ||
                       root_chunk->chunk.state == UVM_PMM_GPU_CHUNK_STATE_TEMP_PINNED);
            list_del_init(&root_chunk->chunk.list);
        }
        else if (root_chunk->chunk.state != UVM_PMM_GPU_CHUNK_STATE_FREE) {
            UVM_ASSERT(root_chunk->chunk.state == UVM_PMM_GPU_CHUNK_STATE_IS_SPLIT ||
                       root_chunk->chunk.state == UVM_PMM_GPU_CHUNK_STATE_ALLOCATED);

#if UVM_EVICTION_POLICY_FIFO
            // FIFO: åªåœ¨é¦–æ¬¡åŠ å…¥æ—¶æ·»åŠ åˆ°é“¾è¡¨ï¼Œä¹‹åä¸ç§»åŠ¨
            if (list_empty(&root_chunk->chunk.list)) {
                list_add_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
            }
            // å¦åˆ™ä¿æŒåŸä½ç½®ä¸å˜
#else
            // LRU: æ¯æ¬¡è®¿é—®éƒ½ç§»åˆ°å°¾éƒ¨
            list_move_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
#endif
        }
    }

    // TODO: Bug 1757148: Improve fragmentation of split chunks
    if (chunk->state == UVM_PMM_GPU_CHUNK_STATE_FREE)
        list_move_tail(&chunk->list, find_free_list_chunk(pmm, chunk));
    else if (chunk->state == UVM_PMM_GPU_CHUNK_STATE_TEMP_PINNED)
        list_del_init(&chunk->list);
}
```

#### æ­¥éª¤3: æ·»åŠ æ—¥å¿— (å¯é€‰)

åœ¨ PMM åˆå§‹åŒ–å‡½æ•°ä¸­æ·»åŠ :

```c
// åœ¨ uvm_pmm_gpu_init() å‡½æ•°ä¸­ (Line ~3400)
NV_STATUS uvm_pmm_gpu_init(uvm_pmm_gpu_t *pmm, uvm_gpu_t *gpu)
{
    // ... åŸæœ‰ä»£ç  ...

    UVM_INFO_PRINT("PMM GPU initialized with %s eviction policy\n",
                   UVM_EVICTION_POLICY_NAME);

    return NV_OK;
}
```

### 3.2 éªŒè¯å’Œæµ‹è¯•

#### ç¼–è¯‘

```bash
cd /home/yunwei37/open-gpu-kernel-modules
make modules
```

#### åŠ è½½æ¨¡å—

```bash
sudo rmmod nvidia_uvm
sudo insmod kernel-open/nvidia-uvm/nvidia-uvm.ko
dmesg | tail -20  # æŸ¥çœ‹æ˜¯å¦æœ‰ "FIFO eviction policy" æ—¥å¿—
```

#### æµ‹è¯•ç¨‹åº

```c
// test_eviction.cu
#include <cuda_runtime.h>
#include <stdio.h>

int main() {
    size_t size = 8ULL * 1024 * 1024 * 1024;  // 8GB (è¶…è¿‡ GPU å†…å­˜)
    char *data;

    cudaMallocManaged(&data, size);

    // é¡ºåºè®¿é—®ï¼Œè§‚å¯Ÿé©±é€é¡ºåº
    for (size_t i = 0; i < size; i += 4096) {
        data[i] = i % 256;
    }

    cudaDeviceSynchronize();
    cudaFree(data);
    return 0;
}
```

ä½¿ç”¨ `nvidia-smi` æˆ– UVM events ç›‘æ§é©±é€è¡Œä¸º:
- **FIFO**: é©±é€é¡ºåºä¸åˆ†é…é¡ºåºä¸€è‡´
- **LRU**: é©±é€é¡ºåºä¸è®¿é—®é¡ºåºç›¸å…³

---

## 4. æœ€å°ä¾µå…¥ä¿®æ”¹ç‚¹æ€»ç»“

### 4.1 Prefetch Policy Hook Points

| Hook Point | æ–‡ä»¶ | è¡Œå· | åŠŸèƒ½ | ä¾µå…¥æ€§ |
|-----------|------|------|------|-------|
| **compute_prefetch_region()** | uvm_perf_prefetch.c | 102 | é¢„å–åŒºåŸŸè®¡ç®—æ ¸å¿ƒ | ğŸŸ¢ ä½ |
| **g_uvm_perf_prefetch_threshold** | uvm_perf_prefetch.c | 64 | é˜ˆå€¼å‚æ•° | ğŸŸ¢ ä½ |
| **uvm_perf_prefetch_get_hint_va_block()** | uvm_perf_prefetch.c | 447 | é¡¶å±‚é¢„å–æ¥å£ | ğŸŸ¡ ä¸­ |
| **init_bitmap_tree_from_region()** | uvm_perf_prefetch.c | 222 | æ ‘åˆå§‹åŒ– | ğŸŸ¡ ä¸­ |

### 4.2 Eviction Policy Hook Points

| Hook Point | æ–‡ä»¶ | è¡Œå· | åŠŸèƒ½ | ä¾µå…¥æ€§ |
|-----------|------|------|------|-------|
| **pick_root_chunk_to_evict()** | uvm_pmm_gpu.c | 1460 | é€‰æ‹©é©±é€ç›®æ ‡ | ğŸŸ¢ ä½ |
| **chunk_update_lists_locked()** | uvm_pmm_gpu.c | 627 | æ›´æ–° LRU/FIFO åˆ—è¡¨ | ğŸŸ¢ ä½ |
| **uvm_pmm_gpu_unpin_allocated()** | uvm_pmm_gpu.c | 677 | åˆ†é…åå›è°ƒ | ğŸŸ¡ ä¸­ |
| **root_chunks æ•°æ®ç»“æ„** | uvm_pmm_gpu.h | 355 | æ·»åŠ æ–°å…ƒæ•°æ® | ğŸ”´ é«˜ |

### 4.3 æ¨èä¿®æ”¹æ–¹æ¡ˆ

#### åœºæ™¯1: æ›¿æ¢é¢„å–ç®—æ³• (å¦‚æ”¹ç”¨å›ºå®šçª—å£é¢„å–)

**ä¿®æ”¹ç‚¹**: `compute_prefetch_region()` (uvm_perf_prefetch.c:102)

```c
static uvm_va_block_region_t compute_prefetch_region_fixed_window(
    uvm_page_index_t page_index,
    uvm_perf_prefetch_bitmap_tree_t *bitmap_tree,
    uvm_va_block_region_t max_prefetch_region)
{
    // ç®€å•çš„å›ºå®šçª—å£: fault page Â± 32 pages
    #define PREFETCH_WINDOW 32

    uvm_page_index_t start = (page_index > PREFETCH_WINDOW) ?
                             (page_index - PREFETCH_WINDOW) : 0;
    uvm_page_index_t end = min(page_index + PREFETCH_WINDOW,
                               max_prefetch_region.outer);

    return uvm_va_block_region(start, end);
}
```

**ä¾µå…¥æ€§**: ğŸŸ¢ ä½ (åªæ”¹ä¸€ä¸ªå‡½æ•°)

#### åœºæ™¯2: å®ç° FIFO é©±é€

**ä¿®æ”¹ç‚¹**: `chunk_update_lists_locked()` (uvm_pmm_gpu.c:642)

```c
// æ³¨é‡Šæ‰:
// list_move_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);

// æ”¹ä¸º:
if (list_empty(&root_chunk->chunk.list)) {
    list_add_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
}
```

**ä¾µå…¥æ€§**: ğŸŸ¢ ä½ (ä¿®æ”¹ 1 è¡Œä»£ç )

#### åœºæ™¯3: å®ç°è®¿é—®é¢‘ç‡é©±é€ (LFU)

**ä¿®æ”¹ç‚¹**:
1. æ·»åŠ å­—æ®µåˆ° `uvm_gpu_root_chunk_t` (uvm_pmm_gpu.h)
2. ä¿®æ”¹ `pick_root_chunk_to_evict()` (uvm_pmm_gpu.c:1460)
3. åœ¨ `chunk_update_lists_locked()` ä¸­æ›´æ–°è®¡æ•°

**ä¾µå…¥æ€§**: ğŸ”´ é«˜ (éœ€è¦ä¿®æ”¹æ•°æ®ç»“æ„å’Œå¤šä¸ªå‡½æ•°)

---

## 5. è°ƒè¯•å’Œæ€§èƒ½åˆ†æ

### 5.1 æ·»åŠ  Tracepoint

åœ¨ `pick_root_chunk_to_evict()` æ·»åŠ :

```c
static uvm_gpu_root_chunk_t *pick_root_chunk_to_evict(uvm_pmm_gpu_t *pmm)
{
    uvm_gpu_chunk_t *chunk;

    uvm_spin_lock(&pmm->list_lock);

    chunk = list_first_chunk(&pmm->root_chunks.va_block_used);

    if (chunk) {
        // æ·»åŠ  trace
        printk(KERN_INFO "UVM: Evicting chunk at PA 0x%llx\n",
               chunk->address);
        chunk_start_eviction(pmm, chunk);
    }

    uvm_spin_unlock(&pmm->list_lock);
    return chunk ? root_chunk_from_chunk(pmm, chunk) : NULL;
}
```

### 5.2 æ€§èƒ½è®¡æ•°å™¨

æ·»åŠ åˆ° `uvm_pmm_gpu_t`:

```c
struct {
    atomic64_t eviction_count;
    atomic64_t prefetch_count;
    atomic64_t hit_count;
} stats;
```

åœ¨å…³é”®è·¯å¾„æ›´æ–°:

```c
// é©±é€æ—¶
atomic64_inc(&pmm->stats.eviction_count);

// é¢„å–æ—¶
atomic64_add(uvm_page_mask_weight(prefetch_pages), &pmm->stats.prefetch_count);

// å‘½ä¸­æ—¶ (é¡µé¢å·²åœ¨ GPU)
atomic64_inc(&pmm->stats.hit_count);
```

é€šè¿‡ `/proc` æˆ– `/sys` å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯ã€‚

---

## 6. å‚è€ƒèµ„æ–™

### ç›¸å…³ä»£ç æ–‡ä»¶

| æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|
| `uvm_perf_prefetch.c/h` | é¢„å–ç­–ç•¥å®ç° |
| `uvm_pmm_gpu.c/h` | GPU ç‰©ç†å†…å­˜ç®¡ç†å’Œé©±é€ |
| `uvm_va_block.c` | VA block ç®¡ç†å’Œè¿ç§» |
| `uvm_perf_thrashing.c` | Thrashing æ£€æµ‹ |
| `uvm_gpu_replayable_faults.c` | Page fault å¤„ç† |

### å…³é”®å®å’Œè¾…åŠ©å‡½æ•°

```c
// éå† bitmap tree
#define uvm_perf_prefetch_bitmap_tree_traverse_counters(counter, tree, page, iter)

// é“¾è¡¨æ“ä½œ
list_first_entry()     // è·å–ç¬¬ä¸€ä¸ªå…ƒç´ 
list_add_tail()        // æ·»åŠ åˆ°å°¾éƒ¨
list_move_tail()       // ç§»åŠ¨åˆ°å°¾éƒ¨
list_del_init()        // åˆ é™¤å¹¶åˆå§‹åŒ–

// Page mask æ“ä½œ
uvm_page_mask_region_fill()    // å¡«å……åŒºåŸŸ
uvm_page_mask_andnot()         // ä¸éæ“ä½œ
uvm_page_mask_weight()         // è®¡ç®— set bits æ•°é‡
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-16
**é€‚ç”¨ä»£ç **: kernel-open/nvidia-uvm (branch: uvm-print-test)
