# NVIDIA UVM LRU é©±é€ç­–ç•¥å®Œæ•´ä½¿ç”¨æŒ‡å—

## ç›®å½•
1. [LRU æœºåˆ¶æ¦‚è¿°](#1-lru-æœºåˆ¶æ¦‚è¿°)
2. [LRU æ•°æ®ç»“æ„è¯¦è§£](#2-lru-æ•°æ®ç»“æ„è¯¦è§£)
3. [LRU å·¥ä½œæµç¨‹](#3-lru-å·¥ä½œæµç¨‹)
4. [å¦‚ä½•ä½¿ç”¨ BPF æ‰©å±• LRU](#4-å¦‚ä½•ä½¿ç”¨-bpf-æ‰©å±•-lru)
5. [å®ç°è‡ªå®šä¹‰é©±é€ç­–ç•¥](#5-å®ç°è‡ªå®šä¹‰é©±é€ç­–ç•¥)
6. [è°ƒè¯•å’Œæ€§èƒ½åˆ†æ](#6-è°ƒè¯•å’Œæ€§èƒ½åˆ†æ)

---

## 1. LRU æœºåˆ¶æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯ LRU

NVIDIA UVM ä½¿ç”¨ **LRU (Least Recently Used)** ç­–ç•¥æ¥ç®¡ç† GPU å†…å­˜çš„é©±é€:
- å½“ GPU å†…å­˜ä¸è¶³æ—¶ï¼Œé©±é€**æœ€ä¹…æœªä½¿ç”¨**çš„å†…å­˜å—
- ç²’åº¦: **2MB root chunk** (ä¸ CPU å¤§é¡µç›¸åŒ)
- æ•°æ®ç»“æ„: Linux å†…æ ¸åŒå‘é“¾è¡¨ (`list_head`)

### 1.2 ä¸ Prefetch çš„å…³ç³»

| æœºåˆ¶ | ä½œç”¨æ—¶æœº | ç›®çš„ |
|------|---------|------|
| **Prefetch** | Page fault æ—¶ | **ä¸»åŠ¨é¢„å–**å¯èƒ½è®¿é—®çš„é¡µé¢ï¼Œå‡å°‘æœªæ¥ fault |
| **LRU Eviction** | GPU å†…å­˜ä¸è¶³æ—¶ | **è¢«åŠ¨é©±é€**æœ€ä¹…æœªä½¿ç”¨çš„é¡µé¢ï¼Œè…¾å‡ºç©ºé—´ |

**ååŒå·¥ä½œ**:
```
ç”¨æˆ·è®¿é—® GPU å†…å­˜åœ°å€
  â†“
Page Fault
  â†“
â”œâ”€> Prefetch: é¢„æµ‹å¹¶é¢„å–å‘¨å›´é¡µé¢ (uvm_perf_prefetch.c)
â””â”€> åˆ†é… GPU å†…å­˜ (uvm_pmm_gpu.c)
      â†“
    å†…å­˜ä¸è¶³?
      â†“ Yes
    LRU Eviction: é©±é€æœ€ä¹…æœªä½¿ç”¨çš„ 2MB chunk
      â†“
    æ›´æ–° LRU åˆ—è¡¨: æ–°åˆ†é…çš„ chunk ç§»åˆ°é“¾è¡¨å°¾éƒ¨
```

### 1.3 æ ¸å¿ƒè®¾è®¡åŸåˆ™

- âœ… **ç²—ç²’åº¦è¿½è¸ª**: åªè¿½è¸ª 2MB root chunkï¼Œä¸è¿½è¸ªå•ä¸ª 4KB é¡µé¢
- âœ… **åˆ†é…æ—¶æ›´æ–°**: åœ¨ chunk åˆ†é…/unpin æ—¶æ›´æ–° LRU ä½ç½®
- âš ï¸ **ä¸è¿½è¸ªè®¿é—®**: å½“å‰å®ç°ä¸è¿½è¸ªå®é™…çš„ GPU è®¿é—®ï¼ˆè§ TODO Line 1487-1488ï¼‰

---

## 2. LRU æ•°æ®ç»“æ„è¯¦è§£

### 2.1 Root Chunks ç»“æ„

**å®šä¹‰ä½ç½®**: `kernel-open/nvidia-uvm/uvm_pmm_gpu.h:350-362`

```c
struct {
    // Root chunks æ•°ç»„ (æ‰€æœ‰ 2MB chunks)
    uvm_gpu_root_chunk_t *array;
    size_t count;

    // LRU åˆ—è¡¨: æœªè¢« VA block ä½¿ç”¨çš„ chunks
    struct list_head va_block_unused;

    // LRU åˆ—è¡¨: è¢« VA block ä½¿ç”¨çš„ chunks (ä¸»è¦é©±é€æ¥æº)
    struct list_head va_block_used;

    // å»¶è¿Ÿé‡Šæ”¾åˆ—è¡¨
    struct list_head va_block_lazy_free;
    nv_kthread_q_item_t va_block_lazy_free_q_item;
} root_chunks;
```

### 2.2 åˆ—è¡¨æ’åºè§„åˆ™

**`va_block_used` åˆ—è¡¨** (LRU æ ¸å¿ƒ):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HEAD (æœ€ä¹…æœªä½¿ç”¨)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chunk 1: æœ€æ—©åˆ†é…/æœ€ä¹…æœªè®¿é—®                 â”‚
â”‚ Chunk 2: â†“                                   â”‚
â”‚ Chunk 3: â†“                                   â”‚
â”‚ ...                                          â”‚
â”‚ Chunk N: æœ€è¿‘åˆ†é…/æœ€è¿‘è®¿é—®                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TAIL (æœ€è¿‘ä½¿ç”¨)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ›´æ–°æ—¶æœº**:
- **`list_move_tail()`**: åœ¨ chunk åˆ†é…/unpin æ—¶å°†å…¶ç§»åˆ°å°¾éƒ¨
- **`list_del_init()`**: åœ¨ chunk è¢« pin æ—¶ä»åˆ—è¡¨ç§»é™¤

### 2.3 Chunk çŠ¶æ€æœº

```c
// uvm_pmm_gpu.h
typedef enum {
    UVM_PMM_GPU_CHUNK_STATE_PMA_OWNED,    // è¢« PMA æ‹¥æœ‰ï¼ˆæœªåˆ†é…ï¼‰
    UVM_PMM_GPU_CHUNK_STATE_FREE,         // åœ¨ free list ä¸­
    UVM_PMM_GPU_CHUNK_STATE_TEMP_PINNED,  // ä¸´æ—¶ pinï¼ˆåˆ†é…ä¸­ï¼‰
    UVM_PMM_GPU_CHUNK_STATE_IS_SPLIT,     // å·²åˆ†å‰²æˆå­ chunks
    UVM_PMM_GPU_CHUNK_STATE_ALLOCATED,    // å·²åˆ†é…ç»™ VA block
} uvm_pmm_gpu_chunk_state_t;
```

**çŠ¶æ€è½¬æ¢** (ä¸ LRU ç›¸å…³):
```
PMA_OWNED â†’ TEMP_PINNED â†’ ALLOCATED â†’ (unpin) â†’ va_block_used åˆ—è¡¨å°¾éƒ¨
                                   â†“
                                (evict) â†’ FREE â†’ PMA_OWNED
```

---

## 3. LRU å·¥ä½œæµç¨‹

### 3.1 å®Œæ•´è°ƒç”¨é“¾

#### é˜¶æ®µ 1: GPU Page Fault è§¦å‘

```
GPU è®¿é—®æœªæ˜ å°„åœ°å€
  â†“
Hardware Fault Buffer è®°å½• fault
  â†“
uvm_parent_gpu_service_replayable_faults()  [uvm_gpu_replayable_faults.c:2906]
  â”œâ”€> fetch_fault_buffer_entries()          [è¯»å– fault buffer]
  â”œâ”€> preprocess_fault_batch()              [é¢„å¤„ç† faults]
  â””â”€> service_fault_batch()                 [å¤„ç† faults]
      â””â”€> service_fault_batch_dispatch()
          â””â”€> service_fault_batch_block()
              â””â”€> service_fault_batch_block_locked()
                  â””â”€> uvm_va_block_service_locked()  [uvm_va_block.c:12349]
```

#### é˜¶æ®µ 2: å†…å­˜åˆ†é…ä¸é©±é€è§¦å‘

```c
// uvm_va_block.c:2080-2089
static NV_STATUS block_alloc_gpu_chunk(uvm_va_block_t *va_block,
                                       uvm_gpu_t *gpu,
                                       NvU64 size,
                                       uvm_gpu_chunk_t **out_gpu_chunk,
                                       uvm_va_block_retry_t *retry)
{
    // ç¬¬ä¸€æ¬¡å°è¯•: ä¸é©±é€
    status = uvm_pmm_gpu_alloc_user(&gpu->pmm, 1, size,
                                     UVM_PMM_ALLOC_FLAGS_NONE,
                                     &gpu_chunk, &retry->tracker);

    // å¦‚æœå¤±è´¥ (NV_ERR_NO_MEMORY), å¸¦é©±é€æ ‡å¿—é‡è¯•
    if (status != NV_OK) {
        status = uvm_pmm_gpu_alloc_user(&gpu->pmm, 1, size,
                                         UVM_PMM_ALLOC_FLAGS_EVICT,  // â† è§¦å‘ LRU é©±é€
                                         &gpu_chunk, &retry->tracker);
    }

    *out_gpu_chunk = gpu_chunk;
    return status;
}
```

#### é˜¶æ®µ 3: LRU é©±é€é€‰æ‹©

```c
// uvm_pmm_gpu.c:1460-1500
static uvm_gpu_root_chunk_t *pick_root_chunk_to_evict(uvm_pmm_gpu_t *pmm)
{
    uvm_gpu_chunk_t *chunk;

    uvm_spin_lock(&pmm->list_lock);

    // ä¼˜å…ˆçº§ 1: ä» free list ä¸­æ‰¾ (non-zero ä¼˜å…ˆ)
    chunk = list_first_chunk(find_free_list(pmm,
                                            UVM_PMM_GPU_MEMORY_TYPE_USER,
                                            UVM_CHUNK_SIZE_MAX,
                                            UVM_PMM_LIST_NO_ZERO));
    if (!chunk) {
        chunk = list_first_chunk(find_free_list(pmm,
                                                UVM_PMM_GPU_MEMORY_TYPE_USER,
                                                UVM_CHUNK_SIZE_MAX,
                                                UVM_PMM_LIST_ZERO));
    }

    // ä¼˜å…ˆçº§ 2: ä» unused åˆ—è¡¨ä¸­æ‰¾
    if (!chunk)
        chunk = list_first_chunk(&pmm->root_chunks.va_block_unused);

    // ä¼˜å…ˆçº§ 3: ä» used åˆ—è¡¨å¤´éƒ¨æ‰¾ (LRU - æœ€ä¹…æœªä½¿ç”¨)
    // TODO: Bug 1765193: æœªæ¥å¯èƒ½åœ¨é¡µé¢è¢«æ˜ å°„æ—¶ä¹Ÿæ›´æ–° LRU
    if (!chunk)
        chunk = list_first_chunk(&pmm->root_chunks.va_block_used);  // â† LRU é€‰æ‹©

    if (chunk)
        chunk_start_eviction(pmm, chunk);  // æ ‡è®°ä¸ºæ­£åœ¨é©±é€

    uvm_spin_unlock(&pmm->list_lock);

    if (chunk)
        return root_chunk_from_chunk(pmm, chunk);
    return NULL;
}
```

**å…³é”®ç‚¹**:
- âœ… `list_first_chunk()` ä»é“¾è¡¨**å¤´éƒ¨**å– chunk (æœ€ä¹…æœªä½¿ç”¨)
- âœ… ä¸‰çº§ä¼˜å…ˆçº§ç¡®ä¿ä¼˜å…ˆä½¿ç”¨ç©ºé—²å†…å­˜
- âš ï¸ TODO æ³¨é‡Šè¡¨æ˜æœªæ¥å¯èƒ½æ”¹è¿› (åœ¨ map æ—¶ä¹Ÿæ›´æ–° LRU)

#### é˜¶æ®µ 4: LRU åˆ—è¡¨æ›´æ–°

```c
// uvm_pmm_gpu.c:627-651
static void chunk_update_lists_locked(uvm_pmm_gpu_t *pmm, uvm_gpu_chunk_t *chunk)
{
    uvm_gpu_root_chunk_t *root_chunk = root_chunk_from_chunk(pmm, chunk);

    uvm_assert_spinlock_locked(&pmm->list_lock);

    if (uvm_gpu_chunk_is_user(chunk)) {
        if (chunk_is_root_chunk_pinned(pmm, chunk)) {
            // å¦‚æœè¢« pinï¼Œä»åˆ—è¡¨ç§»é™¤
            UVM_ASSERT(root_chunk->chunk.state == UVM_PMM_GPU_CHUNK_STATE_IS_SPLIT ||
                       root_chunk->chunk.state == UVM_PMM_GPU_CHUNK_STATE_TEMP_PINNED);
            list_del_init(&root_chunk->chunk.list);
        }
        else if (root_chunk->chunk.state != UVM_PMM_GPU_CHUNK_STATE_FREE) {
            // å…³é”®: ç§»åˆ° used åˆ—è¡¨å°¾éƒ¨ (æœ€è¿‘ä½¿ç”¨)
            UVM_ASSERT(root_chunk->chunk.state == UVM_PMM_GPU_CHUNK_STATE_IS_SPLIT ||
                       root_chunk->chunk.state == UVM_PMM_GPU_CHUNK_STATE_ALLOCATED);
            list_move_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
        }
    }

    // å¤„ç† free chunks
    if (chunk->state == UVM_PMM_GPU_CHUNK_STATE_FREE)
        list_move_tail(&chunk->list, find_free_list_chunk(pmm, chunk));
    else if (chunk->state == UVM_PMM_GPU_CHUNK_STATE_TEMP_PINNED)
        list_del_init(&chunk->list);
}
```

**è°ƒç”¨æ—¶æœº**:
```c
// uvm_pmm_gpu.c:653-675
static void gpu_unpin_temp(uvm_pmm_gpu_t *pmm,
                           uvm_gpu_chunk_t *chunk,
                           uvm_va_block_t *va_block,
                           bool is_referenced)
{
    UVM_ASSERT(chunk->state == UVM_PMM_GPU_CHUNK_STATE_TEMP_PINNED);

    uvm_spin_lock(&pmm->list_lock);

    chunk_unpin(pmm, chunk, UVM_PMM_GPU_CHUNK_STATE_ALLOCATED);
    chunk->is_referenced = is_referenced;
    chunk->va_block = va_block;
    chunk_update_lists_locked(pmm, chunk);  // â† æ›´æ–° LRU ä½ç½®

    uvm_spin_unlock(&pmm->list_lock);
}

// uvm_va_block.c:839
uvm_pmm_gpu_unpin_allocated(&gpu->pmm, gpu_chunk, va_block);  // â† åˆ†é…åè°ƒç”¨
```

### 3.2 å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. GPU Page Fault                                               â”‚
â”‚    uvm_parent_gpu_service_replayable_faults()                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. åˆ†é… GPU å†…å­˜                                                 â”‚
â”‚    uvm_pmm_gpu_alloc_user(..., UVM_PMM_ALLOC_FLAGS_NONE)       â”‚
â”‚    â†“ å¤±è´¥ (NV_ERR_NO_MEMORY)                                    â”‚
â”‚    uvm_pmm_gpu_alloc_user(..., UVM_PMM_ALLOC_FLAGS_EVICT) â†â”€â”€â”€â”â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
                   â†“                                          â”‚  â”‚â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚â”‚
â”‚ 3. LRU é©±é€é€‰æ‹©                                          â”‚  â”‚  â”‚â”‚
â”‚    pick_root_chunk_to_evict()                           â”‚  â”‚  â”‚â”‚
â”‚    â”œâ”€> ä¼˜å…ˆçº§ 1: Free list                              â”‚  â”‚  â”‚â”‚
â”‚    â”œâ”€> ä¼˜å…ˆçº§ 2: va_block_unused                        â”‚  â”‚  â”‚â”‚
â”‚    â””â”€> ä¼˜å…ˆçº§ 3: va_block_used HEAD (LRU)  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”˜  â”‚â”‚
â”‚                                                          â”‚     â”‚â”‚
â”‚    evict_root_chunk()                                   â”‚     â”‚â”‚
â”‚    â””â”€> è¿ç§»é¡µé¢åˆ° CPU/System Memory                     â”‚     â”‚â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚â”‚
                   â†“                                            â”‚â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚ 4. åˆ†é…æˆåŠŸï¼Œæ›´æ–° LRU                                        â”‚ â”‚â”‚
â”‚    uvm_pmm_gpu_unpin_allocated()                            â”‚ â”‚â”‚
â”‚    â””â”€> chunk_update_lists_locked()                          â”‚ â”‚â”‚
â”‚        â””â”€> list_move_tail(..., va_block_used)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”˜â”‚
â”‚                                                              â”‚  â”‚
â”‚    ç»“æœ: æ–° chunk åœ¨é“¾è¡¨å°¾éƒ¨ (æœ€è¿‘ä½¿ç”¨)                      â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                                                   â”‚
    ä¸‹æ¬¡é©±é€æ—¶ï¼Œè¿™ä¸ª chunk æœ€ä¸å®¹æ˜“è¢«é€‰ä¸­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. å¦‚ä½•ä½¿ç”¨ BPF æ‰©å±• LRU

### 4.1 å½“å‰é™åˆ¶

**é—®é¢˜**: å½“å‰ UVM ä»£ç ä¸­ LRU **æ²¡æœ‰ BPF hook ç‚¹**
- Prefetch æœ‰ BPF struct_ops (`uvm_prefetch_before_compute`, `uvm_prefetch_on_tree_iter`)
- LRU é©±é€ç­–ç•¥**ç¡¬ç¼–ç **åœ¨å†…æ ¸ä¸­

### 4.2 æ½œåœ¨çš„ BPF æ‰©å±•ç‚¹

å¦‚æœè¦æ·»åŠ  BPF æ”¯æŒï¼Œå¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®æ’å…¥ hook:

#### Hook ç‚¹ 1: é©±é€é€‰æ‹© (`pick_root_chunk_to_evict`)

```c
// uvm_pmm_gpu.c:1460
static uvm_gpu_root_chunk_t *pick_root_chunk_to_evict(uvm_pmm_gpu_t *pmm)
{
    uvm_gpu_chunk_t *chunk;
    enum uvm_bpf_action action;

    // ğŸ”¥ æ–°å¢ BPF hook: before_pick_evict_chunk
    action = uvm_bpf_call_before_pick_evict_chunk(pmm, &chunk);

    if (action == UVM_BPF_ACTION_BYPASS) {
        // BPF ç›´æ¥é€‰æ‹©äº† chunk
        return root_chunk_from_chunk(pmm, chunk);
    }

    // åŸæœ‰ LRU é€»è¾‘
    uvm_spin_lock(&pmm->list_lock);
    chunk = list_first_chunk(&pmm->root_chunks.va_block_used);
    ...
}
```

#### Hook ç‚¹ 2: LRU æ›´æ–° (`chunk_update_lists_locked`)

```c
// uvm_pmm_gpu.c:627
static void chunk_update_lists_locked(uvm_pmm_gpu_t *pmm, uvm_gpu_chunk_t *chunk)
{
    uvm_gpu_root_chunk_t *root_chunk = root_chunk_from_chunk(pmm, chunk);
    enum uvm_bpf_action action;

    // ğŸ”¥ æ–°å¢ BPF hook: on_chunk_update
    action = uvm_bpf_call_on_chunk_update(pmm, chunk);

    if (action == UVM_BPF_ACTION_BYPASS) {
        // BPF æ¥ç®¡åˆ—è¡¨æ›´æ–°é€»è¾‘
        return;
    }

    // åŸæœ‰ LRU é€»è¾‘ (list_move_tail)
    if (uvm_gpu_chunk_is_user(chunk)) {
        if (!chunk_is_root_chunk_pinned(pmm, chunk) &&
            root_chunk->chunk.state != UVM_PMM_GPU_CHUNK_STATE_FREE) {
            list_move_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
        }
    }
}
```

### 4.3 BPF Struct Ops è®¾è®¡æ–¹æ¡ˆ

#### å†…æ ¸ä¾§ç»“æ„å®šä¹‰

```c
// uvm_bpf_struct_ops.h
struct uvm_eviction_ext {
    /* Eviction selection hook
     * Return: pointer to selected chunk, or NULL to use default LRU
     */
    uvm_gpu_chunk_t *(*pick_evict_chunk)(
        uvm_pmm_gpu_t *pmm,
        struct list_head *va_block_used);

    /* LRU update hook
     * Return: 0 = use default behavior, 1 = BPF handled
     */
    int (*on_chunk_allocated)(
        uvm_pmm_gpu_t *pmm,
        uvm_gpu_chunk_t *chunk,
        uvm_va_block_t *va_block);
};
```

#### BPF ä¾§ç¤ºä¾‹: FIFO ç­–ç•¥

```c
// evict_fifo.bpf.c
#include <vmlinux.h>
#include <bpf/bpf_helpers.h>
#include <bpf/bpf_core_read.h>
#include "uvm_types.h"

/* FIFO ç­–ç•¥: åªåœ¨é¦–æ¬¡åˆ†é…æ—¶åŠ å…¥åˆ—è¡¨ï¼Œä¸æ›´æ–°ä½ç½® */
SEC("struct_ops/on_chunk_allocated")
int BPF_PROG(on_chunk_allocated,
             uvm_pmm_gpu_t *pmm,
             uvm_gpu_chunk_t *chunk,
             uvm_va_block_t *va_block)
{
    uvm_gpu_root_chunk_t *root_chunk = root_chunk_from_chunk(pmm, chunk);

    /* é€šè¿‡ kfunc æ£€æŸ¥ chunk æ˜¯å¦å·²åœ¨åˆ—è¡¨ä¸­ */
    bool in_list = bpf_uvm_chunk_in_list(&root_chunk->chunk.list);

    if (!in_list) {
        /* é¦–æ¬¡åˆ†é…: åŠ åˆ°å°¾éƒ¨ */
        bpf_uvm_list_add_tail(&root_chunk->chunk.list,
                              &pmm->root_chunks.va_block_used);
    }
    /* å¦åˆ™: ä¸æ›´æ–°ä½ç½® (FIFO è¡Œä¸º) */

    return 1; /* UVM_BPF_ACTION_BYPASS - BPF å·²å¤„ç† */
}

SEC(".struct_ops")
struct uvm_eviction_ext uvm_evict_ops_fifo = {
    .on_chunk_allocated = (void *)on_chunk_allocated,
};
```

#### BPF ä¾§ç¤ºä¾‹: Clock ç­–ç•¥

```c
// evict_clock.bpf.c
#include <vmlinux.h>
#include <bpf/bpf_helpers.h>
#include "uvm_types.h"

/* BPF map: ä¸ºæ¯ä¸ª root chunk ç»´æŠ¤ä¸€ä¸ª reference bit */
struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 8192);
    __type(key, u64);   /* chunk address */
    __type(value, u8);  /* reference bit (0 or 1) */
} chunk_ref_bits SEC(".maps");

/* Clock ç­–ç•¥: é€‰æ‹©ç¬¬ä¸€ä¸ª reference bit = 0 çš„ chunk */
SEC("struct_ops/pick_evict_chunk")
uvm_gpu_chunk_t *BPF_PROG(pick_evict_chunk,
                           uvm_pmm_gpu_t *pmm,
                           struct list_head *va_block_used)
{
    uvm_gpu_chunk_t *chunk;

    /* éå† used åˆ—è¡¨ (é€šè¿‡ kfunc helper) */
    bpf_for_each_list_entry(chunk, va_block_used, list) {
        u64 addr = BPF_CORE_READ(chunk, address);
        u8 *ref_bit = bpf_map_lookup_elem(&chunk_ref_bits, &addr);

        if (ref_bit && *ref_bit == 0) {
            /* æ‰¾åˆ° reference bit = 0 çš„ chunk */
            return chunk;
        }

        /* æ¸…é™¤ reference bit (second chance) */
        if (ref_bit) {
            u8 zero = 0;
            bpf_map_update_elem(&chunk_ref_bits, &addr, &zero, BPF_ANY);
        }
    }

    /* æ‰€æœ‰ chunk éƒ½æœ‰ reference bitï¼Œè¿”å›ç¬¬ä¸€ä¸ª */
    return list_first_entry(va_block_used, uvm_gpu_chunk_t, list);
}

/* åˆ†é…æ—¶è®¾ç½® reference bit = 1 */
SEC("struct_ops/on_chunk_allocated")
int BPF_PROG(on_chunk_allocated,
             uvm_pmm_gpu_t *pmm,
             uvm_gpu_chunk_t *chunk,
             uvm_va_block_t *va_block)
{
    u64 addr = BPF_CORE_READ(chunk, address);
    u8 ref_bit = 1;
    bpf_map_update_elem(&chunk_ref_bits, &addr, &ref_bit, BPF_ANY);

    return 0; /* ä½¿ç”¨é»˜è®¤ LRU åˆ—è¡¨æ›´æ–° */
}

SEC(".struct_ops")
struct uvm_eviction_ext uvm_evict_ops_clock = {
    .pick_evict_chunk = (void *)pick_evict_chunk,
    .on_chunk_allocated = (void *)on_chunk_allocated,
};
```

### 4.4 éœ€è¦çš„ Kfuncs

ä¸ºäº†æ”¯æŒä¸Šè¿° BPF ç¨‹åºï¼Œéœ€è¦ä»¥ä¸‹ kfuncs:

```c
/* æ£€æŸ¥ chunk æ˜¯å¦åœ¨åˆ—è¡¨ä¸­ */
__bpf_kfunc bool bpf_uvm_chunk_in_list(struct list_head *list);

/* åˆ—è¡¨æ“ä½œ kfuncs */
__bpf_kfunc void bpf_uvm_list_add_tail(struct list_head *new, struct list_head *head);
__bpf_kfunc void bpf_uvm_list_move_tail(struct list_head *list, struct list_head *head);
__bpf_kfunc void bpf_uvm_list_del_init(struct list_head *entry);

/* åˆ—è¡¨éå† helper (ç±»ä¼¼ bpf_for_each_map_elem) */
__bpf_kfunc long bpf_for_each_list_entry(uvm_gpu_chunk_t *chunk,
                                         struct list_head *head,
                                         void *callback_fn,
                                         void *callback_ctx);

/* è·å– root chunk ä¿¡æ¯ */
__bpf_kfunc uvm_gpu_root_chunk_t *bpf_uvm_root_chunk_from_chunk(
    uvm_pmm_gpu_t *pmm,
    uvm_gpu_chunk_t *chunk);
```

---

## 5. å®ç°è‡ªå®šä¹‰é©±é€ç­–ç•¥

### 5.1 æ–¹æ³• 1: ä¿®æ”¹å†…æ ¸ä»£ç  (æ—  BPF)

å¦‚æœä¸ä½¿ç”¨ BPFï¼Œå¯ä»¥ç›´æ¥ä¿®æ”¹å†…æ ¸ä»£ç å®ç°è‡ªå®šä¹‰ç­–ç•¥ã€‚

#### å®ç° FIFO (First-In-First-Out)

**ä¿®æ”¹æ–‡ä»¶**: `kernel-open/nvidia-uvm/uvm_pmm_gpu.c`

**ä¿®æ”¹ç‚¹ 1**: `chunk_update_lists_locked()` (Line 627)

```c
static void chunk_update_lists_locked(uvm_pmm_gpu_t *pmm, uvm_gpu_chunk_t *chunk)
{
    uvm_gpu_root_chunk_t *root_chunk = root_chunk_from_chunk(pmm, chunk);

    uvm_assert_spinlock_locked(&pmm->list_lock);

    if (uvm_gpu_chunk_is_user(chunk)) {
        if (chunk_is_root_chunk_pinned(pmm, chunk)) {
            list_del_init(&root_chunk->chunk.list);
        }
        else if (root_chunk->chunk.state != UVM_PMM_GPU_CHUNK_STATE_FREE) {
            // FIFO ä¿®æ”¹: åªåœ¨é¦–æ¬¡åŠ å…¥åˆ—è¡¨æ—¶æ“ä½œ
            if (list_empty(&root_chunk->chunk.list)) {
                list_add_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
            }
            // å¦åˆ™ä¸æ›´æ–°ä½ç½® (ä¿æŒ FIFO é¡ºåº)
        }
    }

    // å…¶ä½™é€»è¾‘ä¸å˜
    ...
}
```

**æ•ˆæœ**:
- âœ… LRU â†’ FIFO: æœ€æ—©åˆ†é…çš„å…ˆé©±é€
- âœ… åªéœ€ä¿®æ”¹ 1 ä¸ªå‡½æ•°
- âš ï¸ ä¸è€ƒè™‘è®¿é—®æ¨¡å¼ï¼Œå¯èƒ½é©±é€çƒ­æ•°æ®

#### å®ç°è®¿é—®é¢‘ç‡é©±é€ (LFU - Least Frequently Used)

**ä¿®æ”¹ç‚¹ 1**: æ·»åŠ è®¿é—®è®¡æ•°å­—æ®µ

```c
// uvm_pmm_gpu.h
typedef struct {
    uvm_gpu_chunk_t chunk;
    uvm_tracker_t tracker;

    /* æ–°å¢: è®¿é—®è®¡æ•° */
    atomic64_t access_count;
} uvm_gpu_root_chunk_t;
```

**ä¿®æ”¹ç‚¹ 2**: åœ¨ chunk ä½¿ç”¨æ—¶å¢åŠ è®¡æ•°

```c
// chunk_update_lists_locked()
static void chunk_update_lists_locked(uvm_pmm_gpu_t *pmm, uvm_gpu_chunk_t *chunk)
{
    uvm_gpu_root_chunk_t *root_chunk = root_chunk_from_chunk(pmm, chunk);

    if (uvm_gpu_chunk_is_user(chunk)) {
        if (!chunk_is_root_chunk_pinned(pmm, chunk) &&
            root_chunk->chunk.state != UVM_PMM_GPU_CHUNK_STATE_FREE) {
            /* å¢åŠ è®¿é—®è®¡æ•° */
            atomic64_inc(&root_chunk->access_count);

            /* ä»ç„¶ç§»åˆ°å°¾éƒ¨ (ä¿æŒåˆ—è¡¨æœ‰åº) */
            list_move_tail(&root_chunk->chunk.list, &pmm->root_chunks.va_block_used);
        }
    }
}
```

**ä¿®æ”¹ç‚¹ 3**: é©±é€é€‰æ‹©æ—¶æ‰¾è®¿é—®æœ€å°‘çš„ chunk

```c
// pick_root_chunk_to_evict()
static uvm_gpu_root_chunk_t *pick_root_chunk_to_evict(uvm_pmm_gpu_t *pmm)
{
    uvm_gpu_chunk_t *chunk;
    uvm_gpu_root_chunk_t *min_chunk = NULL;
    u64 min_count = ULLONG_MAX;

    uvm_spin_lock(&pmm->list_lock);

    /* éå† used åˆ—è¡¨ï¼Œæ‰¾è®¿é—®è®¡æ•°æœ€å°çš„ */
    list_for_each_entry(chunk, &pmm->root_chunks.va_block_used, list) {
        uvm_gpu_root_chunk_t *root = root_chunk_from_chunk(pmm, chunk);
        u64 count = atomic64_read(&root->access_count);

        if (count < min_count) {
            min_count = count;
            min_chunk = root;
        }
    }

    if (min_chunk)
        chunk_start_eviction(pmm, &min_chunk->chunk);

    uvm_spin_unlock(&pmm->list_lock);

    return min_chunk;
}
```

**æ•ˆæœ**:
- âœ… LRU â†’ LFU: è®¿é—®æœ€å°‘çš„å…ˆé©±é€
- âš ï¸ éœ€è¦éå†æ•´ä¸ªåˆ—è¡¨ (O(n)ï¼Œå¯èƒ½å½±å“æ€§èƒ½)
- âš ï¸ éœ€è¦åŸå­æ“ä½œç»´æŠ¤è®¡æ•°

### 5.2 æ–¹æ³• 2: é€šè¿‡æ¨¡å—å‚æ•°åˆ‡æ¢ç­–ç•¥

åˆ›å»ºä¸€ä¸ªå¯é…ç½®çš„é©±é€ç­–ç•¥æ¡†æ¶:

```c
// uvm_pmm_gpu.c
typedef enum {
    UVM_EVICT_POLICY_LRU,
    UVM_EVICT_POLICY_FIFO,
    UVM_EVICT_POLICY_LFU,
    UVM_EVICT_POLICY_CLOCK,
} uvm_evict_policy_t;

static uvm_evict_policy_t g_evict_policy = UVM_EVICT_POLICY_LRU;
module_param_named(evict_policy, g_evict_policy, int, S_IRUGO);
MODULE_PARM_DESC(evict_policy, "Eviction policy: 0=LRU, 1=FIFO, 2=LFU, 3=Clock");

// åœ¨ pick_root_chunk_to_evict() ä¸­æ ¹æ®ç­–ç•¥é€‰æ‹©
static uvm_gpu_root_chunk_t *pick_root_chunk_to_evict(uvm_pmm_gpu_t *pmm)
{
    switch (g_evict_policy) {
    case UVM_EVICT_POLICY_LRU:
        return pick_root_chunk_lru(pmm);
    case UVM_EVICT_POLICY_FIFO:
        return pick_root_chunk_fifo(pmm);
    case UVM_EVICT_POLICY_LFU:
        return pick_root_chunk_lfu(pmm);
    case UVM_EVICT_POLICY_CLOCK:
        return pick_root_chunk_clock(pmm);
    default:
        return pick_root_chunk_lru(pmm);
    }
}
```

**åŠ è½½å†…æ ¸æ¨¡å—æ—¶æŒ‡å®šç­–ç•¥**:
```bash
sudo modprobe nvidia-uvm evict_policy=1  # ä½¿ç”¨ FIFO
```

---

## 6. è°ƒè¯•å’Œæ€§èƒ½åˆ†æ

### 6.1 æ·»åŠ  Tracepoint

åœ¨å…³é”®è·¯å¾„æ’å…¥ printk æˆ– tracepoint:

```c
// uvm_pmm_gpu.c:1490
if (!chunk)
    chunk = list_first_chunk(&pmm->root_chunks.va_block_used);

if (chunk) {
    /* æ·»åŠ è°ƒè¯•è¾“å‡º */
    pr_info("UVM Evict: Selected chunk at PA 0x%llx, state=%s\n",
            chunk->address,
            uvm_pmm_gpu_chunk_state_string(chunk->state));

    chunk_start_eviction(pmm, chunk);
}
```

### 6.2 ç»Ÿè®¡ä¿¡æ¯æ”¶é›†

æ·»åŠ é©±é€ç»Ÿè®¡è®¡æ•°:

```c
// uvm_pmm_gpu.h
struct {
    atomic64_t eviction_count;          // æ€»é©±é€æ¬¡æ•°
    atomic64_t eviction_from_lru;       // ä» LRU åˆ—è¡¨é©±é€
    atomic64_t eviction_from_unused;    // ä» unused åˆ—è¡¨é©±é€
    atomic64_t eviction_from_free;      // ä» free åˆ—è¡¨é©±é€
} stats;

// åœ¨ pick_root_chunk_to_evict() ä¸­æ›´æ–°
if (chunk) {
    atomic64_inc(&pmm->stats.eviction_count);
    if (/* from lru */)
        atomic64_inc(&pmm->stats.eviction_from_lru);
}
```

### 6.3 é€šè¿‡ /proc æš´éœ²ç»Ÿè®¡

```c
// uvm_pmm_gpu.c
static int eviction_stats_show(struct seq_file *s, void *data)
{
    uvm_pmm_gpu_t *pmm = s->private;

    seq_printf(s, "Total evictions: %llu\n",
               atomic64_read(&pmm->stats.eviction_count));
    seq_printf(s, "From LRU list: %llu\n",
               atomic64_read(&pmm->stats.eviction_from_lru));
    seq_printf(s, "From unused list: %llu\n",
               atomic64_read(&pmm->stats.eviction_from_unused));
    seq_printf(s, "From free list: %llu\n",
               atomic64_read(&pmm->stats.eviction_from_free));

    return 0;
}

// åˆ›å»º /proc/driver/nvidia-uvm/eviction_stats
proc_create_single("eviction_stats", 0, uvm_proc_dir, eviction_stats_show);
```

æŸ¥çœ‹ç»Ÿè®¡:
```bash
cat /proc/driver/nvidia-uvm/eviction_stats
```

### 6.4 ä½¿ç”¨ eBPF ç›‘æ§ (å¦‚æœæœ‰ BPF æ”¯æŒ)

```bash
# ç›‘æ§é©±é€äº‹ä»¶
sudo bpftrace -e '
kprobe:pick_root_chunk_to_evict {
    printf("Eviction triggered\n");
}

kretprobe:pick_root_chunk_to_evict {
    if (retval != 0) {
        printf("Evicted chunk at 0x%lx\n", retval);
    }
}
'
```

---

## 7. æ€»ç»“

### 7.1 æ ¸å¿ƒè¦ç‚¹

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **ç²’åº¦** | 2MB root chunk (ä¸ CPU å¤§é¡µç›¸åŒ) |
| **æ•°æ®ç»“æ„** | åŒå‘é“¾è¡¨ (`list_head`) |
| **æ›´æ–°æ—¶æœº** | åˆ†é…/unpin æ—¶ (ä¸è¿½è¸ªå®é™…è®¿é—®) |
| **é©±é€ä¼˜å…ˆçº§** | Free â†’ Unused â†’ LRU (ä»å¤´éƒ¨é€‰) |
| **åˆ—è¡¨æ’åº** | HEAD = æœ€ä¹…æœªä½¿ç”¨ï¼ŒTAIL = æœ€è¿‘ä½¿ç”¨ |

### 7.2 é™åˆ¶å’Œæ³¨æ„äº‹é¡¹

1. **ä¸è¿½è¸ªå®é™…è®¿é—®** (TODO Line 1487-1488)
   - åªåœ¨åˆ†é…æ—¶æ›´æ–° LRU
   - å¯†é›†è®¿é—®åœºæ™¯ä¸‹é€€åŒ–ä¸º "æœ€æ—©åˆ†é…å…ˆé©±é€"

2. **é©±é€æ¡ä»¶**
   - Chunk ä¸èƒ½å¤„äº `TEMP_PINNED` æˆ–æ­£åœ¨é©±é€çŠ¶æ€
   - å­ chunks è¢« pin ä¼šé˜»æ­¢æ•´ä¸ª root chunk é©±é€

3. **å½“å‰æ—  BPF æ”¯æŒ**
   - éœ€è¦ä¿®æ”¹å†…æ ¸ä»£ç å®ç°è‡ªå®šä¹‰ç­–ç•¥
   - æˆ–ç­‰å¾…ç¤¾åŒºæ·»åŠ  BPF struct_ops æ”¯æŒ

### 7.3 æ¨èå®è·µ

#### å¦‚æœè¦å®ç°è‡ªå®šä¹‰é©±é€ç­–ç•¥:

**é€‰é¡¹ 1: ä¿®æ”¹å†…æ ¸ (æœ€ç®€å•)**
- ä¿®æ”¹ `pick_root_chunk_to_evict()` - æ”¹å˜é€‰æ‹©é€»è¾‘
- ä¿®æ”¹ `chunk_update_lists_locked()` - æ”¹å˜æ›´æ–°ç­–ç•¥

**é€‰é¡¹ 2: æ·»åŠ  BPF æ”¯æŒ (æœ€çµæ´»)**
- åœ¨ `pick_root_chunk_to_evict()` å‰æ·»åŠ  BPF hook
- åœ¨ `chunk_update_lists_locked()` ä¸­æ·»åŠ  BPF hook
- å®ç° kfuncs ä¾› BPF ç¨‹åºä½¿ç”¨

**é€‰é¡¹ 3: æ¨¡å—å‚æ•°åˆ‡æ¢ (æŠ˜ä¸­æ–¹æ¡ˆ)**
- é¢„å…ˆå®ç°å¤šç§ç­–ç•¥
- é€šè¿‡æ¨¡å—å‚æ•°åœ¨åŠ è½½æ—¶é€‰æ‹©

### 7.4 ä¸ Prefetch çš„ååŒä½¿ç”¨

| åœºæ™¯ | Prefetch ç­–ç•¥ | LRU ç­–ç•¥ | æ•ˆæœ |
|------|--------------|---------|------|
| **é¡ºåºè®¿é—®** | Always Max | LRU | æœ€å¤§åŒ–é¢„å–ï¼Œæœ€ä¹…æœªè®¿é—®å…ˆé©±é€ |
| **éšæœºè®¿é—®** | None | FIFO/Clock | ç¦ç”¨é¢„å–ï¼Œå…¬å¹³é©±é€ |
| **çƒ­æ•°æ®é›†** | Adaptive | LFU | åŠ¨æ€é¢„å–ï¼Œä¿æŠ¤çƒ­æ•°æ® |
| **Thrashing** | Thrashing-aware | Conservative | é¿å…é¢„å–æŠ–åŠ¨é¡µï¼Œé¿å…é©±é€ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-11-23
**ä½œè€…**: UVM BPF Extension Project
**å‚è€ƒä»£ç **:
- å†…æ ¸ä¾§: `kernel-open/nvidia-uvm/uvm_pmm_gpu.c`, `uvm_pmm_gpu.h`
- ç›¸å…³æ–‡æ¡£: `UVM_LRU_POLICY.md`, `UVM_PREFETCH_POLICY_ANALYSIS.md`
