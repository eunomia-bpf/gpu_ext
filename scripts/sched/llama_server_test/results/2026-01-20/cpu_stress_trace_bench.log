INFO 01-20 16:14:13 [__init__.py:216] Automatically detected platform cuda.
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x713a689265c0>, seed=0, num_prompts=100, dataset_name='sharegpt', no_stream=False, dataset_path='/home/yunwei37/workspace/gpu/schedcp/workloads/vllm/datasets/ShareGPT_V3_unfiltered_cleaned_split.json', no_oversample=False, custom_output_len=256, custom_skip_chat_template=False, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 0}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', endpoint_type=None, base_url='http://127.0.0.1:8013', host='127.0.0.1', port=8000, endpoint='/v1/completions', header=None, max_concurrency=1, model='Qwen/Qwen3-30B-A3B-FP8', tokenizer=None, use_beam_search=False, logprobs=None, request_rate=1.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, request_id_prefix='benchmark-serving', top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
 |          | 00:00 elapsed, ? remaining |          | 00:00 elapsed, 00:00 remaining |          | 00:00 elapsed, 3:44:17 remaining
Initial test run completed. Starting main benchmark run...
Traffic request rate: 1.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 1
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<02:37,  1.59s/it]  2%|▏         | 2/100 [00:06<06:07,  3.75s/it]  3%|▎         | 3/100 [00:08<04:15,  2.63s/it]  4%|▍         | 4/100 [00:09<03:18,  2.07s/it]  5%|▌         | 5/100 [00:10<02:28,  1.56s/it]  6%|▌         | 6/100 [00:14<03:47,  2.42s/it]  7%|▋         | 7/100 [00:14<02:35,  1.67s/it]  8%|▊         | 8/100 [00:14<01:51,  1.22s/it]  9%|▉         | 9/100 [00:15<01:32,  1.01s/it] 10%|█         | 10/100 [00:17<02:04,  1.38s/it] 11%|█         | 11/100 [00:17<01:42,  1.15s/it] 12%|█▏        | 12/100 [00:20<02:10,  1.48s/it] 13%|█▎        | 13/100 [00:20<01:38,  1.13s/it] 14%|█▍        | 14/100 [00:22<01:51,  1.29s/it] 16%|█▌        | 16/100 [00:23<01:18,  1.07it/s] 17%|█▋        | 17/100 [00:24<01:30,  1.09s/it] 18%|█▊        | 18/100 [00:26<01:47,  1.31s/it] 19%|█▉        | 19/100 [00:26<01:24,  1.04s/it] 20%|██        | 20/100 [00:30<02:28,  1.86s/it] 21%|██        | 21/100 [00:32<02:28,  1.88s/it] 22%|██▏       | 22/100 [00:33<02:06,  1.62s/it] 23%|██▎       | 23/100 [00:34<01:46,  1.38s/it] 24%|██▍       | 24/100 [00:34<01:20,  1.06s/it] 25%|██▌       | 25/100 [00:35<01:04,  1.16it/s] 27%|██▋       | 27/100 [00:36<00:46,  1.57it/s] 28%|██▊       | 28/100 [00:39<01:32,  1.28s/it] 30%|███       | 30/100 [00:39<01:01,  1.14it/s] 31%|███       | 31/100 [00:40<00:49,  1.39it/s] 32%|███▏      | 32/100 [00:44<01:55,  1.70s/it] 33%|███▎      | 33/100 [00:45<01:36,  1.44s/it] 34%|███▍      | 34/100 [00:48<02:00,  1.83s/it] 35%|███▌      | 35/100 [00:49<01:39,  1.53s/it] 37%|███▋      | 37/100 [00:50<01:11,  1.13s/it] 38%|███▊      | 38/100 [00:51<01:09,  1.12s/it] 39%|███▉      | 39/100 [00:51<00:53,  1.13it/s] 41%|████      | 41/100 [00:53<00:47,  1.24it/s] 43%|████▎     | 43/100 [00:55<00:57,  1.02s/it] 44%|████▍     | 44/100 [00:57<01:00,  1.08s/it] 45%|████▌     | 45/100 [00:57<00:55,  1.01s/it] 46%|████▌     | 46/100 [00:58<00:44,  1.21it/s] 47%|████▋     | 47/100 [00:59<00:52,  1.02it/s] 48%|████▊     | 48/100 [00:59<00:40,  1.29it/s] 49%|████▉     | 49/100 [01:01<00:45,  1.12it/s] 50%|█████     | 50/100 [01:01<00:34,  1.45it/s] 51%|█████     | 51/100 [01:02<00:39,  1.23it/s] 52%|█████▏    | 52/100 [01:02<00:34,  1.40it/s] 53%|█████▎    | 53/100 [01:04<00:52,  1.11s/it] 54%|█████▍    | 54/100 [01:09<01:34,  2.05s/it] 55%|█████▌    | 55/100 [01:09<01:07,  1.50s/it] 56%|█████▌    | 56/100 [01:10<00:56,  1.29s/it] 57%|█████▋    | 57/100 [01:10<00:41,  1.04it/s] 59%|█████▉    | 59/100 [01:10<00:22,  1.84it/s] 60%|██████    | 60/100 [01:12<00:33,  1.18it/s] 62%|██████▏   | 62/100 [01:14<00:36,  1.03it/s] 63%|██████▎   | 63/100 [01:15<00:39,  1.06s/it] 64%|██████▍   | 64/100 [01:16<00:37,  1.03s/it] 66%|██████▌   | 66/100 [01:17<00:22,  1.50it/s] 67%|██████▋   | 67/100 [01:17<00:18,  1.76it/s] 69%|██████▉   | 69/100 [01:17<00:12,  2.58it/s] 71%|███████   | 71/100 [01:19<00:15,  1.87it/s] 72%|███████▏  | 72/100 [01:20<00:16,  1.66it/s] 73%|███████▎  | 73/100 [01:21<00:23,  1.16it/s] 74%|███████▍  | 74/100 [01:27<00:50,  1.95s/it] 75%|███████▌  | 75/100 [01:27<00:39,  1.57s/it] 76%|███████▌  | 76/100 [01:30<00:47,  1.98s/it] 77%|███████▋  | 77/100 [01:30<00:34,  1.48s/it] 78%|███████▊  | 78/100 [01:32<00:31,  1.44s/it] 79%|███████▉  | 79/100 [01:33<00:31,  1.52s/it] 80%|████████  | 80/100 [01:36<00:37,  1.88s/it] 81%|████████  | 81/100 [01:37<00:30,  1.60s/it] 82%|████████▏ | 82/100 [01:38<00:24,  1.35s/it] 84%|████████▍ | 84/100 [01:38<00:12,  1.26it/s] 85%|████████▌ | 85/100 [01:39<00:13,  1.08it/s] 87%|████████▋ | 87/100 [01:40<00:07,  1.71it/s] 88%|████████▊ | 88/100 [01:42<00:13,  1.09s/it] 89%|████████▉ | 89/100 [01:45<00:14,  1.34s/it] 90%|█████████ | 90/100 [01:45<00:10,  1.09s/it] 91%|█████████ | 91/100 [01:45<00:07,  1.15it/s] 92%|█████████▏| 92/100 [01:48<00:11,  1.42s/it] 93%|█████████▎| 93/100 [01:50<00:11,  1.66s/it] 94%|█████████▍| 94/100 [01:53<00:12,  2.02s/it] 95%|█████████▌| 95/100 [01:53<00:07,  1.49s/it] 96%|█████████▌| 96/100 [01:56<00:07,  1.75s/it] 97%|█████████▋| 97/100 [01:58<00:05,  1.99s/it] 98%|█████████▊| 98/100 [02:01<00:04,  2.17s/it] 99%|█████████▉| 99/100 [02:01<00:01,  1.60s/it]100%|██████████| 100/100 [02:04<00:00,  2.10s/it]100%|██████████| 100/100 [02:04<00:00,  1.25s/it]
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     88        
Maximum request concurrency:             1         
Request rate configured (RPS):           1.00      
Benchmark duration (s):                  124.94    
Total input tokens:                      20665     
Total generated tokens:                  20485     
Request throughput (req/s):              0.70      
Output token throughput (tok/s):         163.96    
Peak output token throughput (tok/s):    255.00    
Peak concurrent requests:                4.00      
Total Token throughput (tok/s):          329.35    
---------------Time to First Token----------------
Mean TTFT (ms):                          105.42    
Median TTFT (ms):                        104.87    
P99 TTFT (ms):                           198.15    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          5.51      
Median TPOT (ms):                        5.43      
P99 TPOT (ms):                           8.48      
---------------Inter-token Latency----------------
Mean ITL (ms):                           5.36      
Median ITL (ms):                         5.41      
P99 ITL (ms):                            11.12     
==================================================
