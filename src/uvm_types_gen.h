#ifndef __UVM_TYPES_GEN_H__
#define __UVM_TYPES_GEN_H__

#ifndef BPF_NO_PRESERVE_ACCESS_INDEX
#pragma clang attribute push (__attribute__((preserve_access_index)), apply_to = record)
#endif

#ifndef __ksym
#define __ksym __attribute__((section(".ksyms")))
#endif

#ifndef __weak
#define __weak __attribute__((weak))
#endif

#ifndef __bpf_fastcall
#if __has_attribute(bpf_fastcall)
#define __bpf_fastcall __attribute__((bpf_fastcall))
#else
#define __bpf_fastcall
#endif
#endif

enum {
	NVIDIA_UVM_PRIMARY_MINOR_NUMBER = 0,
	NVIDIA_UVM_TOOLS_MINOR_NUMBER = 1,
	NVIDIA_UVM_NUM_MINOR_DEVICES = 2,
};

enum {
	NV_DEV_STACK_TIMER = 0,
	NV_DEV_STACK_ISR = 1,
	NV_DEV_STACK_ISR_BH = 2,
	NV_DEV_STACK_ISR_BH_UNLOCKED = 3,
	NV_DEV_STACK_GPU_WAKEUP = 4,
	NV_DEV_STACK_COUNT = 5,
};

enum {
	NV_OK = 0,
	NV_ERR_GENERIC = 65535,
	NV_ERR_BROKEN_FB = 1,
	NV_ERR_BUFFER_TOO_SMALL = 2,
	NV_ERR_BUSY_RETRY = 3,
	NV_ERR_CALLBACK_NOT_SCHEDULED = 4,
	NV_ERR_CARD_NOT_PRESENT = 5,
	NV_ERR_CYCLE_DETECTED = 6,
	NV_ERR_DMA_IN_USE = 7,
	NV_ERR_DMA_MEM_NOT_LOCKED = 8,
	NV_ERR_DMA_MEM_NOT_UNLOCKED = 9,
	NV_ERR_DUAL_LINK_INUSE = 10,
	NV_ERR_ECC_ERROR = 11,
	NV_ERR_FIFO_BAD_ACCESS = 12,
	NV_ERR_FREQ_NOT_SUPPORTED = 13,
	NV_ERR_GPU_DMA_NOT_INITIALIZED = 14,
	NV_ERR_GPU_IS_LOST = 15,
	NV_ERR_GPU_IN_FULLCHIP_RESET = 16,
	NV_ERR_GPU_NOT_FULL_POWER = 17,
	NV_ERR_GPU_UUID_NOT_FOUND = 18,
	NV_ERR_HOT_SWITCH = 19,
	NV_ERR_I2C_ERROR = 20,
	NV_ERR_I2C_SPEED_TOO_HIGH = 21,
	NV_ERR_ILLEGAL_ACTION = 22,
	NV_ERR_IN_USE = 23,
	NV_ERR_INFLATE_COMPRESSED_DATA_FAILED = 24,
	NV_ERR_INSERT_DUPLICATE_NAME = 25,
	NV_ERR_INSUFFICIENT_RESOURCES = 26,
	NV_ERR_INSUFFICIENT_PERMISSIONS = 27,
	NV_ERR_INSUFFICIENT_POWER = 28,
	NV_ERR_INVALID_ACCESS_TYPE = 29,
	NV_ERR_INVALID_ADDRESS = 30,
	NV_ERR_INVALID_ARGUMENT = 31,
	NV_ERR_INVALID_BASE = 32,
	NV_ERR_INVALID_CHANNEL = 33,
	NV_ERR_INVALID_CLASS = 34,
	NV_ERR_INVALID_CLIENT = 35,
	NV_ERR_INVALID_COMMAND = 36,
	NV_ERR_INVALID_DATA = 37,
	NV_ERR_INVALID_DEVICE = 38,
	NV_ERR_INVALID_DMA_SPECIFIER = 39,
	NV_ERR_INVALID_EVENT = 40,
	NV_ERR_INVALID_FLAGS = 41,
	NV_ERR_INVALID_FUNCTION = 42,
	NV_ERR_INVALID_HEAP = 43,
	NV_ERR_INVALID_INDEX = 44,
	NV_ERR_INVALID_IRQ_LEVEL = 45,
	NV_ERR_INVALID_LIMIT = 46,
	NV_ERR_INVALID_LOCK_STATE = 47,
	NV_ERR_INVALID_METHOD = 48,
	NV_ERR_INVALID_OBJECT = 49,
	NV_ERR_INVALID_OBJECT_BUFFER = 50,
	NV_ERR_INVALID_OBJECT_HANDLE = 51,
	NV_ERR_INVALID_OBJECT_NEW = 52,
	NV_ERR_INVALID_OBJECT_OLD = 53,
	NV_ERR_INVALID_OBJECT_PARENT = 54,
	NV_ERR_INVALID_OFFSET = 55,
	NV_ERR_INVALID_OPERATION = 56,
	NV_ERR_INVALID_OWNER = 57,
	NV_ERR_INVALID_PARAM_STRUCT = 58,
	NV_ERR_INVALID_PARAMETER = 59,
	NV_ERR_INVALID_PATH = 60,
	NV_ERR_INVALID_POINTER = 61,
	NV_ERR_INVALID_REGISTRY_KEY = 62,
	NV_ERR_INVALID_REQUEST = 63,
	NV_ERR_INVALID_STATE = 64,
	NV_ERR_INVALID_STRING_LENGTH = 65,
	NV_ERR_INVALID_READ = 66,
	NV_ERR_INVALID_WRITE = 67,
	NV_ERR_INVALID_XLATE = 68,
	NV_ERR_IRQ_NOT_FIRING = 69,
	NV_ERR_IRQ_EDGE_TRIGGERED = 70,
	NV_ERR_MEMORY_TRAINING_FAILED = 71,
	NV_ERR_MISMATCHED_SLAVE = 72,
	NV_ERR_MISMATCHED_TARGET = 73,
	NV_ERR_MISSING_TABLE_ENTRY = 74,
	NV_ERR_MODULE_LOAD_FAILED = 75,
	NV_ERR_MORE_DATA_AVAILABLE = 76,
	NV_ERR_MORE_PROCESSING_REQUIRED = 77,
	NV_ERR_MULTIPLE_MEMORY_TYPES = 78,
	NV_ERR_NO_FREE_FIFOS = 79,
	NV_ERR_NO_INTR_PENDING = 80,
	NV_ERR_NO_MEMORY = 81,
	NV_ERR_NO_SUCH_DOMAIN = 82,
	NV_ERR_NO_VALID_PATH = 83,
	NV_ERR_NOT_COMPATIBLE = 84,
	NV_ERR_NOT_READY = 85,
	NV_ERR_NOT_SUPPORTED = 86,
	NV_ERR_OBJECT_NOT_FOUND = 87,
	NV_ERR_OBJECT_TYPE_MISMATCH = 88,
	NV_ERR_OPERATING_SYSTEM = 89,
	NV_ERR_OTHER_DEVICE_FOUND = 90,
	NV_ERR_OUT_OF_RANGE = 91,
	NV_ERR_OVERLAPPING_UVM_COMMIT = 92,
	NV_ERR_PAGE_TABLE_NOT_AVAIL = 93,
	NV_ERR_PID_NOT_FOUND = 94,
	NV_ERR_PROTECTION_FAULT = 95,
	NV_ERR_RC_ERROR = 96,
	NV_ERR_REJECTED_VBIOS = 97,
	NV_ERR_RESET_REQUIRED = 98,
	NV_ERR_STATE_IN_USE = 99,
	NV_ERR_SIGNAL_PENDING = 100,
	NV_ERR_TIMEOUT = 101,
	NV_ERR_TIMEOUT_RETRY = 102,
	NV_ERR_TOO_MANY_PRIMARIES = 103,
	NV_ERR_UVM_ADDRESS_IN_USE = 104,
	NV_ERR_MAX_SESSION_LIMIT_REACHED = 105,
	NV_ERR_LIB_RM_VERSION_MISMATCH = 106,
	NV_ERR_PRIV_SEC_VIOLATION = 107,
	NV_ERR_GPU_IN_DEBUG_MODE = 108,
	NV_ERR_FEATURE_NOT_ENABLED = 109,
	NV_ERR_RESOURCE_LOST = 110,
	NV_ERR_PMU_NOT_READY = 111,
	NV_ERR_FLCN_ERROR = 112,
	NV_ERR_FATAL_ERROR = 113,
	NV_ERR_MEMORY_ERROR = 114,
	NV_ERR_INVALID_LICENSE = 115,
	NV_ERR_NVLINK_INIT_ERROR = 116,
	NV_ERR_NVLINK_MINION_ERROR = 117,
	NV_ERR_NVLINK_CLOCK_ERROR = 118,
	NV_ERR_NVLINK_TRAINING_ERROR = 119,
	NV_ERR_NVLINK_CONFIGURATION_ERROR = 120,
	NV_ERR_RISCV_ERROR = 121,
	NV_ERR_FABRIC_MANAGER_NOT_PRESENT = 122,
	NV_ERR_ALREADY_SIGNALLED = 123,
	NV_ERR_QUEUE_TASK_SLOT_NOT_AVAILABLE = 124,
	NV_ERR_KEY_ROTATION_IN_PROGRESS = 125,
	NV_ERR_TEST_ONLY_CODE_NOT_ENABLED = 126,
	NV_ERR_SECURE_BOOT_FAILED = 127,
	NV_ERR_INSUFFICIENT_ZBC_ENTRY = 128,
	NV_ERR_NVLINK_FABRIC_NOT_READY = 129,
	NV_ERR_NVLINK_FABRIC_FAILURE = 130,
	NV_ERR_GPU_MEMORY_ONLINING_FAILURE = 131,
	NV_ERR_REDUCTION_MANAGER_NOT_AVAILABLE = 132,
	NV_ERR_THRESHOLD_CROSSED = 133,
	NV_ERR_RESOURCE_RETIREMENT_ERROR = 134,
	NV_ERR_FABRIC_STATE_OUT_OF_SYNC = 135,
	NV_ERR_BUFFER_FULL = 136,
	NV_ERR_BUFFER_EMPTY = 137,
	NV_WARN_HOT_SWITCH = 65537,
	NV_WARN_INCORRECT_PERFMON_DATA = 65538,
	NV_WARN_MISMATCHED_SLAVE = 65539,
	NV_WARN_MISMATCHED_TARGET = 65540,
	NV_WARN_MORE_PROCESSING_REQUIRED = 65541,
	NV_WARN_NOTHING_TO_DO = 65542,
	NV_WARN_NULL_OBJECT = 65543,
	NV_WARN_OUT_OF_RANGE = 65544,
	NV_WARN_THRESHOLD_CROSSED = 65545,
};

enum {
	TEST_INLINE_ADD = 0,
	TEST_INLINE_GET = 1,
	TEST_INLINE_SINGLE_BUFFER = 2,
	TEST_INLINE_MAX = 3,
};

enum {
	UVM_ADA_GPC_UTLB_ID_RGG = 0,
	UVM_ADA_GPC_UTLB_ID_LTP0 = 1,
	UVM_ADA_GPC_UTLB_ID_LTP1 = 2,
	UVM_ADA_GPC_UTLB_ID_LTP2 = 3,
	UVM_ADA_GPC_UTLB_ID_LTP3 = 4,
	UVM_ADA_GPC_UTLB_ID_LTP4 = 5,
	UVM_ADA_GPC_UTLB_ID_LTP5 = 6,
	UVM_ADA_GPC_UTLB_ID_LTP6 = 7,
	UVM_ADA_GPC_UTLB_ID_LTP7 = 8,
	UVM_ADA_GPC_UTLB_ID_LTP8 = 9,
	UVM_ADA_GPC_UTLB_ID_LTP9 = 10,
	UVM_ADA_GPC_UTLB_ID_LTP10 = 11,
	UVM_ADA_GPC_UTLB_ID_LTP11 = 12,
	UVM_ADA_GPC_UTLB_COUNT = 13,
};

enum {
	UVM_AMPERE_GPC_UTLB_ID_RGG = 0,
	UVM_AMPERE_GPC_UTLB_ID_LTP0 = 1,
	UVM_AMPERE_GPC_UTLB_ID_LTP1 = 2,
	UVM_AMPERE_GPC_UTLB_ID_LTP2 = 3,
	UVM_AMPERE_GPC_UTLB_ID_LTP3 = 4,
	UVM_AMPERE_GPC_UTLB_ID_LTP4 = 5,
	UVM_AMPERE_GPC_UTLB_ID_LTP5 = 6,
	UVM_AMPERE_GPC_UTLB_ID_LTP6 = 7,
	UVM_AMPERE_GPC_UTLB_ID_LTP7 = 8,
	UVM_AMPERE_GPC_UTLB_ID_LTP8 = 9,
	UVM_AMPERE_GPC_UTLB_ID_LTP9 = 10,
	UVM_AMPERE_GPC_UTLB_ID_LTP10 = 11,
	UVM_AMPERE_GPC_UTLB_ID_LTP11 = 12,
	UVM_AMPERE_GPC_UTLB_ID_LTP12 = 13,
	UVM_AMPERE_GPC_UTLB_ID_LTP13 = 14,
	UVM_AMPERE_GPC_UTLB_ID_LTP14 = 15,
	UVM_AMPERE_GPC_UTLB_ID_LTP15 = 16,
	UVM_AMPERE_GPC_UTLB_COUNT = 17,
};

enum {
	UVM_BLACKWELL_GPC_UTLB_ID_RGG = 0,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP0 = 1,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP1 = 2,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP2 = 3,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP3 = 4,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP4 = 5,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP5 = 6,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP6 = 7,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP7 = 8,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP8 = 9,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP9 = 10,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP10 = 11,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP11 = 12,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP12 = 13,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP13 = 14,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP14 = 15,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP15 = 16,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP16 = 17,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP17 = 18,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP18 = 19,
	UVM_BLACKWELL_GPC_UTLB_ID_LTP19 = 20,
	UVM_BLACKWELL_GPC_UTLB_COUNT = 21,
};

enum {
	UVM_HOPPER_GPC_UTLB_ID_RGG = 0,
	UVM_HOPPER_GPC_UTLB_ID_LTP0 = 1,
	UVM_HOPPER_GPC_UTLB_ID_LTP1 = 2,
	UVM_HOPPER_GPC_UTLB_ID_LTP2 = 3,
	UVM_HOPPER_GPC_UTLB_ID_LTP3 = 4,
	UVM_HOPPER_GPC_UTLB_ID_LTP4 = 5,
	UVM_HOPPER_GPC_UTLB_ID_LTP5 = 6,
	UVM_HOPPER_GPC_UTLB_ID_LTP6 = 7,
	UVM_HOPPER_GPC_UTLB_ID_LTP7 = 8,
	UVM_HOPPER_GPC_UTLB_ID_LTP8 = 9,
	UVM_HOPPER_GPC_UTLB_ID_LTP9 = 10,
	UVM_HOPPER_GPC_UTLB_ID_LTP10 = 11,
	UVM_HOPPER_GPC_UTLB_ID_LTP11 = 12,
	UVM_HOPPER_GPC_UTLB_ID_LTP12 = 13,
	UVM_HOPPER_GPC_UTLB_ID_LTP13 = 14,
	UVM_HOPPER_GPC_UTLB_ID_LTP14 = 15,
	UVM_HOPPER_GPC_UTLB_ID_LTP15 = 16,
	UVM_HOPPER_GPC_UTLB_ID_LTP16 = 17,
	UVM_HOPPER_GPC_UTLB_ID_LTP17 = 18,
	UVM_HOPPER_GPC_UTLB_COUNT = 19,
};

enum {
	UVM_KVMALLOC_LEAK_CHECK_NONE = 0,
	UVM_KVMALLOC_LEAK_CHECK_BYTES = 1,
	UVM_KVMALLOC_LEAK_CHECK_ORIGIN = 2,
	UVM_KVMALLOC_LEAK_CHECK_COUNT = 3,
};

enum {
	UVM_MMU_PTE_FLAGS_NONE = 0,
	UVM_MMU_PTE_FLAGS_CACHED = 1,
	UVM_MMU_PTE_FLAGS_ACCESS_COUNTERS_DISABLED = 2,
	UVM_MMU_PTE_FLAGS_MASK = 3,
};

enum {
	UVM_PASCAL_GPC_UTLB_ID_RGG = 0,
	UVM_PASCAL_GPC_UTLB_ID_LTP0 = 1,
	UVM_PASCAL_GPC_UTLB_ID_LTP1 = 2,
	UVM_PASCAL_GPC_UTLB_ID_LTP2 = 3,
	UVM_PASCAL_GPC_UTLB_ID_LTP3 = 4,
	UVM_PASCAL_GPC_UTLB_ID_LTP4 = 5,
	UVM_PASCAL_GPC_UTLB_COUNT = 6,
};

enum {
	UVM_TEST_ACCESS_COUNTER_RESET_MODE_ALL = 0,
	UVM_TEST_ACCESS_COUNTER_RESET_MODE_TARGETED = 1,
	UVM_TEST_ACCESS_COUNTER_RESET_MODE_MAX = 2,
};

enum {
	UVM_TEST_CHANNEL_STRESS_KEY_ROTATION_OPERATION_CPU_TO_GPU = 0,
	UVM_TEST_CHANNEL_STRESS_KEY_ROTATION_OPERATION_GPU_TO_CPU = 1,
	UVM_TEST_CHANNEL_STRESS_KEY_ROTATION_OPERATION_ROTATE = 2,
};

enum {
	UVM_TEST_CHANNEL_STRESS_MODE_NOOP_PUSH = 0,
	UVM_TEST_CHANNEL_STRESS_MODE_UPDATE_CHANNELS = 1,
	UVM_TEST_CHANNEL_STRESS_MODE_STREAM = 2,
	UVM_TEST_CHANNEL_STRESS_MODE_KEY_ROTATION = 3,
};

enum {
	UVM_TEST_CHUNK_SIZE_GET_USER_SIZE = 0,
};

enum {
	UVM_TEST_GET_RM_PTES_SINGLE_GPU = 0,
	UVM_TEST_GET_RM_PTES_MULTI_GPU_SUPPORTED = 1,
	UVM_TEST_GET_RM_PTES_MULTI_GPU_SLI_SUPPORTED = 2,
	UVM_TEST_GET_RM_PTES_MULTI_GPU_NOT_SUPPORTED = 3,
	UVM_TEST_GET_RM_PTES_MAX = 4,
};

enum {
	UVM_TEST_PAGEABLE_MEM_ACCESS_TYPE_NONE = 0,
	UVM_TEST_PAGEABLE_MEM_ACCESS_TYPE_MMU_NOTIFIER = 1,
	UVM_TEST_PAGEABLE_MEM_ACCESS_TYPE_HMM = 2,
	UVM_TEST_PAGEABLE_MEM_ACCESS_TYPE_ATS_KERNEL = 3,
	UVM_TEST_PAGEABLE_MEM_ACCESS_TYPE_ATS_DRIVER = 4,
	UVM_TEST_PAGEABLE_MEM_ACCESS_TYPE_COUNT = 5,
};

enum {
	UVM_TEST_PAGE_PREFETCH_POLICY_ENABLE = 0,
	UVM_TEST_PAGE_PREFETCH_POLICY_DISABLE = 1,
	UVM_TEST_PAGE_PREFETCH_POLICY_MAX = 2,
};

enum {
	UVM_TEST_PAGE_THRASHING_POLICY_ENABLE = 0,
	UVM_TEST_PAGE_THRASHING_POLICY_DISABLE = 1,
	UVM_TEST_PAGE_THRASHING_POLICY_MAX = 2,
};

enum {
	UVM_TEST_PREFETCH_FILTERING_MODE_FILTER_ALL = 0,
	UVM_TEST_PREFETCH_FILTERING_MODE_FILTER_NONE = 1,
};

enum {
	UVM_TEST_RANGE_SUBTYPE_INVALID = 0,
	UVM_TEST_RANGE_SUBTYPE_UVM = 1,
	UVM_TEST_RANGE_SUBTYPE_HMM = 2,
	UVM_TEST_RANGE_SUBTYPE_MAX = 3,
};

enum {
	UVM_TEST_READ_DUPLICATION_UNSET = 0,
	UVM_TEST_READ_DUPLICATION_ENABLED = 1,
	UVM_TEST_READ_DUPLICATION_DISABLED = 2,
	UVM_TEST_READ_DUPLICATION_MAX = 3,
};

enum {
	UVM_TEST_VA_RANGE_TYPE_INVALID = 0,
	UVM_TEST_VA_RANGE_TYPE_MANAGED = 1,
	UVM_TEST_VA_RANGE_TYPE_EXTERNAL = 2,
	UVM_TEST_VA_RANGE_TYPE_CHANNEL = 3,
	UVM_TEST_VA_RANGE_TYPE_SKED_REFLECTED = 4,
	UVM_TEST_VA_RANGE_TYPE_SEMAPHORE_POOL = 5,
	UVM_TEST_VA_RANGE_TYPE_DEVICE_P2P = 6,
	UVM_TEST_VA_RANGE_TYPE_MAX = 7,
};

enum {
	UVM_TURING_GPC_UTLB_ID_RGG = 0,
	UVM_TURING_GPC_UTLB_ID_LTP0 = 1,
	UVM_TURING_GPC_UTLB_ID_LTP1 = 2,
	UVM_TURING_GPC_UTLB_ID_LTP2 = 3,
	UVM_TURING_GPC_UTLB_ID_LTP3 = 4,
	UVM_TURING_GPC_UTLB_ID_LTP4 = 5,
	UVM_TURING_GPC_UTLB_ID_LTP5 = 6,
	UVM_TURING_GPC_UTLB_ID_LTP6 = 7,
	UVM_TURING_GPC_UTLB_ID_LTP7 = 8,
	UVM_TURING_GPC_UTLB_COUNT = 9,
};

enum {
	UVM_VOLTA_GPC_UTLB_ID_RGG = 0,
	UVM_VOLTA_GPC_UTLB_ID_LTP0 = 1,
	UVM_VOLTA_GPC_UTLB_ID_LTP1 = 2,
	UVM_VOLTA_GPC_UTLB_ID_LTP2 = 3,
	UVM_VOLTA_GPC_UTLB_ID_LTP3 = 4,
	UVM_VOLTA_GPC_UTLB_ID_LTP4 = 5,
	UVM_VOLTA_GPC_UTLB_ID_LTP5 = 6,
	UVM_VOLTA_GPC_UTLB_ID_LTP6 = 7,
	UVM_VOLTA_GPC_UTLB_ID_LTP7 = 8,
	UVM_VOLTA_GPC_UTLB_COUNT = 9,
};

enum {
	UvmInvalidatePageTableLevelAll = 1,
	UvmInvalidatePageTableLevelPte = 2,
	UvmInvalidatePageTableLevelPde0 = 3,
	UvmInvalidatePageTableLevelPde1 = 4,
	UvmInvalidatePageTableLevelPde2 = 5,
	UvmInvalidatePageTableLevelPde3 = 6,
	UvmInvalidatePageTableLevelPde4 = 7,
};

enum {
	UvmInvalidateTlbMemBarNone = 1,
	UvmInvalidateTlbMemBarSys = 2,
	UvmInvalidateTlbMemBarLocal = 3,
};

enum {
	UvmTargetVaModeAll = 1,
	UvmTargetVaModeTargeted = 2,
};

enum {
	UvmTestEvictModeDefault = 1,
	UvmTestEvictModeVirtual = 2,
	UvmTestEvictModePhysical = 3,
};

typedef enum {
	UVM_ACCESS_COUNTER_GRANULARITY_64K = 1,
	UVM_ACCESS_COUNTER_GRANULARITY_2M = 2,
	UVM_ACCESS_COUNTER_GRANULARITY_16M = 3,
	UVM_ACCESS_COUNTER_GRANULARITY_16G = 4,
} UVM_ACCESS_COUNTER_GRANULARITY;

typedef enum {
	UVM_BUFFER_LOCATION_DEFAULT = 0,
	UVM_BUFFER_LOCATION_SYS = 1,
	UVM_BUFFER_LOCATION_VID = 2,
} UVM_BUFFER_LOCATION;

typedef enum {
	UVM_GPU_CHANNEL_ENGINE_TYPE_GR = 1,
	UVM_GPU_CHANNEL_ENGINE_TYPE_CE = 2,
	UVM_GPU_CHANNEL_ENGINE_TYPE_SEC2 = 3,
} UVM_GPU_CHANNEL_ENGINE_TYPE;

typedef enum {
	UVM_LINK_TYPE_NONE = 0,
	UVM_LINK_TYPE_PCIE = 1,
	UVM_LINK_TYPE_NVLINK_1 = 2,
	UVM_LINK_TYPE_NVLINK_2 = 3,
	UVM_LINK_TYPE_NVLINK_3 = 4,
	UVM_LINK_TYPE_NVLINK_4 = 5,
	UVM_LINK_TYPE_NVLINK_5 = 6,
	UVM_LINK_TYPE_C2C = 7,
} UVM_LINK_TYPE;

typedef enum {
	UVM_TEST_NVLINK_ERROR_NONE = 0,
	UVM_TEST_NVLINK_ERROR_UNRESOLVED = 1,
	UVM_TEST_NVLINK_ERROR_RESOLVED = 2,
} UVM_TEST_NVLINK_ERROR_TYPE;

typedef enum {
	UVM_TEST_PTE_MAPPING_INVALID = 0,
	UVM_TEST_PTE_MAPPING_READ_ONLY = 1,
	UVM_TEST_PTE_MAPPING_READ_WRITE = 2,
	UVM_TEST_PTE_MAPPING_READ_WRITE_ATOMIC = 3,
	UVM_TEST_PTE_MAPPING_MAX = 4,
} UVM_TEST_PTE_MAPPING;

typedef enum {
	UVM_VIRT_MODE_NONE = 0,
	UVM_VIRT_MODE_LEGACY = 1,
	UVM_VIRT_MODE_SRIOV_HEAVY = 2,
	UVM_VIRT_MODE_SRIOV_STANDARD = 3,
	UVM_VIRT_MODE_COUNT = 4,
} UVM_VIRT_MODE;

typedef enum {
	UvmCounterNameBytesXferHtD = 0,
	UvmCounterNameBytesXferDtH = 1,
	UvmCounterNameCpuPageFaultCount = 2,
	UvmCounterNamePrefetchBytesXferHtD = 7,
	UvmCounterNamePrefetchBytesXferDtH = 8,
	UvmCounterNameGpuPageFaultCount = 9,
	UVM_TOTAL_COUNTERS = 10,
} UvmCounterName;

typedef enum {
	UvmEventAperturePeer0 = 1,
	UvmEventAperturePeer1 = 2,
	UvmEventAperturePeer2 = 3,
	UvmEventAperturePeer3 = 4,
	UvmEventAperturePeer4 = 5,
	UvmEventAperturePeer5 = 6,
	UvmEventAperturePeer6 = 7,
	UvmEventAperturePeer7 = 8,
	UvmEventAperturePeerMax = 8,
	UvmEventApertureSys = 9,
	UvmEventApertureVid = 10,
} UvmEventApertureType;

typedef enum {
	UvmEventFatalReasonInvalid = 0,
	UvmEventFatalReasonInvalidAddress = 1,
	UvmEventFatalReasonInvalidPermissions = 2,
	UvmEventFatalReasonInvalidFaultType = 3,
	UvmEventFatalReasonOutOfMemory = 4,
	UvmEventFatalReasonInternalError = 5,
	UvmEventFatalReasonInvalidOperation = 6,
	UvmEventNumFatalReasons = 7,
} UvmEventFatalReason;

typedef enum {
	UvmEventFaultClientTypeInvalid = 0,
	UvmEventFaultClientTypeGpc = 1,
	UvmEventFaultClientTypeHub = 2,
	UvmEventNumFaultClientTypes = 3,
} UvmEventFaultClientType;

typedef enum {
	UvmFaultTypeInvalid = 0,
	UvmFaultTypeInvalidPde = 1,
	UvmFaultTypeInvalidPte = 2,
	UvmFaultTypeWrite = 3,
	UvmFaultTypeAtomic = 4,
	UvmFaultTypeFatal = 5,
	UvmFaultTypeInvalidPdeSize = 5,
	UvmFaultTypeLimitViolation = 6,
	UvmFaultTypeUnboundInstBlock = 7,
	UvmFaultTypePrivViolation = 8,
	UvmFaultTypePitchMaskViolation = 9,
	UvmFaultTypeWorkCreation = 10,
	UvmFaultTypeUnsupportedAperture = 11,
	UvmFaultTypeCompressionFailure = 12,
	UvmFaultTypeUnsupportedKind = 13,
	UvmFaultTypeRegionViolation = 14,
	UvmFaultTypePoison = 15,
	UvmFaultTypeCcViolation = 16,
	UvmEventNumFaultTypes = 17,
} UvmEventFaultType;

typedef enum {
	UvmEventMapRemoteCauseInvalid = 0,
	UvmEventMapRemoteCauseCoherence = 1,
	UvmEventMapRemoteCauseThrashing = 2,
	UvmEventMapRemoteCausePolicy = 3,
	UvmEventMapRemoteCauseOutOfMemory = 4,
	UvmEventMapRemoteCauseEviction = 5,
} UvmEventMapRemoteCause;

typedef enum {
	UvmEventMemoryAccessTypeInvalid = 0,
	UvmEventMemoryAccessTypeRead = 1,
	UvmEventMemoryAccessTypeWrite = 2,
	UvmEventMemoryAccessTypeAtomic = 3,
	UvmEventMemoryAccessTypePrefetch = 4,
	UvmEventNumMemoryAccessTypes = 5,
} UvmEventMemoryAccessType;

typedef enum {
	UvmEventMigrationCauseInvalid = 0,
	UvmEventMigrationCauseUser = 1,
	UvmEventMigrationCauseCoherence = 2,
	UvmEventMigrationCausePrefetch = 3,
	UvmEventMigrationCauseEviction = 4,
	UvmEventMigrationCauseAccessCounters = 5,
	UvmEventNumMigrationCauses = 6,
} UvmEventMigrationCause;

typedef enum {
	UvmEventTypeInvalid = 0,
	UvmEventTypeMemoryViolation = 1,
	UvmEventTypeCpuFault = 1,
	UvmEventTypeMigration = 2,
	UvmEventTypeGpuFault = 3,
	UvmEventTypeGpuFaultReplay = 4,
	UvmEventTypeFaultBufferOverflow = 5,
	UvmEventTypeFatalFault = 6,
	UvmEventTypeReadDuplicate = 7,
	UvmEventTypeReadDuplicateInvalidate = 8,
	UvmEventTypePageSizeChange = 9,
	UvmEventTypeThrashingDetected = 10,
	UvmEventTypeThrottlingStart = 11,
	UvmEventTypeThrottlingEnd = 12,
	UvmEventTypeMapRemote = 13,
	UvmEventTypeEviction = 14,
	UvmEventNumTypes = 15,
	UvmEventTestTypesFirst = 62,
	UvmEventTypeTestHmmSplitInvalidate = 62,
	UvmEventTypeTestAccessCounter = 63,
	UvmEventTestTypesLast = 63,
	UvmEventNumTypesAll = 64,
} UvmEventType;

typedef enum {
	UvmGpuCachingTypeDefault = 0,
	UvmGpuCachingTypeForceUncached = 1,
	UvmGpuCachingTypeForceCached = 2,
	UvmGpuCachingTypeCount = 3,
} UvmGpuCachingType;

typedef enum {
	UvmGpuCompressionTypeDefault = 0,
	UvmGpuCompressionTypeEnabledNoPlc = 1,
	UvmGpuCompressionTypeCount = 2,
} UvmGpuCompressionType;

typedef enum {
	UvmGpuFormatElementBitsDefault = 0,
	UvmGpuFormatElementBits8 = 1,
	UvmGpuFormatElementBits16 = 2,
	UvmGpuFormatElementBits32 = 4,
	UvmGpuFormatElementBits64 = 5,
	UvmGpuFormatElementBits128 = 6,
	UvmGpuFormatElementBitsCount = 7,
} UvmGpuFormatElementBits;

typedef enum {
	UvmGpuFormatTypeDefault = 0,
	UvmGpuFormatTypeBlockLinear = 1,
	UvmGpuFormatTypeCount = 2,
} UvmGpuFormatType;

typedef enum {
	UvmGpuMappingTypeDefault = 0,
	UvmGpuMappingTypeReadWriteAtomic = 1,
	UvmGpuMappingTypeReadWrite = 2,
	UvmGpuMappingTypeReadOnly = 3,
	UvmGpuMappingTypeCount = 4,
} UvmGpuMappingType;

typedef enum {
	UvmRmGpuCachingTypeDefault = 0,
	UvmRmGpuCachingTypeForceUncached = 1,
	UvmRmGpuCachingTypeForceCached = 2,
	UvmRmGpuCachingTypeCount = 3,
} UvmRmGpuCachingType;

typedef enum {
	UvmRmGpuCompressionTypeDefault = 0,
	UvmRmGpuCompressionTypeEnabledNoPlc = 1,
	UvmRmGpuCompressionTypeCount = 2,
} UvmRmGpuCompressionType;

typedef enum {
	UvmRmGpuFormatElementBitsDefault = 0,
	UvmRmGpuFormatElementBits8 = 1,
	UvmRmGpuFormatElementBits16 = 2,
	UvmRmGpuFormatElementBits32 = 4,
	UvmRmGpuFormatElementBits64 = 5,
	UvmRmGpuFormatElementBits128 = 6,
	UvmRmGpuFormatElementBitsCount = 7,
} UvmRmGpuFormatElementBits;

typedef enum {
	UvmRmGpuFormatTypeDefault = 0,
	UvmRmGpuFormatTypeBlockLinear = 1,
	UvmRmGpuFormatTypeCount = 2,
} UvmRmGpuFormatType;

typedef enum {
	UvmRmGpuMappingTypeDefault = 0,
	UvmRmGpuMappingTypeReadWriteAtomic = 1,
	UvmRmGpuMappingTypeReadWrite = 2,
	UvmRmGpuMappingTypeReadOnly = 3,
	UvmRmGpuMappingTypeCount = 4,
} UvmRmGpuMappingType;

typedef enum {
	UvmTestDeferredWorkTypeAcessedByMappings = 1,
} UvmTestDeferredWorkType;

typedef enum {
	UvmTestPmmSanityModeFull = 1,
	UvmTestPmmSanityModeBasic = 2,
} UvmTestPmmSanityMode;

typedef enum {
	ALLOC_TYPE_MALLOC = 0,
	ALLOC_TYPE_ZALLOC = 1,
	ALLOC_TYPE_REALLOC_NULL = 2,
	ALLOC_TYPE_REALLOC_ZERO = 3,
	ALLOC_TYPE_MAX = 4,
} alloc_type_t;

typedef enum {
	BASIC_TEST_FREE_PATTERN_IMMEDIATE = 0,
	BASIC_TEST_FREE_PATTERN_ALL_FORWARD = 1,
	BASIC_TEST_FREE_PATTERN_ALL_REVERSE = 2,
	BASIC_TEST_FREE_PATTERN_EVERY_N = 3,
	BASIC_TEST_FREE_PATTERN_COUNT = 4,
} basic_test_free_pattern_t;

typedef enum {
	BLOCK_PTE_OP_MAP = 0,
	BLOCK_PTE_OP_REVOKE = 1,
	BLOCK_PTE_OP_COUNT = 2,
} block_pte_op_t;

typedef enum {
	CHUNK_WALK_PRE_ORDER = 0,
	CHUNK_WALK_POST_ORDER = 1,
} chunk_walk_order_t;

typedef enum {
	FAULT_FETCH_MODE_BATCH_READY = 0,
	FAULT_FETCH_MODE_ALL = 1,
} fault_fetch_mode_t;

typedef enum {
	FAULT_SERVICE_MODE_REGULAR = 0,
	FAULT_SERVICE_MODE_CANCEL = 1,
} fault_service_mode_t;

typedef enum {
	FREE_ROOT_CHUNK_MODE_DEFAULT = 0,
	FREE_ROOT_CHUNK_MODE_PMA_EVICTION = 1,
	FREE_ROOT_CHUNK_MODE_SKIP_PMA_FREE = 2,
} free_root_chunk_mode_t;

typedef enum {
	HW_FAULT_BUFFER_FLUSH_MODE_DISCARD = 0,
	HW_FAULT_BUFFER_FLUSH_MODE_MOVE = 1,
} hw_fault_buffer_flush_mode_t;

typedef enum {
	MEM_ALLOC_TYPE_SYSMEM_DMA = 0,
	MEM_ALLOC_TYPE_SYSMEM_PROTECTED = 1,
	MEM_ALLOC_TYPE_VIDMEM_PROTECTED = 2,
} mem_alloc_type_t;

typedef enum {
	NOTIFICATION_FETCH_MODE_BATCH_READY = 0,
	NOTIFICATION_FETCH_MODE_ALL = 1,
} notification_fetch_mode_t;

typedef enum {
	PDE_TYPE_SINGLE = 0,
	PDE_TYPE_DUAL_BIG = 1,
	PDE_TYPE_DUAL_SMALL = 2,
	PDE_TYPE_COUNT = 3,
} pde_type_t;

typedef enum {
	RBTT_OP_ADD = 0,
	RBTT_OP_REMOVE = 1,
	RBTT_OP_COUNT = 2,
} rbtt_test_op_t;

typedef enum {
	REMOTE_EGM_ALLOWED = 0,
	REMOTE_EGM_NOT_ALLOWED = 1,
} remote_egm_mode_t;

typedef enum {
	RTT_OP_ADD = 0,
	RTT_OP_REMOVE = 1,
	RTT_OP_SPLIT = 2,
	RTT_OP_MERGE = 3,
	RTT_OP_SHRINK = 4,
	RTT_OP_MAX = 5,
} rtt_op_t;

typedef enum {
	SPLIT_TEST_MODE_NORMAL = 0,
	SPLIT_TEST_MODE_MERGE = 1,
	SPLIT_TEST_MODE_INJECT_ERROR = 2,
	SPLIT_TEST_MODE_COUNT = 3,
} split_test_mode_t;

typedef enum {
	UVM_ACCESS_COUNTER_CLEAR_OP_NONE = 0,
	UVM_ACCESS_COUNTER_CLEAR_OP_TARGETED = 1,
	UVM_ACCESS_COUNTER_CLEAR_OP_ALL = 2,
} uvm_access_counter_clear_op_t;

typedef enum {
	UVM_APERTURE_PEER_0 = 0,
	UVM_APERTURE_PEER_1 = 1,
	UVM_APERTURE_PEER_2 = 2,
	UVM_APERTURE_PEER_3 = 3,
	UVM_APERTURE_PEER_4 = 4,
	UVM_APERTURE_PEER_5 = 5,
	UVM_APERTURE_PEER_6 = 6,
	UVM_APERTURE_PEER_7 = 7,
	UVM_APERTURE_PEER_MAX = 8,
	UVM_APERTURE_SYS = 9,
	UVM_APERTURE_VID = 10,
	UVM_APERTURE_DEFAULT = 11,
	UVM_APERTURE_MAX = 12,
} uvm_aperture_t;

typedef enum {
	UVM_API_RANGE_TYPE_MANAGED = 0,
	UVM_API_RANGE_TYPE_HMM = 1,
	UVM_API_RANGE_TYPE_ATS = 2,
	UVM_API_RANGE_TYPE_INVALID = 3,
} uvm_api_range_type_t;

typedef enum {
	UVM_ATS_SERVICE_TYPE_FAULTS = 0,
	UVM_ATS_SERVICE_TYPE_ACCESS_COUNTERS = 1,
	UVM_ATS_SERVICE_TYPE_COUNT = 2,
} uvm_ats_service_type_t;

typedef enum {
	UVM_CHANNEL_POOL_TYPE_CE = 1,
	UVM_CHANNEL_POOL_TYPE_CE_PROXY = 2,
	UVM_CHANNEL_POOL_TYPE_SEC2 = 4,
	UVM_CHANNEL_POOL_TYPE_WLC = 8,
	UVM_CHANNEL_POOL_TYPE_LCIC = 16,
	UVM_CHANNEL_POOL_TYPE_COUNT = 5,
	UVM_CHANNEL_POOL_TYPE_MASK = 31,
} uvm_channel_pool_type_t;

typedef enum {
	UVM_CHANNEL_RESERVE_WITH_P2P = 0,
	UVM_CHANNEL_RESERVE_NO_P2P = 1,
} uvm_channel_reserve_type_t;

typedef enum {
	UVM_CHANNEL_TYPE_CPU_TO_GPU = 0,
	UVM_CHANNEL_TYPE_GPU_TO_CPU = 1,
	UVM_CHANNEL_TYPE_GPU_INTERNAL = 2,
	UVM_CHANNEL_TYPE_MEMOPS = 3,
	UVM_CHANNEL_TYPE_GPU_TO_GPU = 4,
	UVM_CHANNEL_TYPE_CE_COUNT = 5,
	UVM_CHANNEL_TYPE_SEC2 = 5,
	UVM_CHANNEL_TYPE_WLC = 6,
	UVM_CHANNEL_TYPE_LCIC = 7,
	UVM_CHANNEL_TYPE_COUNT = 8,
} uvm_channel_type_t;

typedef enum {
	UVM_CHANNEL_UPDATE_MODE_COMPLETED = 0,
	UVM_CHANNEL_UPDATE_MODE_FORCE_ALL = 1,
} uvm_channel_update_mode_t;

typedef enum {
	UVM_CHUNK_SIZE_1 = 1,
	UVM_CHUNK_SIZE_2 = 2,
	UVM_CHUNK_SIZE_4 = 4,
	UVM_CHUNK_SIZE_8 = 8,
	UVM_CHUNK_SIZE_16 = 16,
	UVM_CHUNK_SIZE_32 = 32,
	UVM_CHUNK_SIZE_64 = 64,
	UVM_CHUNK_SIZE_128 = 128,
	UVM_CHUNK_SIZE_256 = 256,
	UVM_CHUNK_SIZE_512 = 512,
	UVM_CHUNK_SIZE_1K = 1024,
	UVM_CHUNK_SIZE_2K = 2048,
	UVM_CHUNK_SIZE_4K = 4096,
	UVM_CHUNK_SIZE_8K = 8192,
	UVM_CHUNK_SIZE_16K = 16384,
	UVM_CHUNK_SIZE_32K = 32768,
	UVM_CHUNK_SIZE_64K = 65536,
	UVM_CHUNK_SIZE_128K = 131072,
	UVM_CHUNK_SIZE_256K = 262144,
	UVM_CHUNK_SIZE_512K = 524288,
	UVM_CHUNK_SIZE_1M = 1048576,
	UVM_CHUNK_SIZE_2M = 2097152,
	UVM_CHUNK_SIZE_MAX = 2097152,
	UVM_CHUNK_SIZE_INVALID = 4194304,
} uvm_chunk_size_t;

typedef uvm_chunk_size_t uvm_chunk_sizes_mask_t;

typedef enum {
	UVM_CPU_CHUNK_ALLOC_FLAGS_NONE = 0,
	UVM_CPU_CHUNK_ALLOC_FLAGS_ZERO = 1,
	UVM_CPU_CHUNK_ALLOC_FLAGS_ACCOUNT = 2,
	UVM_CPU_CHUNK_ALLOC_FLAGS_STRICT = 4,
	UVM_CPU_CHUNK_ALLOC_FLAGS_ALLOW_MOVABLE = 8,
} uvm_cpu_chunk_alloc_flags_t;

typedef enum {
	UVM_CPU_CHUNK_STORAGE_CHUNK = 0,
	UVM_CPU_CHUNK_STORAGE_MIXED = 1,
	UVM_CPU_CHUNK_STORAGE_COUNT = 2,
} uvm_cpu_chunk_storage_type_t;

typedef enum {
	UVM_CPU_CHUNK_TYPE_PHYSICAL = 0,
	UVM_CPU_CHUNK_TYPE_LOGICAL = 1,
	UVM_CPU_CHUNK_TYPE_HMM = 2,
} uvm_cpu_chunk_type_t;

typedef enum {
	UVM_DEFERRED_FREE_OBJECT_TYPE_CHANNEL = 0,
	UVM_DEFERRED_FREE_OBJECT_GPU_VA_SPACE = 1,
	UVM_DEFERRED_FREE_OBJECT_TYPE_EXTERNAL_ALLOCATION = 2,
	UVM_DEFERRED_FREE_OBJECT_TYPE_DEVICE_P2P_MEM = 3,
	UVM_DEFERRED_FREE_OBJECT_TYPE_COUNT = 4,
} uvm_deferred_free_object_type_t;

typedef enum {
	UVM_FAULT_ACCESS_TYPE_PREFETCH = 0,
	UVM_FAULT_ACCESS_TYPE_READ = 1,
	UVM_FAULT_ACCESS_TYPE_WRITE = 2,
	UVM_FAULT_ACCESS_TYPE_ATOMIC_WEAK = 3,
	UVM_FAULT_ACCESS_TYPE_ATOMIC_STRONG = 4,
	UVM_FAULT_ACCESS_TYPE_COUNT = 5,
} uvm_fault_access_type_t;

typedef enum {
	UVM_FAULT_CANCEL_VA_MODE_ALL = 0,
	UVM_FAULT_CANCEL_VA_MODE_WRITE_AND_ATOMIC = 1,
	UVM_FAULT_CANCEL_VA_MODE_COUNT = 2,
} uvm_fault_cancel_va_mode_t;

typedef enum {
	UVM_FAULT_CLIENT_TYPE_GPC = 0,
	UVM_FAULT_CLIENT_TYPE_HUB = 1,
	UVM_FAULT_CLIENT_TYPE_COUNT = 2,
} uvm_fault_client_type_t;

typedef enum {
	UVM_FAULT_REPLAY_TYPE_START = 0,
	UVM_FAULT_REPLAY_TYPE_START_ACK_ALL = 1,
	UVM_FAULT_REPLAY_TYPE_MAX = 2,
} uvm_fault_replay_type_t;

typedef enum {
	UVM_FAULT_TYPE_INVALID_PDE = 0,
	UVM_FAULT_TYPE_INVALID_PTE = 1,
	UVM_FAULT_TYPE_ATOMIC = 2,
	UVM_FAULT_TYPE_WRITE = 3,
	UVM_FAULT_TYPE_READ = 4,
	UVM_FAULT_TYPE_FATAL = 5,
	UVM_FAULT_TYPE_PDE_SIZE = 5,
	UVM_FAULT_TYPE_VA_LIMIT_VIOLATION = 6,
	UVM_FAULT_TYPE_UNBOUND_INST_BLOCK = 7,
	UVM_FAULT_TYPE_PRIV_VIOLATION = 8,
	UVM_FAULT_TYPE_PITCH_MASK_VIOLATION = 9,
	UVM_FAULT_TYPE_WORK_CREATION = 10,
	UVM_FAULT_TYPE_UNSUPPORTED_APERTURE = 11,
	UVM_FAULT_TYPE_COMPRESSION_FAILURE = 12,
	UVM_FAULT_TYPE_UNSUPPORTED_KIND = 13,
	UVM_FAULT_TYPE_REGION_VIOLATION = 14,
	UVM_FAULT_TYPE_POISONED = 15,
	UVM_FAULT_TYPE_CC_VIOLATION = 16,
	UVM_FAULT_TYPE_COUNT = 17,
} uvm_fault_type_t;

typedef enum {
	UVM_FD_UNINITIALIZED = 0,
	UVM_FD_INITIALIZING = 1,
	UVM_FD_VA_SPACE = 2,
	UVM_FD_MM = 3,
	UVM_FD_TEST = 4,
	UVM_FD_COUNT = 5,
} uvm_fd_type_t;

typedef enum {
	UVM_GPFIFO_ENTRY_TYPE_NORMAL = 0,
	UVM_GPFIFO_ENTRY_TYPE_CONTROL = 1,
} uvm_gpfifo_entry_type_t;

typedef enum {
	UVM_GPFIFO_SYNC_PROCEED = 0,
	UVM_GPFIFO_SYNC_WAIT = 1,
} uvm_gpfifo_sync_t;

typedef enum {
	UVM_GPU_BUFFER_FLUSH_MODE_CACHED_PUT = 0,
	UVM_GPU_BUFFER_FLUSH_MODE_UPDATE_PUT = 1,
	UVM_GPU_BUFFER_FLUSH_MODE_WAIT_UPDATE_PUT = 2,
} uvm_gpu_buffer_flush_mode_t;

typedef enum {
	UVM_GPU_LINK_INVALID = 0,
	UVM_GPU_LINK_PCIE = 1,
	UVM_GPU_LINK_NVLINK_1 = 2,
	UVM_GPU_LINK_NVLINK_2 = 3,
	UVM_GPU_LINK_NVLINK_3 = 4,
	UVM_GPU_LINK_NVLINK_4 = 5,
	UVM_GPU_LINK_NVLINK_5 = 6,
	UVM_GPU_LINK_C2C = 7,
	UVM_GPU_LINK_MAX = 8,
} uvm_gpu_link_type_t;

typedef enum {
	UVM_GPU_PEER_COPY_MODE_UNSUPPORTED = 0,
	UVM_GPU_PEER_COPY_MODE_VIRTUAL = 1,
	UVM_GPU_PEER_COPY_MODE_PHYSICAL = 2,
	UVM_GPU_PEER_COPY_MODE_COUNT = 3,
} uvm_gpu_peer_copy_mode_t;

typedef enum {
	UVM_GPU_VA_SPACE_STATE_INIT = 0,
	UVM_GPU_VA_SPACE_STATE_ACTIVE = 1,
	UVM_GPU_VA_SPACE_STATE_DEAD = 2,
	UVM_GPU_VA_SPACE_STATE_COUNT = 3,
} uvm_gpu_va_space_state_t;

typedef enum {
	UVM_LOCK_FLAGS_INVALID = 0,
	UVM_LOCK_FLAGS_MODE_EXCLUSIVE = 1,
	UVM_LOCK_FLAGS_MODE_SHARED = 2,
	UVM_LOCK_FLAGS_MODE_ANY = 3,
	UVM_LOCK_FLAGS_MODE_MASK = 3,
	UVM_LOCK_FLAGS_OUT_OF_ORDER = 4,
	UVM_LOCK_FLAGS_TRYLOCK = 8,
	UVM_LOCK_FLAGS_MASK = 15,
} uvm_lock_flags_t;

typedef enum {
	UVM_LOCK_ORDER_INVALID = 0,
	UVM_LOCK_ORDER_GLOBAL_PM = 1,
	UVM_LOCK_ORDER_GLOBAL = 2,
	UVM_LOCK_ORDER_ACCESS_COUNTERS = 3,
	UVM_LOCK_ORDER_ISR = 4,
	UVM_LOCK_ORDER_MMAP_LOCK = 5,
	UVM_LOCK_ORDER_VA_SPACES_LIST = 6,
	UVM_LOCK_ORDER_VA_SPACE_SERIALIZE_WRITERS = 7,
	UVM_LOCK_ORDER_VA_SPACE_READ_ACQUIRE_WRITE_RELEASE_LOCK = 8,
	UVM_LOCK_ORDER_VA_SPACE = 9,
	UVM_LOCK_ORDER_EXT_RANGE_TREE = 10,
	UVM_LOCK_ORDER_GPU_SEMAPHORE_POOL = 11,
	UVM_LOCK_ORDER_RM_API = 12,
	UVM_LOCK_ORDER_RM_GPUS = 13,
	UVM_LOCK_ORDER_VA_BLOCK_MIGRATE = 14,
	UVM_LOCK_ORDER_VA_BLOCK = 15,
	UVM_LOCK_ORDER_CONF_COMPUTING_DMA_BUFFER_POOL = 16,
	UVM_LOCK_ORDER_CHUNK_MAPPING = 17,
	UVM_LOCK_ORDER_PAGE_TREE = 18,
	UVM_LOCK_ORDER_KEY_ROTATION = 19,
	UVM_LOCK_ORDER_CSL_PUSH = 20,
	UVM_LOCK_ORDER_KEY_ROTATION_WLC = 21,
	UVM_LOCK_ORDER_CSL_WLC_PUSH = 22,
	UVM_LOCK_ORDER_CSL_SEC2_PUSH = 23,
	UVM_LOCK_ORDER_PUSH = 24,
	UVM_LOCK_ORDER_PMM = 25,
	UVM_LOCK_ORDER_PMM_PMA = 26,
	UVM_LOCK_ORDER_PMM_ROOT_CHUNK = 27,
	UVM_LOCK_ACCESS_COUNTERS_CLEAR_OPS = 28,
	UVM_LOCK_ORDER_CHANNEL = 29,
	UVM_LOCK_ORDER_WLC_CHANNEL = 30,
	UVM_LOCK_ORDER_TOOLS_VA_SPACE_LIST = 31,
	UVM_LOCK_ORDER_VA_SPACE_EVENTS = 32,
	UVM_LOCK_ORDER_VA_SPACE_TOOLS = 33,
	UVM_LOCK_ORDER_SEMA_POOL_TRACKER = 34,
	UVM_LOCK_ORDER_SECURE_SEMAPHORE = 35,
	UVM_LOCK_ORDER_CSL_CTX = 36,
	UVM_LOCK_ORDER_LEAF = 37,
	UVM_LOCK_ORDER_COUNT = 38,
} uvm_lock_order_t;

typedef enum {
	UVM_MAKE_RESIDENT_CAUSE_REPLAYABLE_FAULT = 0,
	UVM_MAKE_RESIDENT_CAUSE_NON_REPLAYABLE_FAULT = 1,
	UVM_MAKE_RESIDENT_CAUSE_ACCESS_COUNTER = 2,
	UVM_MAKE_RESIDENT_CAUSE_PREFETCH = 3,
	UVM_MAKE_RESIDENT_CAUSE_EVICTION = 4,
	UVM_MAKE_RESIDENT_CAUSE_API_TOOLS = 5,
	UVM_MAKE_RESIDENT_CAUSE_API_MIGRATE = 6,
	UVM_MAKE_RESIDENT_CAUSE_API_SET_RANGE_GROUP = 7,
	UVM_MAKE_RESIDENT_CAUSE_API_HINT = 8,
	UVM_MAKE_RESIDENT_CAUSE_MAX = 9,
} uvm_make_resident_cause_t;

typedef enum {
	UVM_MEMBAR_NONE = 0,
	UVM_MEMBAR_GPU = 1,
	UVM_MEMBAR_SYS = 2,
} uvm_membar_t;

typedef enum {
	UVM_MIGRATE_MODE_MAKE_RESIDENT = 0,
	UVM_MIGRATE_MODE_MAKE_RESIDENT_AND_MAP = 1,
} uvm_migrate_mode_t;

typedef enum {
	UVM_MIGRATE_PASS_FIRST = 0,
	UVM_MIGRATE_PASS_SECOND = 1,
} uvm_migrate_pass_t;

typedef enum {
	UVM_MMU_ENGINE_TYPE_GRAPHICS = 0,
	UVM_MMU_ENGINE_TYPE_HOST = 1,
	UVM_MMU_ENGINE_TYPE_CE = 2,
	UVM_MMU_ENGINE_TYPE_COUNT = 3,
} uvm_mmu_engine_type_t;

typedef enum {
	UVM_PAGE_TREE_TYPE_USER = 0,
	UVM_PAGE_TREE_TYPE_KERNEL = 1,
	UVM_PAGE_TREE_TYPE_COUNT = 2,
} uvm_page_tree_type_t;

typedef enum {
	UVM_PERF_EVENT_BLOCK_DESTROY = 0,
	UVM_PERF_EVENT_BLOCK_SHRINK = 1,
	UVM_PERF_EVENT_BLOCK_MUNMAP = 2,
	UVM_PERF_EVENT_RANGE_DESTROY = 3,
	UVM_PERF_EVENT_RANGE_SHRINK = 4,
	UVM_PERF_EVENT_MODULE_UNLOAD = 5,
	UVM_PERF_EVENT_FAULT = 6,
	UVM_PERF_EVENT_MIGRATION = 7,
	UVM_PERF_EVENT_REVOCATION = 8,
	UVM_PERF_EVENT_COUNT = 9,
} uvm_perf_event_t;

typedef enum {
	UVM_PERF_FAULT_REPLAY_POLICY_BLOCK = 0,
	UVM_PERF_FAULT_REPLAY_POLICY_BATCH = 1,
	UVM_PERF_FAULT_REPLAY_POLICY_BATCH_FLUSH = 2,
	UVM_PERF_FAULT_REPLAY_POLICY_ONCE = 3,
	UVM_PERF_FAULT_REPLAY_POLICY_MAX = 4,
} uvm_perf_fault_replay_policy_t;

typedef enum {
	UVM_PERF_MODULE_FIRST_TYPE = 0,
	UVM_PERF_MODULE_TYPE_TEST = 0,
	UVM_PERF_MODULE_TYPE_THRASHING = 1,
	UVM_PERF_MODULE_TYPE_ACCESS_COUNTERS = 2,
	UVM_PERF_MODULE_TYPE_COUNT = 3,
} uvm_perf_module_type_t;

typedef enum {
	UVM_PERF_THRASHING_HINT_TYPE_NONE = 0,
	UVM_PERF_THRASHING_HINT_TYPE_PIN = 1,
	UVM_PERF_THRASHING_HINT_TYPE_THROTTLE = 2,
} uvm_perf_thrashing_hint_type_t;

typedef enum {
	UVM_PMM_ALLOC_FLAGS_NONE = 0,
	UVM_PMM_ALLOC_FLAGS_EVICT = 1,
	UVM_PMM_ALLOC_FLAGS_DONT_BATCH = 2,
	UVM_PMM_ALLOC_FLAGS_MASK = 3,
} uvm_pmm_alloc_flags_t;

typedef enum {
	PMM_CONTEXT_DEFAULT = 0,
	PMM_CONTEXT_PMA_EVICTION = 1,
} uvm_pmm_context_t;

typedef enum {
	UVM_PMM_GPU_CHUNK_STATE_PMA_OWNED = 0,
	UVM_PMM_GPU_CHUNK_STATE_FREE = 1,
	UVM_PMM_GPU_CHUNK_STATE_IS_SPLIT = 2,
	UVM_PMM_GPU_CHUNK_STATE_TEMP_PINNED = 3,
	UVM_PMM_GPU_CHUNK_STATE_ALLOCATED = 4,
	UVM_PMM_GPU_CHUNK_STATE_COUNT = 5,
} uvm_pmm_gpu_chunk_state_t;

typedef enum {
	UVM_PMM_GPU_MEMORY_TYPE_USER = 0,
	UVM_PMM_GPU_MEMORY_TYPE_KERNEL = 1,
	UVM_PMM_GPU_MEMORY_TYPE_COUNT = 2,
} uvm_pmm_gpu_memory_type_t;

typedef enum {
	UVM_PMM_LIST_ZERO = 0,
	UVM_PMM_LIST_NO_ZERO = 1,
	UVM_PMM_LIST_ZERO_COUNT = 2,
} uvm_pmm_list_zero_t;

typedef enum {
	UVM_POPULATE_PERMISSIONS_INHERIT = 0,
	UVM_POPULATE_PERMISSIONS_ANY = 1,
	UVM_POPULATE_PERMISSIONS_WRITE = 2,
} uvm_populate_permissions_t;

typedef enum {
	UVM_PROT_NONE = 0,
	UVM_PROT_READ_ONLY = 1,
	UVM_PROT_READ_WRITE = 2,
	UVM_PROT_READ_WRITE_ATOMIC = 3,
	UVM_PROT_MAX = 4,
} uvm_prot_t;

typedef enum {
	UVM_PTE_BITS_CPU_READ = 0,
	UVM_PTE_BITS_CPU_WRITE = 1,
	UVM_PTE_BITS_CPU_MAX = 2,
} uvm_pte_bits_cpu_t;

typedef enum {
	UVM_PTE_BITS_GPU_READ = 0,
	UVM_PTE_BITS_GPU_WRITE = 1,
	UVM_PTE_BITS_GPU_ATOMIC = 2,
	UVM_PTE_BITS_GPU_MAX = 3,
} uvm_pte_bits_gpu_t;

typedef enum {
	UVM_PUSH_FLAG_CE_NEXT_PIPELINED = 0,
	UVM_PUSH_FLAG_NEXT_MEMBAR_NONE = 1,
	UVM_PUSH_FLAG_NEXT_MEMBAR_GPU = 2,
	UVM_PUSH_FLAG_COUNT = 3,
} uvm_push_flag_t;

typedef enum {
	UVM_READ_DUPLICATION_UNSET = 0,
	UVM_READ_DUPLICATION_ENABLED = 1,
	UVM_READ_DUPLICATION_DISABLED = 2,
	UVM_READ_DUPLICATION_MAX = 3,
} uvm_read_duplication_policy_t;

typedef enum {
	UVM_RM_MEM_TYPE_GPU = 0,
	UVM_RM_MEM_TYPE_SYS = 1,
} uvm_rm_mem_type_t;

typedef enum {
	UVM_SERVICE_OPERATION_REPLAYABLE_FAULTS = 0,
	UVM_SERVICE_OPERATION_NON_REPLAYABLE_FAULTS = 1,
	UVM_SERVICE_OPERATION_ACCESS_COUNTERS = 2,
} uvm_service_operation_t;

typedef enum {
	UVM_VA_BLOCK_TRANSFER_MODE_MOVE = 1,
	UVM_VA_BLOCK_TRANSFER_MODE_COPY = 2,
} uvm_va_block_transfer_mode_t;

typedef enum {
	UVM_VA_POLICY_PREFERRED_LOCATION = 0,
	UVM_VA_POLICY_ACCESSED_BY = 1,
	UVM_VA_POLICY_READ_DUPLICATION = 2,
} uvm_va_policy_type_t;

typedef enum {
	UVM_VA_RANGE_TYPE_INVALID = 0,
	UVM_VA_RANGE_TYPE_MANAGED = 1,
	UVM_VA_RANGE_TYPE_EXTERNAL = 2,
	UVM_VA_RANGE_TYPE_CHANNEL = 3,
	UVM_VA_RANGE_TYPE_SKED_REFLECTED = 4,
	UVM_VA_RANGE_TYPE_SEMAPHORE_POOL = 5,
	UVM_VA_RANGE_TYPE_DEVICE_P2P = 6,
	UVM_VA_RANGE_TYPE_MAX = 7,
} uvm_va_range_type_t;

typedef enum {
	UVM_VA_SPACE_MM_STATE_UNINITIALIZED = 0,
	UVM_VA_SPACE_MM_STATE_ALIVE = 1,
	UVM_VA_SPACE_MM_STATE_RELEASED = 2,
} uvm_va_space_mm_state_t;

enum UVM_KEY_ROTATION_STATUS {
	UVM_KEY_ROTATION_STATUS_IDLE = 0,
	UVM_KEY_ROTATION_STATUS_PENDING = 1,
	UVM_KEY_ROTATION_STATUS_IN_PROGRESS = 2,
	UVM_KEY_ROTATION_STATUS_FAILED_TIMEOUT = 3,
	UVM_KEY_ROTATION_STATUS_FAILED_THRESHOLD = 4,
	UVM_KEY_ROTATION_STATUS_FAILED_ROTATION = 5,
	UVM_KEY_ROTATION_STATUS_MAX_COUNT = 6,
};

enum UvmCslOperation {
	UVM_CSL_OPERATION_ENCRYPT = 0,
	UVM_CSL_OPERATION_DECRYPT = 1,
};

typedef enum UvmCslOperation UvmCslOperation;

enum UvmPmaGpuMemoryType_tag {
	UVM_PMA_GPU_MEMORY_TYPE_UNPROTECTED = 0,
	UVM_PMA_GPU_MEMORY_TYPE_PROTECTED = 1,
};

typedef enum UvmPmaGpuMemoryType_tag UVM_PMA_GPU_MEMORY_TYPE;

enum _TEGRASOC_WHICH_CLK {
	TEGRASOC_WHICH_CLK_NVDISPLAYHUB = 0,
	TEGRASOC_WHICH_CLK_NVDISPLAY_DISP = 1,
	TEGRASOC_WHICH_CLK_NVDISPLAY_P0 = 2,
	TEGRASOC_WHICH_CLK_NVDISPLAY_P1 = 3,
	TEGRASOC_WHICH_CLK_DPAUX0 = 4,
	TEGRASOC_WHICH_CLK_FUSE = 5,
	TEGRASOC_WHICH_CLK_DSIPLL_VCO = 6,
	TEGRASOC_WHICH_CLK_DSIPLL_CLKOUTPN = 7,
	TEGRASOC_WHICH_CLK_DSIPLL_CLKOUTA = 8,
	TEGRASOC_WHICH_CLK_SPPLL0_VCO = 9,
	TEGRASOC_WHICH_CLK_SPPLL0_CLKOUTA = 10,
	TEGRASOC_WHICH_CLK_SPPLL0_CLKOUTB = 11,
	TEGRASOC_WHICH_CLK_SPPLL0_CLKOUTPN = 12,
	TEGRASOC_WHICH_CLK_SPPLL1_CLKOUTPN = 13,
	TEGRASOC_WHICH_CLK_SPPLL0_DIV27 = 14,
	TEGRASOC_WHICH_CLK_SPPLL1_DIV27 = 15,
	TEGRASOC_WHICH_CLK_SPPLL0_DIV10 = 16,
	TEGRASOC_WHICH_CLK_SPPLL0_DIV25 = 17,
	TEGRASOC_WHICH_CLK_SPPLL1_VCO = 18,
	TEGRASOC_WHICH_CLK_VPLL0_REF = 19,
	TEGRASOC_WHICH_CLK_VPLL0 = 20,
	TEGRASOC_WHICH_CLK_VPLL1 = 21,
	TEGRASOC_WHICH_CLK_NVDISPLAY_P0_REF = 22,
	TEGRASOC_WHICH_CLK_RG0 = 23,
	TEGRASOC_WHICH_CLK_RG1 = 24,
	TEGRASOC_WHICH_CLK_DISPPLL = 25,
	TEGRASOC_WHICH_CLK_DISPHUBPLL = 26,
	TEGRASOC_WHICH_CLK_DSI_LP = 27,
	TEGRASOC_WHICH_CLK_DSI_CORE = 28,
	TEGRASOC_WHICH_CLK_DSI_PIXEL = 29,
	TEGRASOC_WHICH_CLK_PRE_SOR0 = 30,
	TEGRASOC_WHICH_CLK_PRE_SOR1 = 31,
	TEGRASOC_WHICH_CLK_DP_LINKA_REF = 32,
	TEGRASOC_WHICH_CLK_SOR_LINKA_INPUT = 33,
	TEGRASOC_WHICH_CLK_SOR_LINKA_AFIFO = 34,
	TEGRASOC_WHICH_CLK_SOR_LINKA_AFIFO_M = 35,
	TEGRASOC_WHICH_CLK_RG0_M = 36,
	TEGRASOC_WHICH_CLK_RG1_M = 37,
	TEGRASOC_WHICH_CLK_SOR0_M = 38,
	TEGRASOC_WHICH_CLK_SOR1_M = 39,
	TEGRASOC_WHICH_CLK_PLLHUB = 40,
	TEGRASOC_WHICH_CLK_SOR0 = 41,
	TEGRASOC_WHICH_CLK_SOR1 = 42,
	TEGRASOC_WHICH_CLK_SOR_PADA_INPUT = 43,
	TEGRASOC_WHICH_CLK_PRE_SF0 = 44,
	TEGRASOC_WHICH_CLK_SF0 = 45,
	TEGRASOC_WHICH_CLK_SF1 = 46,
	TEGRASOC_WHICH_CLK_DSI_PAD_INPUT = 47,
	TEGRASOC_WHICH_CLK_PRE_SOR0_REF = 48,
	TEGRASOC_WHICH_CLK_PRE_SOR1_REF = 49,
	TEGRASOC_WHICH_CLK_SOR0_PLL_REF = 50,
	TEGRASOC_WHICH_CLK_SOR1_PLL_REF = 51,
	TEGRASOC_WHICH_CLK_SOR0_REF = 52,
	TEGRASOC_WHICH_CLK_SOR1_REF = 53,
	TEGRASOC_WHICH_CLK_OSC = 54,
	TEGRASOC_WHICH_CLK_DSC = 55,
	TEGRASOC_WHICH_CLK_MAUD = 56,
	TEGRASOC_WHICH_CLK_AZA_2XBIT = 57,
	TEGRASOC_WHICH_CLK_AZA_BIT = 58,
	TEGRASOC_WHICH_CLK_MIPI_CAL = 59,
	TEGRASOC_WHICH_CLK_UART_FST_MIPI_CAL = 60,
	TEGRASOC_WHICH_CLK_SOR0_DIV = 61,
	TEGRASOC_WHICH_CLK_DISP_ROOT = 62,
	TEGRASOC_WHICH_CLK_HUB_ROOT = 63,
	TEGRASOC_WHICH_CLK_PLLA_DISP = 64,
	TEGRASOC_WHICH_CLK_PLLA_DISPHUB = 65,
	TEGRASOC_WHICH_CLK_PLLA = 66,
	TEGRASOC_WHICH_CLK_EMC = 67,
	TEGRASOC_WHICH_CLK_GPU_FIRST = 68,
	TEGRASOC_WHICH_CLK_GPU_SYS = 68,
	TEGRASOC_WHICH_CLK_GPU_NVD = 69,
	TEGRASOC_WHICH_CLK_GPU_UPROC = 70,
	TEGRASOC_WHICH_CLK_GPU_GPC0 = 71,
	TEGRASOC_WHICH_CLK_GPU_GPC1 = 72,
	TEGRASOC_WHICH_CLK_GPU_GPC2 = 73,
	TEGRASOC_WHICH_CLK_GPU_LAST = 73,
	TEGRASOC_WHICH_CLK_MAX = 74,
};

enum bpf_access_type;

enum bpf_func_id;

enum uvm_bpf_action {
	UVM_BPF_ACTION_DEFAULT = 0,
	UVM_BPF_ACTION_BYPASS = 1,
	UVM_BPF_ACTION_ENTER_LOOP = 2,
};

typedef _Bool bool;

typedef int NvS32;

typedef int __kernel_pid_t;

typedef int module1_data_type_t;

typedef __kernel_pid_t pid_t;

typedef long int __kernel_long_t;

typedef __kernel_long_t __kernel_ssize_t;

typedef __kernel_ssize_t ssize_t;

typedef long long int NvS64;

typedef long long int __kernel_loff_t;

typedef long long int __s64;

typedef __kernel_loff_t loff_t;

typedef __s64 s64;

typedef long long unsigned int NvU64;

typedef NvU64 NvLength;

typedef NvU64 NvUPtr;

typedef long long unsigned int UvmGpuPointer;

typedef long unsigned int __kernel_ulong_t;

typedef __kernel_ulong_t __kernel_size_t;

typedef __kernel_size_t size_t;

typedef short int NvS16;

typedef short unsigned int NvU16;

typedef short unsigned int NvV16;

typedef NvU16 uvm_page_index_t;

typedef signed char __s8;

typedef __s8 s8;

typedef unsigned char NvU8;

typedef NvU8 NvBool;

typedef unsigned char __u8;

typedef __u8 u8;

typedef u8 uint8_t;

typedef unsigned int NvU32;

typedef NvU32 NV_STATUS;

typedef NvU32 NvHandle;

typedef unsigned int NvV32;

typedef unsigned int __u32;

typedef __u32 u32;

typedef u32 __kernel_dev_t;

typedef __kernel_dev_t dev_t;

typedef unsigned int gfp_t;

typedef NvU32 uvm_gpu_semaphore_notifier_t;

typedef unsigned int vm_fault_t;

struct nv_uuid {
	NvU8 uuid[16];
};

typedef struct nv_uuid NvUuid;

typedef NvUuid NvProcessorUuid;

typedef struct {
	NvU64 base;
	NvU64 length;
	NvU64 offset;
	NvProcessorUuid gpuUuid;
	NvS32 rmCtrlFd;
	NvU32 hClient;
	NvU32 hMemory;
	NV_STATUS rmStatus;
} UVM_ALLOC_DEVICE_P2P_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuid;
	NvU32 gpuMappingType;
	NvU32 gpuCachingType;
	NvU32 gpuFormatType;
	NvU32 gpuElementBits;
	NvU32 gpuCompressionType;
} UvmGpuMappingAttributes;

typedef struct {
	NvU64 base;
	NvU64 length;
	UvmGpuMappingAttributes perGpuAttributes[256];
	NvU64 gpuAttributesCount;
	NV_STATUS rmStatus;
} UVM_ALLOC_SEMAPHORE_POOL_PARAMS;

typedef struct {
	NvU64 rangeGroupIds[32];
	NvU64 numGroupIds;
	NV_STATUS rmStatus;
} UVM_ALLOW_MIGRATION_RANGE_GROUPS_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_CLEAN_UP_ZOMBIE_RESOURCES_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_CLEAR_ALL_ACCESS_COUNTERS_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_CREATE_EXTERNAL_RANGE_PARAMS;

typedef struct {
	NvU64 rangeGroupId;
	NV_STATUS rmStatus;
} UVM_CREATE_RANGE_GROUP_PARAMS;

typedef struct {
	NvU64 rangeGroupId;
	NV_STATUS rmStatus;
} UVM_DESTROY_RANGE_GROUP_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuidA;
	NvProcessorUuid gpuUuidB;
	NV_STATUS rmStatus;
} UVM_DISABLE_PEER_ACCESS_PARAMS;

typedef struct {
	NvU64 requestedBase;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_DISABLE_READ_DUPLICATION_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NV_STATUS rmStatus;
} UVM_DISABLE_SYSTEM_WIDE_ATOMICS_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuidA;
	NvProcessorUuid gpuUuidB;
	NV_STATUS rmStatus;
} UVM_ENABLE_PEER_ACCESS_PARAMS;

typedef struct {
	NvU64 requestedBase;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_ENABLE_READ_DUPLICATION_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NV_STATUS rmStatus;
} UVM_ENABLE_SYSTEM_WIDE_ATOMICS_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_FREE_PARAMS;

typedef struct {
	NvU64 flags;
	NV_STATUS rmStatus;
} UVM_INITIALIZE_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NvProcessorUuid gpuUuid;
	NV_STATUS rmStatus;
} UVM_MAP_DYNAMIC_PARALLELISM_REGION_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NvU64 offset;
	UvmGpuMappingAttributes perGpuAttributes[256];
	NvU64 gpuAttributesCount;
	NvS32 rmCtrlFd;
	NvU32 hClient;
	NvU32 hMemory;
	NV_STATUS rmStatus;
} UVM_MAP_EXTERNAL_ALLOCATION_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NvProcessorUuid gpuUuid;
	NV_STATUS rmStatus;
} UVM_MAP_EXTERNAL_SPARSE_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NvProcessorUuid destinationUuid;
	NvU32 flags;
	NvU64 semaphoreAddress;
	NvU32 semaphorePayload;
	NvS32 cpuNumaNode;
	NvU64 userSpaceStart;
	NvU64 userSpaceLength;
	NV_STATUS rmStatus;
} UVM_MIGRATE_PARAMS;

typedef struct {
	NvU64 rangeGroupId;
	NvProcessorUuid destinationUuid;
	NV_STATUS rmStatus;
} UVM_MIGRATE_RANGE_GROUP_PARAMS;

typedef struct {
	NvS32 uvmFd;
	NV_STATUS rmStatus;
} UVM_MM_INITIALIZE_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvBool pageableMemAccess;
	NV_STATUS rmStatus;
} UVM_PAGEABLE_MEM_ACCESS_ON_GPU_PARAMS;

typedef struct {
	NvBool pageableMemAccess;
	NV_STATUS rmStatus;
} UVM_PAGEABLE_MEM_ACCESS_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NvU32 flags;
	NV_STATUS rmStatus;
} UVM_POPULATE_PAGEABLE_PARAMS;

typedef struct {
	NvU64 rangeGroupIds[32];
	NvU64 numGroupIds;
	NV_STATUS rmStatus;
} UVM_PREVENT_MIGRATION_RANGE_GROUPS_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuid;
	NvS32 rmCtrlFd;
	NvHandle hClient;
	NvHandle hChannel;
	NvU64 base;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_REGISTER_CHANNEL_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvBool numaEnabled;
	NvS32 numaNodeId;
	NvS32 rmCtrlFd;
	NvHandle hClient;
	NvHandle hSmcPartRef;
	NV_STATUS rmStatus;
} UVM_REGISTER_GPU_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuid;
	NvS32 rmCtrlFd;
	NvHandle hClient;
	NvHandle hVaSpace;
	NV_STATUS rmStatus;
} UVM_REGISTER_GPU_VASPACE_PARAMS;

typedef struct {
	NvU64 requestedBase;
	NvU64 length;
	NvProcessorUuid accessedByUuid;
	NV_STATUS rmStatus;
} UVM_SET_ACCESSED_BY_PARAMS;

typedef struct {
	NvU64 requestedBase;
	NvU64 length;
	NvProcessorUuid preferredLocation;
	NvS32 preferredCpuNumaNode;
	NV_STATUS rmStatus;
} UVM_SET_PREFERRED_LOCATION_PARAMS;

typedef struct {
	NvU64 rangeGroupId;
	NvU64 requestedBase;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_SET_RANGE_GROUP_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvBool enabled;
	NV_STATUS rmStatus;
} UVM_TEST_ACCESS_COUNTERS_ENABLED_BY_DEFAULT_PARAMS;

typedef struct {
	NvBool skipTimestampTest;
	NV_STATUS rmStatus;
} UVM_TEST_CE_SANITY_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_CGROUP_ACCOUNTING_SUPPORTED_PARAMS;

typedef struct {
	NvProcessorUuid uuid;
	NvU64 va;
	NvU32 mapping;
	NV_STATUS rmStatus;
} UVM_TEST_CHANGE_PTE_MAPPING_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_CHANNEL_SANITY_PARAMS;

typedef struct {
	NvU32 mode;
	NvU32 iterations;
	NvU32 num_streams;
	NvU32 key_rotation_operation;
	NvU32 seed;
	NvU32 verbose;
	NV_STATUS rmStatus;
} UVM_TEST_CHANNEL_STRESS_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvS32 rm_ctrl_fd;
	NvHandle client;
	NvHandle channel;
	NvU32 ve_id;
	NvS32 va_space_fd;
	NV_STATUS rmStatus;
} UVM_TEST_CHECK_CHANNEL_VA_SPACE_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_CPU_CHUNK_API_PARAMS;

typedef struct {
	NvU64 delay_us;
	NV_STATUS rmStatus;
} UVM_TEST_DESTROY_GPU_VA_SPACE_DELAY_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuidA;
	NvProcessorUuid gpuUuidB;
	NV_STATUS rmStatus;
} UVM_TEST_DISABLE_NVLINK_PEER_ACCESS_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 timeout_ns;
	NV_STATUS rmStatus;
} UVM_TEST_DRAIN_REPLAYABLE_FAULTS_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuidA;
	NvProcessorUuid gpuUuidB;
	NV_STATUS rmStatus;
} UVM_TEST_ENABLE_NVLINK_PEER_ACCESS_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU32 eviction_mode;
	NvU64 address;
	NvBool chunk_was_evicted;
	NvU64 evicted_physical_address;
	NvU64 chunk_size_backing_virtual;
	NV_STATUS rmStatus;
} UVM_TEST_EVICT_CHUNK_PARAMS;

typedef struct {
	NvU64 iterations;
	NV_STATUS rmStatus;
} UVM_TEST_FAULT_BUFFER_FLUSH_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_FILE_INITIALIZE_PARAMS;

typedef struct {
	NvU64 offset;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_TEST_FILE_UNMAP_PARAMS;

typedef struct {
	NvU32 work_type;
	NV_STATUS rmStatus;
} UVM_TEST_FLUSH_DEFERRED_WORK_PARAMS;

typedef struct {
	NvBool force_copy_with_ce;
	NV_STATUS rmStatus;
} UVM_TEST_FORCE_CPU_TO_CPU_COPY_WITH_CE_PARAMS;

typedef struct {
	NvU64 alloc_size_mask;
	NvU32 rmStatus;
} UVM_TEST_GET_CPU_CHUNK_ALLOC_SIZES_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 ref_count;
	NV_STATUS rmStatus;
} UVM_TEST_GET_GPU_REF_COUNT_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 timestamp_ns;
	NV_STATUS rmStatus;
} UVM_TEST_GET_GPU_TIME_PARAMS;

typedef struct {
	NvU64 addr;
	NV_STATUS rmStatus;
} UVM_TEST_GET_KERNEL_VIRTUAL_ADDRESS_PARAMS;

typedef struct {
	NvU32 type;
	NV_STATUS rmStatus;
} UVM_TEST_GET_PAGEABLE_MEM_ACCESS_TYPE_PARAMS;

typedef struct {
	NvU32 policy;
	NvU64 nap_ns;
	NvU64 pin_ns;
	NvBool map_remote_on_native_atomics_fault;
	NV_STATUS rmStatus;
} UVM_TEST_GET_PAGE_THRASHING_POLICY_PARAMS;

typedef struct {
	NvU32 reenable_lapse;
	NV_STATUS rmStatus;
} UVM_TEST_GET_PREFETCH_FAULTS_REENABLE_LAPSE_PARAMS;

typedef struct {
	NvS32 rmCtrlFd;
	NvHandle hClient;
	NvHandle hMemory;
	NvU32 test_mode;
	NvU64 size;
	NvProcessorUuid gpu_uuid;
	NV_STATUS rmStatus;
} UVM_TEST_GET_RM_PTES_PARAMS;

typedef struct {
	NvU64 user_space_end_address;
	NV_STATUS rmStatus;
} UVM_TEST_GET_USER_SPACE_END_ADDRESS_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_GPU_SEMAPHORE_SANITY_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_HOST_SANITY_PARAMS;

typedef struct {
	NvU64 amount;
	NvU32 counter;
	NvProcessorUuid processor;
	NvU32 count;
	NV_STATUS rmStatus;
} UVM_TEST_INCREMENT_TOOLS_COUNTER_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU32 error_type;
	NV_STATUS rmStatus;
} UVM_TEST_INJECT_NVLINK_ERROR_PARAMS;

typedef struct {
	NvU8 eventType;
	NvU8 direction;
	NvU8 srcIndex;
	NvU8 dstIndex;
	NvU32 padding32Bits;
	NvU64 address;
	NvU64 migratedBytes;
	NvU64 beginTimeStamp;
	NvU64 endTimeStamp;
	NvU64 streamId;
} UvmEventMigrationInfo_Lite;

typedef struct {
	NvU8 eventType;
	NvU8 accessType;
	NvU16 padding16Bits;
	NvU32 cpuId;
	NvU64 address;
	NvU64 timeStamp;
	NvU32 pid;
	NvU32 threadId;
	NvU64 pc;
} UvmEventCpuFaultInfo;

typedef struct {
	NvU8 eventType;
	NvU8 migrationCause;
	NvU8 srcIndex;
	NvU8 dstIndex;
	NvU32 padding32Bits;
	NvU64 address;
	NvU64 migratedBytes;
	NvU64 beginTimeStamp;
	NvU64 endTimeStamp;
	NvU64 rangeGroupId;
	NvU64 beginTimeStampGpu;
	NvU64 endTimeStampGpu;
} UvmEventMigrationInfo;

typedef struct {
	NvU8 eventType;
	NvU8 faultType;
	NvU8 accessType;
	NvU8 gpuIndex;
	union {
		NvU16 gpcId;
		NvU16 channelId;
	};
	NvU16 clientId;
	NvU64 address;
	NvU64 timeStamp;
	NvU64 timeStampGpu;
	NvU32 batchId;
	NvU8 clientType;
	NvU8 padding8Bits;
	NvU16 padding16Bits;
} UvmEventGpuFaultInfo;

typedef struct {
	NvU8 eventType;
	NvU8 gpuIndex;
	NvU8 clientType;
	NvU8 padding8bits;
	NvU32 batchId;
	NvU64 timeStamp;
	NvU64 timeStampGpu;
} UvmEventGpuFaultReplayInfo;

typedef struct {
	NvU8 eventType;
	NvU8 faultType;
	NvU8 accessType;
	NvU8 processorIndex;
	NvU8 reason;
	NvU8 padding8bits;
	NvU16 padding16bits;
	NvU64 address;
	NvU64 timeStamp;
} UvmEventFatalFaultInfo;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 padding16bits;
	NvU32 padding32bits;
	NvU64 processors;
	NvU64 address;
	NvU64 size;
	NvU64 timeStamp;
} UvmEventReadDuplicateInfo;

typedef struct {
	NvU8 eventType;
	NvU8 residentIndex;
	NvU16 padding16bits;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 size;
	NvU64 timeStamp;
} UvmEventReadDuplicateInvalidateInfo;

typedef struct {
	NvU8 eventType;
	NvU8 processorIndex;
	NvU16 padding16bits;
	NvU32 size;
	NvU64 address;
	NvU64 timeStamp;
} UvmEventPageSizeChangeInfo;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 padding16bits;
	NvU32 padding32bits;
	NvU64 processors;
	NvU64 address;
	NvU64 size;
	NvU64 timeStamp;
} UvmEventThrashingDetectedInfo;

typedef struct {
	NvU8 eventType;
	NvU8 processorIndex;
	NvU16 padding16bits;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 timeStamp;
} UvmEventThrottlingStartInfo;

typedef struct {
	NvU8 eventType;
	NvU8 processorIndex;
	NvU16 padding16bits;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 timeStamp;
} UvmEventThrottlingEndInfo;

typedef struct {
	NvU8 eventType;
	NvU8 srcIndex;
	NvU8 dstIndex;
	NvU8 mapRemoteCause;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 size;
	NvU64 timeStamp;
	NvU64 timeStampGpu;
} UvmEventMapRemoteInfo;

typedef struct {
	NvU8 eventType;
	NvU8 srcIndex;
	NvU8 dstIndex;
	NvU8 padding8bits;
	NvU32 padding32bits;
	NvU64 addressOut;
	NvU64 addressIn;
	NvU64 size;
	NvU64 timeStamp;
} UvmEventEvictionInfo;

typedef struct {
	NvU8 eventType;
	NvU8 srcIndex;
	NvU8 aperture;
	NvU8 instancePtrAperture;
	NvU8 padding8bits;
	NvU8 veId;
	NvU16 padding16bits;
	NvU32 value;
	NvU32 subGranularity;
	NvU32 tag;
	NvU32 bank;
	NvU64 address;
	NvU64 instancePtr;
} UvmEventTestAccessCounterInfo;

typedef struct {
	NvU8 eventType;
} UvmEventTestSplitInvalidateInfo;

typedef struct {
	union {
		union {
			NvU8 eventType;
			UvmEventMigrationInfo_Lite migration_Lite;
			UvmEventCpuFaultInfo cpuFault;
			UvmEventMigrationInfo migration;
			UvmEventGpuFaultInfo gpuFault;
			UvmEventGpuFaultReplayInfo gpuFaultReplay;
			UvmEventFatalFaultInfo fatalFault;
			UvmEventReadDuplicateInfo readDuplicate;
			UvmEventReadDuplicateInvalidateInfo readDuplicateInvalidate;
			UvmEventPageSizeChangeInfo pageSizeChange;
			UvmEventThrashingDetectedInfo thrashing;
			UvmEventThrottlingStartInfo throttlingStart;
			UvmEventThrottlingEndInfo throttlingEnd;
			UvmEventMapRemoteInfo mapRemote;
			UvmEventEvictionInfo eviction;
		} eventData;
		union {
			NvU8 eventType;
			UvmEventTestAccessCounterInfo accessCounter;
			UvmEventTestSplitInvalidateInfo splitInvalidate;
		} testEventData;
	};
} UvmEventEntry;

typedef struct {
	UvmEventEntry entry;
	NvU32 count;
	NV_STATUS rmStatus;
} UVM_TEST_INJECT_TOOLS_EVENT_PARAMS;

typedef struct {
	NvU8 eventType;
	NvU8 migrationCause;
	NvU16 padding16Bits;
	NvU16 srcIndex;
	NvU16 dstIndex;
	NvS32 srcNid;
	NvS32 dstNid;
	NvU64 address;
	NvU64 migratedBytes;
	NvU64 beginTimeStamp;
	NvU64 endTimeStamp;
	NvU64 rangeGroupId;
	NvU64 beginTimeStampGpu;
	NvU64 endTimeStampGpu;
} UvmEventMigrationInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 faultType;
	NvU16 gpuIndex;
	union {
		NvU16 gpcId;
		NvU16 channelId;
	};
	NvU16 clientId;
	NvU64 address;
	NvU64 timeStamp;
	NvU64 timeStampGpu;
	NvU32 batchId;
	NvU8 clientType;
	NvU8 accessType;
	NvU16 padding16bits;
} UvmEventGpuFaultInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 clientType;
	NvU16 gpuIndex;
	NvU32 batchId;
	NvU64 timeStamp;
	NvU64 timeStampGpu;
} UvmEventGpuFaultReplayInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 faultType;
	NvU8 accessType;
	NvU8 reason;
	NvU16 processorIndex;
	NvU16 padding16bits;
	NvU64 address;
	NvU64 timeStamp;
} UvmEventFatalFaultInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 padding16bits;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 size;
	NvU64 timeStamp;
	NvU64 processors[5];
} UvmEventReadDuplicateInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 residentIndex;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 size;
	NvU64 timeStamp;
} UvmEventReadDuplicateInvalidateInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 processorIndex;
	NvU32 size;
	NvU64 address;
	NvU64 timeStamp;
} UvmEventPageSizeChangeInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 padding16bits;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 size;
	NvU64 timeStamp;
	NvU64 processors[5];
} UvmEventThrashingDetectedInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 processorIndex;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 timeStamp;
} UvmEventThrottlingStartInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 processorIndex;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 timeStamp;
} UvmEventThrottlingEndInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 mapRemoteCause;
	NvU16 padding16bits;
	NvU16 srcIndex;
	NvU16 dstIndex;
	NvU64 address;
	NvU64 size;
	NvU64 timeStamp;
	NvU64 timeStampGpu;
} UvmEventMapRemoteInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 padding8bits;
	NvU16 padding16bits;
	NvU16 srcIndex;
	NvU16 dstIndex;
	NvU64 addressOut;
	NvU64 addressIn;
	NvU64 size;
	NvU64 timeStamp;
} UvmEventEvictionInfo_V2;

typedef struct {
	NvU8 eventType;
	NvU8 aperture;
	NvU8 instancePtrAperture;
	NvU8 veId;
	NvU16 padding16bits;
	NvU16 srcIndex;
	NvU32 value;
	NvU32 subGranularity;
	NvU32 tag;
	NvU32 bank;
	NvU32 padding32bits;
	NvU64 address;
	NvU64 instancePtr;
} UvmEventTestAccessCounterInfo_V2;

typedef struct {
	union {
		union {
			NvU8 eventType;
			UvmEventMigrationInfo_Lite migration_Lite;
			UvmEventCpuFaultInfo cpuFault;
			UvmEventMigrationInfo_V2 migration;
			UvmEventGpuFaultInfo_V2 gpuFault;
			UvmEventGpuFaultReplayInfo_V2 gpuFaultReplay;
			UvmEventFatalFaultInfo_V2 fatalFault;
			UvmEventReadDuplicateInfo_V2 readDuplicate;
			UvmEventReadDuplicateInvalidateInfo_V2 readDuplicateInvalidate;
			UvmEventPageSizeChangeInfo_V2 pageSizeChange;
			UvmEventThrashingDetectedInfo_V2 thrashing;
			UvmEventThrottlingStartInfo_V2 throttlingStart;
			UvmEventThrottlingEndInfo_V2 throttlingEnd;
			UvmEventMapRemoteInfo_V2 mapRemote;
			UvmEventEvictionInfo_V2 eviction;
		} eventData;
		union {
			NvU8 eventType;
			UvmEventTestAccessCounterInfo_V2 accessCounter;
			UvmEventTestSplitInvalidateInfo splitInvalidate;
		} testEventData;
	};
} UvmEventEntry_V2;

typedef struct {
	UvmEventEntry_V2 entry_v2;
	NvU32 count;
	NV_STATUS rmStatus;
} UVM_TEST_INJECT_TOOLS_EVENT_V2_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 va;
	NvU32 target_va_mode;
	NvU32 page_table_level;
	NvU32 membar;
	NvBool disable_gpc_invalidate;
	NV_STATUS rmStatus;
} UVM_TEST_INVALIDATE_TLB_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_KVMALLOC_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_LOCK_SANITY_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_MAKE_CHANNEL_STOPS_IMMEDIATE_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_MEM_SANITY_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NV_STATUS rmStatus;
} UVM_TEST_NUMA_CHECK_AFFINITY_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_NV_KTHREAD_Q_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_PAGE_TREE_PARAMS;

typedef struct {
	NvProcessorUuid gpuA;
	NvProcessorUuid gpuB;
	NV_STATUS rmStatus;
} UVM_TEST_PEER_IDENTITY_MAPPINGS_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid_1;
	NvProcessorUuid gpu_uuid_2;
	NV_STATUS rmStatus;
	NvU64 ref_count;
} UVM_TEST_PEER_REF_COUNT_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_PERF_EVENTS_SANITY_PARAMS;

typedef struct {
	NvU64 range_address;
	NvU32 range_size;
	NV_STATUS rmStatus;
} UVM_TEST_PERF_MODULE_SANITY_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_PERF_UTILS_SANITY_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 page_size;
	NvBool contiguous;
	NvU64 num_pages;
	NvU64 phys_begin;
	NvU64 phys_end;
	NvU32 nap_us_before_free;
	NV_STATUS rmStatus;
} UVM_TEST_PMA_ALLOC_FREE_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 pma_batch_size;
	NV_STATUS rmStatus;
} UVM_TEST_PMA_GET_BATCH_SIZE_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU32 nap_us_before_free;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_ALLOC_FREE_ROOT_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU32 num_chunks;
	NvU32 num_work_iterations;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_ASYNC_ALLOC_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 chunk_size;
	NvS64 alloc_limit;
	NvU64 allocated;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_CHECK_LEAK_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_PMM_CHUNK_WITH_ELEVATED_PAGE_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU32 error_after_num_chunks;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_INJECT_PMA_EVICT_ERROR_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 key;
	NvU64 value;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_QUERY_PARAMS;

struct UvmPmaStatistics_tag {
	volatile NvU64 numPages2m;
	volatile NvU64 numFreePages64k;
	volatile NvU64 numFreePages2m;
	volatile NvU64 numPages2mProtected;
	volatile NvU64 numFreePages64kProtected;
	volatile NvU64 numFreePages2mProtected;
};

typedef struct UvmPmaStatistics_tag UvmPmaStatistics;

typedef struct {
	NvProcessorUuid gpu_uuid;
	UvmPmaStatistics pma_stats;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_QUERY_PMA_STATS_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_RELEASE_FREE_ROOT_CHUNKS_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU64 range_address1;
	NvU64 range_address2;
	NvU64 range_size2;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_REVERSE_MAP_PARAMS;

typedef struct {
	NvU32 mode;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_SANITY_PARAMS;

typedef struct {
	NvU64 range_address1;
	NvU64 range_address2;
	NV_STATUS rmStatus;
} UVM_TEST_PMM_SYSMEM_PARAMS;

typedef struct {
	NvBool skipTimestampTest;
	NV_STATUS rmStatus;
} UVM_TEST_PUSH_SANITY_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU8 num_notification_buffers;
	NvU32 num_notification_entries;
	NV_STATUS rmStatus;
} UVM_TEST_QUERY_ACCESS_COUNTERS_PARAMS;

typedef struct {
	NvU32 verbose;
	NvU32 seed;
	NvU32 iters;
	NV_STATUS rmStatus;
} UVM_TEST_RANGE_ALLOCATOR_SANITY_PARAMS;

typedef struct {
	NvU64 rangeGroupId;
	NvU64 count;
	NV_STATUS rmStatus;
} UVM_TEST_RANGE_GROUP_RANGE_COUNT_PARAMS;

typedef struct {
	NvU64 lookup_address;
	NvU64 range_group_range_start;
	NvU64 range_group_range_end;
	NvU64 range_group_id;
	NvU32 range_group_present;
	NV_STATUS rmStatus;
} UVM_TEST_RANGE_GROUP_RANGE_INFO_PARAMS;

typedef struct {
	NvU64 rangeGroupIds[4];
	NV_STATUS rmStatus;
} UVM_TEST_RANGE_GROUP_TREE_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_RANGE_TREE_DIRECTED_PARAMS;

typedef struct {
	NvU32 seed;
	NvU64 main_iterations;
	NvU32 verbose;
	NvU32 high_probability;
	NvU32 add_remove_shrink_group_probability;
	NvU32 shrink_probability;
	NvU32 collision_checks;
	NvU32 iterator_checks;
	NvU64 max_end;
	NvU64 max_ranges;
	NvU64 max_batch_count;
	NvU32 max_attempts;
	struct {
		NvU64 total_adds;
		NvU64 failed_adds;
		NvU64 max_attempts_add;
		NvU64 total_removes;
		NvU64 total_splits;
		NvU64 failed_splits;
		NvU64 max_attempts_split;
		NvU64 total_merges;
		NvU64 failed_merges;
		NvU64 max_attempts_merge;
		NvU64 total_shrinks;
		NvU64 failed_shrinks;
	} stats;
	NV_STATUS rmStatus;
} UVM_TEST_RANGE_TREE_RANDOM_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_RB_TREE_DIRECTED_PARAMS;

typedef struct {
	NvU64 iterations;
	NvU64 range_max;
	NvU32 node_limit;
	NvU32 seed;
	NV_STATUS rmStatus;
} UVM_TEST_RB_TREE_RANDOM_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU32 granularity;
	NvU32 threshold;
	NvBool enable_migrations;
	NvU32 max_batch_size;
	NvBool one_iteration_per_batch;
	NvU32 sleep_per_iteration_us;
	NV_STATUS rmStatus;
} UVM_TEST_RECONFIGURE_ACCESS_COUNTERS_PARAMS;

typedef struct {
	NvU64 unload_state_buf;
	NV_STATUS rmStatus;
} UVM_TEST_REGISTER_UNLOAD_STATE_BUFFER_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU32 mode;
	NvU32 bank;
	NvU32 tag;
	NV_STATUS rmStatus;
} UVM_TEST_RESET_ACCESS_COUNTERS_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_RM_MEM_SANITY_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_RNG_SANITY_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_SEC2_CPU_GPU_ROUNDTRIP_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_SEC2_SANITY_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvBool ignore;
	NV_STATUS rmStatus;
} UVM_TEST_SET_IGNORE_ACCESS_COUNTERS_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvBool suspended;
	NV_STATUS rmStatus;
} UVM_TEST_SET_P2P_SUSPENDED_PARAMS;

typedef struct {
	NvU32 policy;
	NV_STATUS rmStatus;
} UVM_TEST_SET_PAGE_PREFETCH_POLICY_PARAMS;

typedef struct {
	NvU32 policy;
	NvU64 pin_ns;
	NV_STATUS rmStatus;
} UVM_TEST_SET_PAGE_THRASHING_POLICY_PARAMS;

typedef struct {
	NvU32 reenable_lapse;
	NV_STATUS rmStatus;
} UVM_TEST_SET_PREFETCH_FAULTS_REENABLE_LAPSE_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NvU32 filtering_mode;
	NV_STATUS rmStatus;
} UVM_TEST_SET_PREFETCH_FILTERING_PARAMS;

typedef struct {
	NvBool skip;
	NV_STATUS rmStatus;
} UVM_TEST_SKIP_MIGRATE_VMA_PARAMS;

typedef struct {
	NvU64 delay_us;
	NV_STATUS rmStatus;
} UVM_TEST_SPLIT_INVALIDATE_DELAY_PARAMS;

typedef struct {
	NvU32 iterations;
	NvU32 delay_us;
	NvU64 ns;
	NV_STATUS rmStatus;
} UVM_TEST_THREAD_CONTEXT_PERF_PARAMS;

typedef struct {
	NvU32 iterations;
	NV_STATUS rmStatus;
} UVM_TEST_THREAD_CONTEXT_SANITY_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuid;
	NV_STATUS rmStatus;
} UVM_TEST_TOOLS_FLUSH_REPLAY_EVENTS_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_TRACKER_SANITY_PARAMS;

typedef struct {
	NvU64 lookup_address;
	NvU64 va_block_start;
	NvU64 va_block_end;
	NV_STATUS rmStatus;
} UVM_TEST_VA_BLOCK_INFO_PARAMS;

typedef struct {
	NvU64 lookup_address;
	NvU32 page_table_allocation_retry_force_count;
	NvU32 user_pages_allocation_retry_force_count;
	NvU64 cpu_chunk_allocation_size_mask;
	NvS32 cpu_chunk_allocation_target_id;
	NvS32 cpu_chunk_allocation_actual_id;
	NvU32 cpu_chunk_allocation_error_count;
	NvBool eviction_error;
	NvBool populate_error;
	NV_STATUS rmStatus;
} UVM_TEST_VA_BLOCK_INJECT_ERROR_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_VA_BLOCK_PARAMS;

typedef struct {
	NvU64 vma_start;
	NvU64 vma_end;
	NvBool is_zombie;
	NvBool owned_by_calling_process;
	NvU32 subtype;
} UVM_TEST_VA_RANGE_INFO_MANAGED;

typedef struct {
	NvU64 lookup_address;
	NvU64 va_range_start;
	NvU64 va_range_end;
	NvU32 read_duplication;
	NvProcessorUuid preferred_location;
	NvS32 preferred_cpu_nid;
	NvProcessorUuid accessed_by[257];
	NvU32 accessed_by_count;
	NvU32 type;
	union {
		UVM_TEST_VA_RANGE_INFO_MANAGED managed;
	};
	NV_STATUS rmStatus;
} UVM_TEST_VA_RANGE_INFO_PARAMS;

typedef struct {
	NvU64 lookup_address;
	NV_STATUS rmStatus;
} UVM_TEST_VA_RANGE_INJECT_ADD_GPU_VA_SPACE_ERROR_PARAMS;

typedef struct {
	NvU64 lookup_address;
	NV_STATUS rmStatus;
} UVM_TEST_VA_RANGE_INJECT_SPLIT_ERROR_PARAMS;

typedef struct {
	NvU64 split_address;
	NV_STATUS rmStatus;
} UVM_TEST_VA_RANGE_SPLIT_PARAMS;

typedef struct {
	NvU64 lookup_address;
	NvBool is_async;
	NvProcessorUuid resident_on[257];
	NvU32 resident_on_count;
	NvS32 resident_nid;
	NvU32 resident_physical_size[257];
	NvU64 resident_physical_address[257];
	NvProcessorUuid mapped_on[257];
	NvU32 mapping_type[257];
	NvU64 mapping_physical_address[257];
	NvBool is_egm_mapping[257];
	NvU32 mapped_on_count;
	NvU64 page_size[257];
	NvProcessorUuid populated_on[257];
	NvU32 populated_on_count;
	NV_STATUS rmStatus;
} UVM_TEST_VA_RESIDENCY_INFO_PARAMS;

typedef struct {
	NvU32 num_dummy_thread_contexts;
	NV_STATUS rmStatus;
} UVM_TEST_VA_SPACE_ADD_DUMMY_THREAD_CONTEXTS_PARAMS;

typedef struct {
	NvBool allow_movable;
	NV_STATUS rmStatus;
} UVM_TEST_VA_SPACE_ALLOW_MOVABLE_ALLOCATIONS_PARAMS;

typedef struct {
	NvU32 migrate_vma_allocation_fail_nth;
	NvU32 va_block_allocation_fail_nth;
	NvBool gpu_access_counters_alloc_buffer;
	NvBool gpu_access_counters_alloc_block_context;
	NvBool gpu_isr_access_counters_alloc;
	NvBool gpu_isr_access_counters_alloc_stats_cpu;
	NvBool access_counters_batch_context_notifications;
	NvBool access_counters_batch_context_notification_cache;
	NV_STATUS rmStatus;
} UVM_TEST_VA_SPACE_INJECT_ERROR_PARAMS;

typedef struct {
	NvU64 retain_done_ptr;
	NvU64 sleep_us;
	NV_STATUS rmStatus;
} UVM_TEST_VA_SPACE_MM_OR_CURRENT_RETAIN_PARAMS;

typedef struct {
	NvU64 va_space_ptr;
	NvU64 addr;
	NvU64 val_before;
	NvU64 val_after;
	NvU64 sleep_us;
	NV_STATUS rmStatus;
} UVM_TEST_VA_SPACE_MM_RETAIN_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TEST_VA_SPACE_REMOVE_DUMMY_THREAD_CONTEXTS_PARAMS;

typedef struct {
	NvU64 counterTypeFlags;
	NV_STATUS rmStatus;
} UVM_TOOLS_DISABLE_COUNTERS_PARAMS;

typedef struct {
	NvU64 counterTypeFlags;
	NV_STATUS rmStatus;
} UVM_TOOLS_ENABLE_COUNTERS_PARAMS;

typedef struct {
	NvU64 eventTypeFlags;
	NV_STATUS rmStatus;
} UVM_TOOLS_EVENT_QUEUE_DISABLE_EVENTS_PARAMS;

typedef struct {
	NvU64 eventTypeFlags;
	NV_STATUS rmStatus;
} UVM_TOOLS_EVENT_QUEUE_ENABLE_EVENTS_PARAMS;

typedef struct {
	NV_STATUS rmStatus;
} UVM_TOOLS_FLUSH_EVENTS_PARAMS;

typedef struct {
	NvU64 tablePtr;
	NV_STATUS rmStatus;
} UVM_TOOLS_GET_PROCESSOR_UUID_TABLE_PARAMS;

typedef UVM_TOOLS_GET_PROCESSOR_UUID_TABLE_PARAMS UVM_TOOLS_GET_PROCESSOR_UUID_TABLE_V2_PARAMS;

typedef struct {
	NvU64 queueBuffer;
	NvU64 queueBufferSize;
	NvU64 controlBuffer;
	NvProcessorUuid processor;
	NvU32 allProcessors;
	NvU32 uvmFd;
	NV_STATUS rmStatus;
} UVM_TOOLS_INIT_EVENT_TRACKER_PARAMS;

typedef UVM_TOOLS_INIT_EVENT_TRACKER_PARAMS UVM_TOOLS_INIT_EVENT_TRACKER_V2_PARAMS;

typedef struct {
	NvU64 buffer;
	NvU64 size;
	NvU64 targetVa;
	NvU64 bytesRead;
	NV_STATUS rmStatus;
} UVM_TOOLS_READ_PROCESS_MEMORY_PARAMS;

typedef struct {
	NvU32 notificationThreshold;
	NV_STATUS rmStatus;
} UVM_TOOLS_SET_NOTIFICATION_THRESHOLD_PARAMS;

typedef struct {
	NvU64 buffer;
	NvU64 size;
	NvU64 targetVa;
	NvU64 bytesWritten;
	NV_STATUS rmStatus;
} UVM_TOOLS_WRITE_PROCESS_MEMORY_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NvProcessorUuid gpuUuid;
	NV_STATUS rmStatus;
} UVM_UNMAP_EXTERNAL_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuid;
	NvHandle hClient;
	NvHandle hChannel;
	NV_STATUS rmStatus;
} UVM_UNREGISTER_CHANNEL_PARAMS;

typedef struct {
	NvProcessorUuid gpu_uuid;
	NV_STATUS rmStatus;
} UVM_UNREGISTER_GPU_PARAMS;

typedef struct {
	NvProcessorUuid gpuUuid;
	NV_STATUS rmStatus;
} UVM_UNREGISTER_GPU_VASPACE_PARAMS;

typedef struct {
	NvU64 requestedBase;
	NvU64 length;
	NvProcessorUuid accessedByUuid;
	NV_STATUS rmStatus;
} UVM_UNSET_ACCESSED_BY_PARAMS;

typedef struct {
	NvU64 requestedBase;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_UNSET_PREFERRED_LOCATION_PARAMS;

typedef struct {
	NvU64 base;
	NvU64 length;
	NV_STATUS rmStatus;
} UVM_VALIDATE_VA_RANGE_PARAMS;

typedef struct {
	NvBool supported: 1;
	NvBool grce: 1;
	NvBool shared: 1;
	NvBool sysmemRead: 1;
	NvBool sysmemWrite: 1;
	NvBool sysmem: 1;
	NvBool nvlinkP2p: 1;
	NvBool p2p: 1;
	NvBool secure: 1;
	NvU32 cePceMask;
} UvmGpuCopyEngineCaps;

struct pci_dev;

typedef struct {
	struct pci_dev *pci_dev;
	NvU64 dma_addressable_start;
	NvU64 dma_addressable_limit;
} UvmGpuPlatformInfo;

typedef struct {
	NvU8 bufferEntry[32];
} access_counter_buffer_entry_c365_t;

typedef struct {
	NvU32 val;
} uvm_processor_id_t;

typedef struct {
	uvm_processor_id_t processor_id;
	bool set_bit;
} accessed_by_split_params_t;

typedef struct {
	s64 counter;
} atomic64_t;

typedef atomic64_t atomic_long_t;

typedef struct {
	int counter;
} atomic_t;

struct list_head {
	long: 64;
	long: 64;
};

struct uvm_va_space_struct;

typedef struct uvm_va_space_struct uvm_va_space_t;

struct uvm_pmm_gpu_struct;

typedef struct uvm_pmm_gpu_struct uvm_pmm_gpu_t;

struct uvm_mem_struct;

typedef struct uvm_mem_struct uvm_mem_t;

typedef struct {
	struct list_head list;
	size_t num_chunks_total;
	uvm_va_space_t *va_space;
	uvm_pmm_gpu_t *pmm;
	uvm_mem_t *verif_mem;
	uvm_pmm_gpu_memory_type_t type;
	basic_test_free_pattern_t free_pattern;
} basic_test_state_t;

typedef struct {
	NvU64 address;
	uvm_aperture_t aperture;
	bool is_virtual;
	bool is_unprotected;
} uvm_gpu_address_t;

typedef struct {
	uvm_processor_id_t id;
	int nid;
	bool is_block_contig;
	uvm_gpu_address_t gpu_address;
} block_copy_addr_t;

struct uvm_channel_struct;

typedef struct uvm_channel_struct uvm_channel_t;

typedef struct {
	uvm_channel_t *channel;
	NvU64 value;
} uvm_tracker_entry_t;

typedef struct {
	union {
		uvm_tracker_entry_t static_entries[1];
		uvm_tracker_entry_t *dynamic_entries;
	};
	NvU32 size;
	NvU32 max_size;
} uvm_tracker_t;

struct UvmCslIv {
	NvU8 iv[12];
	NvU8 fresh;
};

typedef struct UvmCslIv UvmCslIv;

typedef struct {
	long unsigned int bitmap[8];
} uvm_page_mask_t;

typedef struct {
	uvm_mem_t *alloc;
	uvm_tracker_t tracker;
	uvm_mem_t *auth_tag;
	UvmCslIv decrypt_iv[512];
	NvU32 key_version[512];
	uvm_page_mask_t encrypted_page_mask;
	struct list_head node;
} uvm_conf_computing_dma_buffer_t;

typedef struct {
	block_copy_addr_t src;
	block_copy_addr_t dst;
	uvm_conf_computing_dma_buffer_t *dma_buffer;
	bool copy_pushed;
} block_copy_state_t;

typedef struct {
	size_t num_chunks;
	size_t chunk_index;
	uvm_chunk_size_t chunk_size;
} block_gpu_chunk_split_state_t;

typedef void (*nv_q_func_t)(void *);

struct nv_kthread_q_item {
	struct list_head q_list_node;
	nv_q_func_t function_to_run;
	void *function_args;
};

typedef struct nv_kthread_q_item nv_kthread_q_item_t;

typedef struct {
	nv_kthread_q_item_t queue_item;
	uvm_processor_id_t src;
	uvm_processor_id_t dst;
	UvmEventMapRemoteCause cause;
	NvU64 timestamp;
	uvm_va_space_t *va_space;
	uvm_channel_t *channel;
	struct list_head events;
} block_map_remote_data_t;

typedef struct {
	nv_kthread_q_item_t queue_item;
	uvm_processor_id_t dst;
	NvS16 dst_nid;
	uvm_processor_id_t src;
	NvS16 src_nid;
	uvm_va_space_t *va_space;
	uvm_channel_t *channel;
	struct list_head events;
	NvU64 start_timestamp_cpu;
	NvU64 end_timestamp_cpu;
	NvU64 *start_timestamp_gpu_addr;
	NvU64 start_timestamp_gpu;
	NvU64 range_group_id;
} block_migration_data_t;

typedef struct {
	uvm_processor_id_t processor;
	uvm_page_index_t page_index;
	int nid;
} block_phys_page_t;

typedef struct {
	long unsigned int bitmap[5];
} uvm_processor_mask_t;

typedef struct {
	struct {
		NvU64 last_time_stamp: 58;
		bool has_migration_events: 1;
		bool has_revocation_events: 1;
		NvU8 num_thrashing_events: 3;
		bool pinned: 1;
	};
	struct {
		NvU64 throttling_end_time_stamp: 58;
		long: 6;
		NvU8 throttling_count: 8;
	};
	uvm_processor_mask_t processors;
	uvm_processor_mask_t throttled_processors;
	uvm_processor_id_t pinned_residency_id;
	uvm_processor_id_t do_not_throttle_processor_id;
} page_thrashing_info_t;

typedef struct {
	page_thrashing_info_t *pages;
	NvU16 num_thrashing_pages;
	NvU8 thrashing_reset_count;
	uvm_processor_id_t last_processor;
	NvU64 last_time_stamp;
	NvU64 last_thrashing_time_stamp;
	NvU32 throttling_count;
	uvm_page_mask_t thrashing_pages;
	struct {
		NvU32 count;
		uvm_page_mask_t mask;
		struct list_head list;
	} pinned_pages;
} block_thrashing_info_t;

typedef struct {
	uvm_page_index_t first;
	uvm_page_index_t outer;
} uvm_va_block_region_t;

struct uvm_va_block_struct;

typedef struct uvm_va_block_struct uvm_va_block_t;

struct uvm_va_range_struct;

typedef struct uvm_va_range_struct uvm_va_range_t;

struct uvm_perf_module_struct;

typedef struct uvm_perf_module_struct uvm_perf_module_t;

struct uvm_va_range_managed_struct;

typedef struct uvm_va_range_managed_struct uvm_va_range_managed_t;

struct uvm_fault_buffer_entry_struct;

typedef struct uvm_fault_buffer_entry_struct uvm_fault_buffer_entry_t;

struct uvm_push_struct;

typedef struct uvm_push_struct uvm_push_t;

struct uvm_make_resident_context_struct;

typedef struct uvm_make_resident_context_struct uvm_make_resident_context_t;

typedef union {
	struct {
		uvm_va_block_t *block;
	} block_destroy;
	struct {
		uvm_va_block_t *block;
	} block_shrink;
	struct {
		uvm_va_block_t *block;
		uvm_va_block_region_t region;
	} block_munmap;
	struct {
		uvm_va_range_t *range;
	} range_destroy;
	struct {
		uvm_va_range_t *range;
	} range_shrink;
	struct {
		uvm_perf_module_t *module;
		uvm_va_block_t *block;
		uvm_va_range_managed_t *range;
	} module_unload;
	struct {
		uvm_va_space_t *space;
		uvm_va_block_t *block;
		uvm_processor_id_t proc_id;
		uvm_processor_id_t preferred_location;
		union {
			struct {
				uvm_fault_buffer_entry_t *buffer_entry;
				NvU32 batch_id;
				bool is_duplicate;
			} gpu;
			struct {
				NvU64 fault_va;
				NvU32 cpu_num;
				bool is_write;
				NvU64 pc;
			} cpu;
		};
	} fault;
	struct {
		union {
			uvm_push_t *push;
			NvU64 cpu_start_timestamp;
		};
		uvm_va_block_t *block;
		uvm_processor_id_t dst;
		uvm_processor_id_t src;
		NvS16 dst_nid;
		NvS16 src_nid;
		NvU64 address;
		NvU64 bytes;
		uvm_va_block_transfer_mode_t transfer_mode;
		uvm_make_resident_cause_t cause;
		uvm_make_resident_context_t *make_resident_context;
	} migration;
	struct {
		uvm_va_block_t *block;
		uvm_processor_id_t proc_id;
		NvU64 address;
		NvU64 bytes;
		uvm_prot_t old_prot;
		uvm_prot_t new_prot;
	} revocation;
} uvm_perf_event_data_t;

typedef void (*uvm_perf_event_callback_t)(uvm_perf_event_t, uvm_perf_event_data_t *);

typedef struct {
	uvm_perf_event_callback_t callback;
	struct list_head callback_list_node;
} callback_desc_t;

typedef struct {
	uvm_va_block_t *va_block_to_evict_from;
} evict_data_t;

typedef struct {
	NvU64 base;
	NvU64 size;
	NvU64 page_size;
	NvU32 depth;
	uvm_membar_t membar;
} fake_tlb_invalidate_t;

typedef struct {
	NvU8 bufferEntry[32];
} fault_buffer_entry_b069_t;

typedef struct {
	NvU8 bufferEntry[32];
} fault_buffer_entry_c369_t;

struct uvm_reverse_map_struct;

typedef struct uvm_reverse_map_struct uvm_reverse_map_t;

typedef struct {
	NvU64 phys_start;
	NvU64 phys_end;
	uvm_reverse_map_t *mappings;
	NvU32 num_mappings;
} get_chunk_mappings_data_t;

struct uvm_gpu_chunk_struct;

typedef struct uvm_gpu_chunk_struct uvm_gpu_chunk_t;

typedef struct {
	size_t num_written;
	size_t num_to_write;
	size_t num_to_skip;
	uvm_gpu_chunk_t **subchunks;
} get_subchunks_walk_t;

struct mmu_interval_notifier {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

typedef struct {
	struct mmu_interval_notifier notifier;
	uvm_va_block_t *existing_block;
} hmm_split_invalidate_data_t;

struct kmem_cache;

typedef struct {
	struct kmem_cache *cache;
	NvU32 refcount;
	char name[32];
} kmem_cache_ref_t;

typedef struct {
	struct list_head events_node;
	NvU64 address;
	NvU64 size;
	NvU64 timestamp_gpu;
	NvU64 *timestamp_gpu_addr;
} map_remote_data_t;

struct mm_struct;

typedef struct {
	uvm_va_space_t *va_space;
	struct mm_struct *mm;
	const long unsigned int start;
	const long unsigned int length;
	uvm_processor_id_t dst_id;
	int dst_node_id;
	uvm_populate_permissions_t populate_permissions;
	NvU32 populate_flags;
	bool skip_mapped: 1;
	bool populate_on_cpu_alloc_failures: 1;
	bool populate_on_migrate_vma_failures: 1;
	NvU64 *user_space_start;
	NvU64 *user_space_length;
	uvm_processor_mask_t *gpus_to_check_for_nvlink_errors;
	bool fail_on_unresolved_sto_errors;
} uvm_migrate_args_t;

struct sg_table {
	long: 64;
	long: 64;
};

struct uvm_gpu_struct;

typedef struct uvm_gpu_struct uvm_gpu_t;

typedef struct {
	uvm_migrate_args_t *uvm_migrate_args;
	NV_STATUS status;
	long unsigned int populate_pages_mask[8];
	long unsigned int allocation_failed_mask[8];
	long unsigned int dst_resident_pages_mask[8];
	long unsigned int scratch1_mask[8];
	long unsigned int scratch2_mask[8];
	long unsigned int dst_pfn_array[512];
	long unsigned int src_pfn_array[512];
	uvm_tracker_t tracker;
	struct {
		long unsigned int num_pages;
		struct sg_table sgt_anon;
		uvm_gpu_t *sgt_anon_gpu;
		struct sg_table sgt_from[257];
		uvm_gpu_t *sgt_from_gpus[257];
	} dma;
	uvm_processor_mask_t src_processors;
	struct {
		long unsigned int page_mask[8];
	} processors[257];
	long unsigned int num_pages;
	long unsigned int num_populate_anon_pages;
} migrate_vma_state_t;

typedef struct {
	struct list_head events_node;
	NvU64 bytes;
	NvU64 address;
	NvU64 *end_timestamp_gpu_addr;
	NvU64 end_timestamp_gpu;
	UvmEventMigrationCause cause;
} migration_data_t;

typedef struct {
	int value[4];
} module2_data_type_t;

typedef struct {
	long unsigned int bits[16];
} nodemask_t;

typedef struct {
	uvm_va_block_t *va_block;
	uvm_page_index_t page_index;
	NvU64 deadline;
	struct list_head va_space_list_entry;
	struct list_head va_block_list_entry;
} pinned_page_t;

typedef struct {
	struct list_head entry;
	uvm_gpu_chunk_t *chunks[128];
} pmm_leak_bucket_t;

typedef struct {
	uvm_processor_id_t processor_id;
	int nid;
} preferred_location_split_params_t;

struct proc_dir_entry;

typedef struct {
	struct proc_dir_entry *procfs_file;
	atomic64_t num_thrashing;
	atomic64_t num_throttle;
	atomic64_t num_pin_local;
	atomic64_t num_pin_remote;
} processor_thrashing_stats_t;

struct spinlock {
	int: 32;
};

typedef struct spinlock spinlock_t;

typedef struct {
	spinlock_t lock;
} uvm_spinlock_t;

struct rb_root {
	long: 64;
};

struct uvm_range_tree_struct {
	struct rb_root rb_root;
	struct list_head head;
};

typedef struct uvm_range_tree_struct uvm_range_tree_t;

typedef struct {
	uvm_spinlock_t lock;
	NvU64 size;
	uvm_range_tree_t range_tree;
} uvm_range_allocator_t;

typedef struct {
	unsigned int z;
	unsigned int w;
	unsigned int jsr;
	unsigned int jcong;
} uvm_test_rng_t;

struct uvm_range_tree_node_struct;

typedef struct uvm_range_tree_node_struct uvm_range_tree_node_t;

typedef struct {
	NvU64 aligned_start;
	uvm_range_tree_node_t *node;
} uvm_range_allocation_t;

typedef struct {
	uvm_range_allocator_t range_allocator;
	uvm_test_rng_t rng;
	uvm_range_allocation_t *range_allocs;
	size_t allocated_ranges;
	size_t free_size;
	NvU64 total_allocs;
} random_test_state_t;

typedef struct {
	struct rb_root rb_root;
	struct list_head head;
} uvm_rb_tree_t;

typedef struct {
	uvm_rb_tree_t tree;
	uvm_test_rng_t rng;
	struct list_head nodes;
	rbtt_test_op_t preferred_op;
	size_t count;
} rbtt_state_t;

struct rb_node {
	long: 64;
	long: 64;
	long: 64;
};

typedef struct {
	NvU64 key;
	struct rb_node rb_node;
	struct list_head list;
} uvm_rb_tree_node_t;

typedef struct {
	NvU64 key;
	uvm_rb_tree_node_t node;
	struct list_head list;
} rbtt_tree_node_t;

typedef uvm_processor_id_t uvm_gpu_id_t;

typedef struct {
	nv_kthread_q_item_t queue_item;
	uvm_channel_t *channel;
	uvm_gpu_id_t gpu_id;
	NvU32 batch_id;
	uvm_fault_client_type_t client_type;
	NvU64 timestamp;
	NvU64 timestamp_gpu;
	NvU64 *timestamp_gpu_addr;
} replay_data_t;

typedef struct {
	NvU64 start;
	NvU64 end;
} rtt_range_t;

typedef struct {
	uvm_chunk_size_t min_size;
	size_t num_subchunks_curr;
	size_t num_subchunks_total;
	uvm_gpu_chunk_t **subchunks;
	bool inject_error;
} split_walk_t;

typedef struct {
	uvm_gpu_chunk_t *chunk;
	uvm_tracker_t tracker;
	NvU32 pattern;
	long: 0;
	struct list_head node;
} test_chunk_t;

typedef struct {
	NvU64 count;
	NV_STATUS status;
} test_pte_maker_data_t;

typedef struct {
	NvU64 *timestmap_in_pushbuffer;
	NvU64 timestamp;
} timestamp_test_t;

typedef struct {
	uvm_page_mask_t pages;
	uvm_page_index_t offset;
	NvU16 leaf_count;
	NvU8 level_count;
} uvm_perf_prefetch_bitmap_tree_t;

typedef struct {
	union {
		struct {
			uvm_page_mask_t prefetch_only_fault_mask;
			uvm_page_mask_t read_fault_mask;
			uvm_page_mask_t write_fault_mask;
			uvm_page_mask_t accessed_mask;
			uvm_page_mask_t faults_serviced_mask;
			uvm_page_mask_t reads_serviced_mask;
		} faults;
		struct {
			uvm_page_mask_t accessed_mask;
			uvm_page_mask_t migrated_mask;
		} access_counters;
	};
	uvm_fault_client_type_t client_type;
	uvm_processor_id_t residency_id;
	int residency_node;
	struct {
		bool has_preferred_location;
		bool first_touch;
		uvm_page_mask_t prefetch_pages_mask;
		long unsigned int pfns[512];
		uvm_page_mask_t residency_mask;
		struct mmu_interval_notifier notifier;
		uvm_va_space_t *va_space;
		uvm_perf_prefetch_bitmap_tree_t bitmap_tree;
	} prefetch_state;
} uvm_ats_fault_context_t;

struct nv_kref {
	atomic_t refcount;
};

typedef struct nv_kref nv_kref_t;

struct iommu_sva;

typedef struct {
	nv_kref_t kref;
	struct iommu_sva *iommu_handle;
} uvm_sva_gpu_va_space_t;

typedef struct {
	bool enabled;
	NvU32 pasid;
	uvm_sva_gpu_va_space_t sva;
} uvm_ats_gpu_va_space_t;

struct rw_semaphore {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

typedef struct {
	struct rw_semaphore sem;
} uvm_rw_semaphore_t;

typedef struct {
	int placeholder;
} uvm_sva_va_space_t;

typedef struct {
	uvm_processor_mask_t registered_gpu_va_spaces;
	uvm_rw_semaphore_t lock;
	uvm_sva_va_space_t sva;
} uvm_ats_va_space_t;

typedef struct {
	long unsigned int *bits;
} uvm_bit_locks_t;

struct uvmGpuTsg_tag;

typedef struct uvmGpuTsg_tag *uvmGpuTsgHandle;

struct mutex {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

typedef struct {
	struct mutex m;
} uvm_mutex_t;

struct semaphore {
	long: 64;
	long: 64;
	long: 64;
};

typedef struct {
	struct semaphore sem;
} uvm_semaphore_t;

struct uvm_channel_manager_struct;

typedef struct uvm_channel_manager_struct uvm_channel_manager_t;

struct uvm_rm_mem_struct;

typedef struct uvm_rm_mem_struct uvm_rm_mem_t;

struct UvmCslContext_tag;

typedef struct UvmCslContext_tag UvmCslContext;

typedef struct {
	uvm_channel_manager_t *manager;
	uvmGpuTsgHandle *tsg_handles;
	NvU32 num_tsgs;
	uvm_channel_t *channels;
	NvU32 num_channels;
	unsigned int engine_index;
	uvm_channel_pool_type_t pool_type;
	long: 0;
	union {
		uvm_spinlock_t spinlock;
		uvm_mutex_t mutex;
	};
	struct {
		long unsigned int push_locks[1];
		uvm_semaphore_t push_sem;
		uvm_rm_mem_t *pool_sysmem;
		uvm_rm_mem_t *pool_vidmem;
		struct {
			NvU32 version;
			long: 0;
			uvm_mutex_t mutex;
			UvmCslContext **csl_contexts;
			unsigned int num_csl_contexts;
			atomic64_t encrypted;
			atomic64_t decrypted;
		} key_rotation;
	} conf_computing;
} uvm_channel_pool_t;

typedef struct {
	struct list_head free_dma_buffers;
	size_t num_dma_buffers;
	uvm_mutex_t lock;
} uvm_conf_computing_dma_buffer_pool_t;

typedef struct {
	long unsigned int big_chunks[1];
	void *slots[32];
} uvm_cpu_chunk_storage_mixed_t;

typedef struct {
	int numa_node;
	uvm_processor_mask_t gpus;
} uvm_cpu_gpu_affinity_t;

struct page;

struct uvm_cpu_chunk_struct {
	uvm_cpu_chunk_type_t type: 2;
	size_t log2_size: 5;
	nv_kref_t refcount;
	struct page *page;
};

typedef struct uvm_cpu_chunk_struct uvm_cpu_chunk_t;

typedef struct {
	uvm_cpu_chunk_t common;
	uvm_cpu_chunk_t *parent;
	uvm_processor_mask_t mapped_gpus;
} uvm_cpu_logical_chunk_t;

typedef struct {
	NvU8 bitmap;
} uvm_sub_processor_mask_t;

typedef struct {
	NvU64 dma_addr;
	NvU32 map_count;
	uvm_sub_processor_mask_t sub_processors;
} uvm_cpu_phys_mapping_t;

typedef struct {
	long unsigned int bitmap[1];
} uvm_parent_processor_mask_t;

typedef struct {
	uvm_cpu_chunk_t common;
	uvm_mutex_t lock;
	struct {
		union {
			uvm_cpu_phys_mapping_t static_entry;
			uvm_cpu_phys_mapping_t *dynamic_entries;
		};
		size_t max_entries;
		uvm_parent_processor_mask_t dma_addrs_mask;
	} gpu_mappings;
	long unsigned int *dirty_bitmap;
} uvm_cpu_physical_chunk_t;

typedef struct {
	uvm_deferred_free_object_type_t type;
	long: 0;
	struct list_head list_node;
} uvm_deferred_free_object_t;

struct wait_queue_head {
	long: 64;
	long: 64;
	long: 64;
};

typedef struct wait_queue_head wait_queue_head_t;

typedef struct {
	nv_kref_t refcount;
	nv_kref_t va_range_count;
	uvm_gpu_t *gpu;
	NvHandle rm_memory_handle;
	NvU64 *pfns;
	NvU64 pfn_count;
	NvLength page_size;
	uvm_deferred_free_object_t deferred_free;
	struct list_head *deferred_free_list;
	wait_queue_head_t waitq;
} uvm_device_p2p_mem_t;

struct uvm_parent_gpu_struct;

typedef struct uvm_parent_gpu_struct uvm_parent_gpu_t;

typedef struct {
	NvU64 node_start;
	NvU64 node_end;
	uvm_parent_processor_mask_t parent_gpus;
	uvm_parent_gpu_t *routing_table[32];
} uvm_egm_numa_node_info_t;

struct uvm_range_tree_node_struct {
	NvU64 start;
	NvU64 end;
	struct rb_node rb_node;
	struct list_head list;
};

typedef struct {
	uvm_gpu_t *gpu;
	NvHandle rm_handle;
	nv_kref_t ref_count;
} uvm_ext_gpu_mem_handle;

struct uvm_page_tree_struct;

typedef struct uvm_page_tree_struct uvm_page_tree_t;

struct uvm_page_table_range_struct;

typedef struct uvm_page_table_range_struct uvm_page_table_range_t;

struct uvm_page_table_range_vec_struct {
	uvm_page_tree_t *tree;
	NvU64 start;
	NvU64 size;
	NvU64 page_size;
	uvm_page_table_range_t *ranges;
	size_t range_count;
};

typedef struct uvm_page_table_range_vec_struct uvm_page_table_range_vec_t;

typedef struct {
	uvm_range_tree_node_t node;
	uvm_ext_gpu_mem_handle *mem_handle;
	uvm_tracker_t tracker;
	uvm_gpu_t *gpu;
	uvm_gpu_t *owning_gpu;
	bool is_sysmem;
	bool is_egm;
	uvm_page_table_range_vec_t pt_range_vec;
	uvm_deferred_free_object_t deferred_free;
} uvm_ext_gpu_map_t;

typedef struct {
	uvm_mutex_t lock;
	uvm_range_tree_t tree;
} uvm_ext_gpu_range_tree_t;

struct ccslContext_t;

struct UvmCslContext_tag {
	struct ccslContext_t *ctx;
	void *nvidia_stack;
};

struct Device;

union UvmFaultMetadataPacket_tag;

typedef union UvmFaultMetadataPacket_tag UvmFaultMetadataPacket;

struct UvmGpuFaultInfo_tag {
	struct {
		volatile NvU32 *pFaultBufferGet;
		volatile NvU32 *pFaultBufferPut;
		volatile NvU32 *pFaultBufferInfo;
		volatile NvU32 *pPmcIntr;
		volatile NvU32 *pPmcIntrEnSet;
		volatile NvU32 *pPmcIntrEnClear;
		volatile NvU32 *pPrefetchCtrl;
		NvU32 replayableFaultMask;
		void *bufferAddress;
		NvU32 bufferSize;
		UvmFaultMetadataPacket *bufferMetadata;
		UvmCslContext cslCtx;
	} replayable;
	struct {
		void *shadowBufferAddress;
		void *shadowBufferContext;
		NvU32 bufferSize;
		void *isr_sp;
		void *isr_bh_sp;
		volatile NvU32 *pFaultBufferPut;
		NvU32 shadowBufferGet;
		UvmFaultMetadataPacket *shadowBufferMetadata;
	} nonReplayable;
	NvHandle faultBufferHandle;
	struct Device *pDevice;
};

typedef struct UvmGpuFaultInfo_tag UvmGpuFaultInfo;

typedef struct {
	NvU64 address;
	uvm_aperture_t aperture;
} uvm_gpu_phys_address_t;

typedef struct {
	uvm_fault_client_type_t client_type: 2;
	uvm_mmu_engine_type_t mmu_engine_type: 3;
	NvU16 client_id;
	NvU16 mmu_engine_id;
	union {
		struct {
			NvU16 utlb_id;
			NvU8 gpc_id;
		};
		NvU16 channel_id;
	};
	NvU8 ve_id;
} uvm_fault_source_t;

struct uvm_fault_buffer_entry_struct {
	NvU64 fault_address;
	NvU64 timestamp;
	uvm_gpu_phys_address_t instance_ptr;
	uvm_fault_source_t fault_source;
	uvm_fault_type_t fault_type: 6;
	uvm_fault_access_type_t fault_access_type: 4;
	uvm_va_space_t *va_space;
	uvm_gpu_t *gpu;
	bool is_fatal: 1;
	bool is_throttled: 1;
	bool is_invalid_prefetch: 1;
	bool is_replayable: 1;
	bool is_virtual: 1;
	bool in_protected_mode: 1;
	bool filtered: 1;
	UvmEventFatalReason fatal_reason: 4;
	union {
		struct {
			uvm_fault_cancel_va_mode_t cancel_va_mode: 2;
		} replayable;
		struct {
			NvU32 buffer_index;
		} non_replayable;
	};
	struct list_head merged_instances_list;
	NvU32 access_type_mask;
	NvU16 num_instances;
};

typedef struct {
	NvU32 num_pending_faults;
	bool has_fatal_faults;
	bool in_lockdown;
	bool cancelled;
	uvm_fault_buffer_entry_t prev_fatal_fault;
	uvm_fault_buffer_entry_t *last_fault;
} uvm_fault_utlb_info_t;

struct uvm_fault_service_batch_context_struct {
	uvm_fault_buffer_entry_t *fault_cache;
	uvm_fault_buffer_entry_t **ordered_fault_cache;
	uvm_fault_utlb_info_t *utlbs;
	NvU32 max_utlb_id;
	NvU32 num_cached_faults;
	NvU32 num_coalesced_faults;
	uvm_va_space_t *fatal_va_space;
	uvm_gpu_t *fatal_gpu;
	bool has_throttled_faults;
	NvU32 num_invalid_prefetch_faults;
	NvU32 num_duplicate_faults;
	NvU32 num_replays;
	uvm_ats_fault_context_t ats_context;
	NvU32 batch_id;
	uvm_tracker_t tracker;
	bool is_single_instance_ptr;
	uvm_fault_buffer_entry_t *last_fault;
};

typedef struct uvm_fault_service_batch_context_struct uvm_fault_service_batch_context_t;

typedef struct {
	uvm_page_mask_t page_mask;
	unsigned int count;
} uvm_prot_page_mask_array_t[3];

typedef struct {
	uvm_page_mask_t **node_masks;
	nodemask_t nodes;
} uvm_make_resident_page_tracking_t;

struct uvm_make_resident_context_struct {
	uvm_page_mask_t page_mask;
	uvm_page_mask_t copy_resident_pages_mask;
	uvm_page_mask_t pages_staged;
	uvm_page_mask_t pages_migrated;
	uvm_page_mask_t pages_changed_residency;
	uvm_processor_mask_t all_involved_processors;
	uvm_page_mask_t node_pages_mask;
	uvm_processor_id_t dest_id;
	int dest_nid;
	uvm_make_resident_page_tracking_t cpu_pages_used;
	uvm_make_resident_cause_t cause;
	NvU32 access_counters_buffer_index;
};

typedef struct {
	bool pte_is_2m;
	bool needs_4k;
	long unsigned int big_ptes[1];
	long unsigned int big_ptes_covered[1];
} uvm_va_block_new_pte_state_t;

typedef struct {
	uvm_push_t *push;
	char *next_data;
} uvm_push_inline_data_t;

struct uvm_pte_batch_struct {
	uvm_push_t *push;
	uvm_push_inline_data_t inline_data;
	bool inlining;
	uvm_gpu_phys_address_t pte_first_address;
	NvU32 pte_entry_size;
	NvU64 pte_bits_queue[4];
	NvU32 pte_count;
	uvm_membar_t membar;
};

typedef struct uvm_pte_batch_struct uvm_pte_batch_t;

typedef struct {
	NvU64 start;
	NvU64 size;
	NvU64 page_sizes;
} uvm_tlb_batch_range_t;

struct uvm_tlb_batch_struct {
	uvm_page_tree_t *tree;
	union {
		NvU32 total_pages;
		NvU32 total_ranges;
	};
	uvm_tlb_batch_range_t ranges[4];
	NvU32 count;
	NvU64 biggest_page_size;
	uvm_membar_t membar;
};

typedef struct uvm_tlb_batch_struct uvm_tlb_batch_t;

struct migrate_vma {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct vm_area_struct;

typedef struct {
	uvm_page_mask_t caller_page_mask;
	uvm_processor_mask_t caller_processor_mask;
	uvm_page_mask_t scratch_page_mask;
	nodemask_t scratch_node_mask;
	uvm_processor_mask_t scratch_processor_mask;
	uvm_processor_mask_t map_processors_eviction;
	uvm_processor_mask_t unmap_processors_mask;
	uvm_processor_mask_t fast_access_mask;
	struct uvm_make_resident_context_struct make_resident;
	struct {
		uvm_page_mask_t map_running_page_mask;
		uvm_page_mask_t revoke_running_page_mask;
		uvm_page_mask_t big_split_page_mask;
		uvm_processor_mask_t non_uvm_lite_gpus;
		uvm_page_mask_t page_mask;
		uvm_page_mask_t filtered_page_mask;
		uvm_page_mask_t migratable_mask;
		uvm_va_block_new_pte_state_t new_pte_state;
		uvm_pte_batch_t pte_batch;
		uvm_tlb_batch_t tlb_batch;
		UvmEventMapRemoteCause cause;
	} mapping;
	uvm_prot_page_mask_array_t mask_by_prot;
	struct {
		uvm_page_mask_t running_page_mask;
	} update_read_duplicated_pages;
	struct mm_struct *mm;
	struct {
		long unsigned int src_pfns[512];
		union {
			long unsigned int dst_pfns[512];
			struct page *pages[512];
		};
		struct vm_area_struct *vma;
		uvm_processor_mask_t map_processors_eviction;
		struct migrate_vma migrate_vma_args;
	} hmm;
	char page_mask_string_buffer[136];
} uvm_va_block_context_t;

typedef struct {
	uvm_page_mask_t prefetch_pages_mask;
	uvm_processor_id_t residency;
} uvm_perf_prefetch_hint_t;

struct vm_fault;

struct uvm_service_block_context_struct {
	uvm_service_operation_t operation;
	uvm_processor_mask_t resident_processors;
	uvm_processor_mask_t gpus_to_check_for_nvlink_errors;
	uvm_va_block_region_t region;
	NvU8 access_type[512];
	unsigned int num_retries;
	uvm_page_mask_t thrashing_pin_mask;
	unsigned int thrashing_pin_count;
	uvm_page_mask_t read_duplicate_mask;
	unsigned int read_duplicate_count;
	struct {
		struct list_head service_context_list;
		uvm_processor_mask_t gpus_to_check_for_ecc;
		NvU64 wakeup_time_stamp;
		bool did_migrate;
		long unsigned int notifier_seq;
		struct vm_fault *vmf;
	} cpu_fault;
	uvm_prot_page_mask_array_t mappings_by_prot;
	uvm_page_mask_t did_not_migrate_mask;
	uvm_page_mask_t revocation_mask;
	uvm_processor_mask_t update_processors;
	struct {
		uvm_page_mask_t new_residency;
	} per_processor_masks[257];
	uvm_va_block_context_t *block_context;
	uvm_perf_prefetch_hint_t prefetch_hint;
	uvm_perf_prefetch_bitmap_tree_t prefetch_bitmap_tree;
	NvU32 access_counters_buffer_index;
};

typedef struct uvm_service_block_context_struct uvm_service_block_context_t;

struct uvm_ats_fault_invalidate_struct {
	bool tlb_batch_pending;
	uvm_tlb_batch_t tlb_batch;
};

typedef struct uvm_ats_fault_invalidate_struct uvm_ats_fault_invalidate_t;

struct uvm_replayable_fault_buffer_struct {
	NvU32 max_faults;
	NvU32 cached_get;
	NvU32 cached_put;
	uvm_perf_fault_replay_policy_t replay_policy;
	uvm_tracker_t replay_tracker;
	NvU32 replay_update_put_ratio;
	struct {
		NvU64 num_prefetch_faults;
		NvU64 num_read_faults;
		NvU64 num_write_faults;
		NvU64 num_atomic_faults;
		NvU64 num_duplicate_faults;
		atomic64_t num_pages_out;
		atomic64_t num_pages_in;
		NvU64 num_replays;
		NvU64 num_replays_ack_all;
	} stats;
	NvU32 utlb_count;
	uvm_fault_service_batch_context_t batch_service_context;
	uvm_service_block_context_t block_service_context;
	uvm_ats_fault_invalidate_t ats_invalidate;
};

struct uvm_non_replayable_fault_buffer_struct {
	NvU32 max_faults;
	uvm_tracker_t clear_faulted_tracker;
	void *shadow_buffer_copy;
	uvm_fault_buffer_entry_t *fault_cache;
	struct {
		NvU64 num_read_faults;
		NvU64 num_write_faults;
		NvU64 num_atomic_faults;
		NvU64 num_physical_faults;
		atomic64_t num_pages_out;
		atomic64_t num_pages_in;
	} stats;
	uvm_tracker_t fault_service_tracker;
	uvm_service_block_context_t block_service_context;
	NvU32 batch_id;
	uvm_ats_fault_context_t ats_context;
	uvm_ats_fault_invalidate_t ats_invalidate;
};

typedef struct {
	UvmGpuFaultInfo rm_info;
	NvU32 max_batch_size;
	struct uvm_replayable_fault_buffer_struct replayable;
	struct uvm_non_replayable_fault_buffer_struct non_replayable;
	bool prefetch_faults_enabled;
	NvU64 disable_prefetch_faults_timestamp;
} uvm_fault_buffer_t;

typedef struct {
	NvU32 encrypted_payload;
	uvm_gpu_semaphore_notifier_t notifier;
	NvU64 unused;
	NvU8 auth_tag[16];
} uvm_gpu_encrypted_semaphore_payload_t;

typedef struct {
	NvU64 base;
	uvm_page_table_range_vec_t *range_vec;
	bool ready;
} uvm_gpu_identity_mapping_t;

typedef struct {
	NvU64 ref_count;
} uvm_gpu_peer_t;

typedef struct {
	uvm_page_table_range_t *range;
	NvU32 num_mapped_pages;
} uvm_gpu_root_chunk_mapping_t;

typedef void (*uvm_hal_init_t)(uvm_push_t *);

typedef bool (*uvm_hal_host_method_is_valid)(uvm_push_t *, NvU32, NvU32);

typedef bool (*uvm_hal_host_sw_method_is_valid)(uvm_push_t *, NvU32, NvU32);

typedef void (*uvm_hal_wait_for_idle_t)(uvm_push_t *);

typedef void (*uvm_hal_membar_sys_t)(uvm_push_t *);

typedef void (*uvm_hal_membar_gpu_t)(uvm_push_t *);

typedef void (*uvm_hal_noop_t)(uvm_push_t *, NvU32);

typedef void (*uvm_hal_interrupt_t)(uvm_push_t *);

typedef void (*uvm_hal_semaphore_release_t)(uvm_push_t *, NvU64, NvU32);

typedef void (*uvm_hal_semaphore_acquire_t)(uvm_push_t *, NvU64, NvU32);

typedef void (*uvm_hal_semaphore_timestamp_t)(uvm_push_t *, NvU64);

typedef bool (*uvm_hal_semaphore_target_is_valid_t)(uvm_push_t *, NvU64);

typedef void (*uvm_hal_host_set_gpfifo_entry_t)(NvU64 *, NvU64, NvU32, uvm_gpfifo_sync_t);

typedef void (*uvm_hal_host_set_gpfifo_noop_t)(NvU64 *);

typedef void (*uvm_hal_host_set_gpfifo_pushbuffer_segment_base_t)(NvU64 *, NvU64);

typedef void (*uvm_hal_host_write_gpu_put_t)(uvm_channel_t *, NvU32);

typedef void (*uvm_hal_host_tlb_invalidate_all_t)(uvm_push_t *, uvm_gpu_phys_address_t, NvU32, uvm_membar_t);

typedef void (*uvm_hal_host_tlb_invalidate_va_t)(uvm_push_t *, uvm_gpu_phys_address_t, NvU32, NvU64, NvU64, NvU64, uvm_membar_t);

typedef void (*uvm_hal_host_tlb_invalidate_test_t)(uvm_push_t *, uvm_gpu_phys_address_t, UVM_TEST_INVALIDATE_TLB_PARAMS *);

typedef void (*uvm_hal_fault_buffer_replay_t)(uvm_push_t *, uvm_fault_replay_type_t);

typedef void (*uvm_hal_fault_cancel_global_t)(uvm_push_t *, uvm_gpu_phys_address_t);

typedef void (*uvm_hal_fault_cancel_targeted_t)(uvm_push_t *, uvm_gpu_phys_address_t, NvU32, NvU32);

typedef void (*uvm_hal_fault_cancel_va_t)(uvm_push_t *, uvm_gpu_phys_address_t, const uvm_fault_buffer_entry_t *, uvm_fault_cancel_va_mode_t);

struct uvm_user_channel_struct;

typedef struct uvm_user_channel_struct uvm_user_channel_t;

typedef void (*uvm_hal_host_clear_faulted_channel_method_t)(uvm_push_t *, uvm_user_channel_t *, const uvm_fault_buffer_entry_t *);

typedef void (*uvm_hal_host_clear_faulted_channel_register_t)(uvm_user_channel_t *, const uvm_fault_buffer_entry_t *);

typedef void (*uvm_hal_access_counter_clear_all_t)(uvm_push_t *);

struct uvm_access_counter_buffer_entry_struct;

typedef struct uvm_access_counter_buffer_entry_struct uvm_access_counter_buffer_entry_t;

typedef void (*uvm_hal_access_counter_clear_targeted_t)(uvm_push_t *, const uvm_access_counter_buffer_entry_t *);

typedef uvm_access_counter_clear_op_t (*uvm_hal_access_counter_query_clear_op_t)(uvm_parent_gpu_t *, uvm_access_counter_buffer_entry_t **, NvU32);

typedef NvU64 (*uvm_hal_get_time_t)(uvm_gpu_t *);

struct uvm_host_hal_struct {
	uvm_hal_init_t init;
	uvm_hal_host_method_is_valid method_is_valid;
	uvm_hal_host_sw_method_is_valid sw_method_is_valid;
	uvm_hal_wait_for_idle_t wait_for_idle;
	uvm_hal_membar_sys_t membar_sys;
	uvm_hal_membar_gpu_t membar_gpu;
	uvm_hal_noop_t noop;
	uvm_hal_interrupt_t interrupt;
	uvm_hal_semaphore_release_t semaphore_release;
	uvm_hal_semaphore_acquire_t semaphore_acquire;
	uvm_hal_semaphore_timestamp_t semaphore_timestamp;
	uvm_hal_semaphore_target_is_valid_t semaphore_target_is_valid;
	uvm_hal_host_set_gpfifo_entry_t set_gpfifo_entry;
	uvm_hal_host_set_gpfifo_noop_t set_gpfifo_noop;
	uvm_hal_host_set_gpfifo_pushbuffer_segment_base_t set_gpfifo_pushbuffer_segment_base;
	uvm_hal_host_write_gpu_put_t write_gpu_put;
	uvm_hal_host_tlb_invalidate_all_t tlb_invalidate_all;
	uvm_hal_host_tlb_invalidate_va_t tlb_invalidate_va;
	uvm_hal_host_tlb_invalidate_test_t tlb_invalidate_test;
	uvm_hal_fault_buffer_replay_t replay_faults;
	uvm_hal_fault_cancel_global_t cancel_faults_global;
	uvm_hal_fault_cancel_targeted_t cancel_faults_targeted;
	uvm_hal_fault_cancel_va_t cancel_faults_va;
	uvm_hal_host_clear_faulted_channel_method_t clear_faulted_channel_sw_method;
	uvm_hal_host_clear_faulted_channel_method_t clear_faulted_channel_method;
	uvm_hal_host_clear_faulted_channel_register_t clear_faulted_channel_register;
	uvm_hal_access_counter_clear_all_t access_counter_clear_all;
	uvm_hal_access_counter_clear_targeted_t access_counter_clear_targeted;
	uvm_hal_access_counter_query_clear_op_t access_counter_query_clear_op;
	uvm_hal_get_time_t get_time;
};

typedef struct uvm_host_hal_struct uvm_host_hal_t;

typedef bool (*uvm_hal_ce_method_is_valid)(uvm_push_t *, NvU32, NvU32);

typedef void (*uvm_hal_ce_offset_out_t)(uvm_push_t *, NvU64);

typedef void (*uvm_hal_ce_offset_in_out_t)(uvm_push_t *, NvU64, NvU64);

typedef NvU32 (*uvm_hal_ce_phys_mode_t)(uvm_push_t *, uvm_gpu_address_t, uvm_gpu_address_t);

typedef NvU32 (*uvm_hal_ce_plc_mode_t)(void);

typedef NvU32 (*uvm_hal_ce_memcopy_type_t)(uvm_gpu_address_t, uvm_gpu_address_t);

typedef bool (*uvm_hal_ce_memcopy_is_valid)(uvm_push_t *, uvm_gpu_address_t, uvm_gpu_address_t);

typedef void (*uvm_hal_ce_memcopy_patch_src)(uvm_push_t *, uvm_gpu_address_t *);

typedef void (*uvm_hal_memcopy_t)(uvm_push_t *, uvm_gpu_address_t, uvm_gpu_address_t, size_t);

typedef void (*uvm_hal_memcopy_v_to_v_t)(uvm_push_t *, NvU64, NvU64, size_t);

typedef bool (*uvm_hal_ce_memset_is_valid)(uvm_push_t *, uvm_gpu_address_t, size_t, size_t);

typedef void (*uvm_hal_memset_1_t)(uvm_push_t *, uvm_gpu_address_t, NvU8, size_t);

typedef void (*uvm_hal_memset_4_t)(uvm_push_t *, uvm_gpu_address_t, NvU32, size_t);

typedef void (*uvm_hal_memset_8_t)(uvm_push_t *, uvm_gpu_address_t, NvU64, size_t);

typedef void (*uvm_hal_memset_v_4_t)(uvm_push_t *, NvU64, NvU32, size_t);

typedef void (*uvm_hal_semaphore_reduction_inc_t)(uvm_push_t *, NvU64, NvU32);

typedef void (*uvm_hal_ce_encrypt_t)(uvm_push_t *, uvm_gpu_address_t, uvm_gpu_address_t, NvU32, uvm_gpu_address_t);

typedef void (*uvm_hal_ce_decrypt_t)(uvm_push_t *, uvm_gpu_address_t, uvm_gpu_address_t, NvU32, uvm_gpu_address_t);

struct uvm_ce_hal_struct {
	uvm_hal_init_t init;
	uvm_hal_ce_method_is_valid method_is_valid;
	uvm_hal_semaphore_release_t semaphore_release;
	uvm_hal_semaphore_timestamp_t semaphore_timestamp;
	uvm_hal_semaphore_target_is_valid_t semaphore_target_is_valid;
	uvm_hal_ce_offset_out_t offset_out;
	uvm_hal_ce_offset_in_out_t offset_in_out;
	uvm_hal_ce_phys_mode_t phys_mode;
	uvm_hal_ce_plc_mode_t plc_mode;
	uvm_hal_ce_memcopy_type_t memcopy_copy_type;
	uvm_hal_ce_memcopy_is_valid memcopy_is_valid;
	uvm_hal_ce_memcopy_patch_src memcopy_patch_src;
	uvm_hal_memcopy_t memcopy;
	uvm_hal_memcopy_v_to_v_t memcopy_v_to_v;
	uvm_hal_ce_memset_is_valid memset_is_valid;
	uvm_hal_memset_1_t memset_1;
	uvm_hal_memset_4_t memset_4;
	uvm_hal_memset_8_t memset_8;
	uvm_hal_memset_v_4_t memset_v_4;
	uvm_hal_semaphore_reduction_inc_t semaphore_reduction_inc;
	uvm_hal_ce_encrypt_t encrypt;
	uvm_hal_ce_decrypt_t decrypt;
};

typedef struct uvm_ce_hal_struct uvm_ce_hal_t;

typedef void (*uvm_hal_arch_init_properties_t)(uvm_parent_gpu_t *);

struct uvm_mmu_mode_hal_struct;

typedef struct uvm_mmu_mode_hal_struct uvm_mmu_mode_hal_t;

typedef uvm_mmu_mode_hal_t * (*uvm_hal_lookup_mode_hal_t)(NvU64);

typedef void (*uvm_hal_mmu_enable_prefetch_faults_t)(uvm_parent_gpu_t *);

typedef void (*uvm_hal_mmu_disable_prefetch_faults_t)(uvm_parent_gpu_t *);

typedef NvU16 (*uvm_hal_mmu_client_id_to_utlb_id_t)(NvU16);

struct uvm_arch_hal_struct {
	uvm_hal_arch_init_properties_t init_properties;
	uvm_hal_lookup_mode_hal_t mmu_mode_hal;
	uvm_hal_mmu_enable_prefetch_faults_t enable_prefetch_faults;
	uvm_hal_mmu_disable_prefetch_faults_t disable_prefetch_faults;
	uvm_hal_mmu_client_id_to_utlb_id_t mmu_client_id_to_utlb_id;
};

typedef struct uvm_arch_hal_struct uvm_arch_hal_t;

typedef void (*uvm_hal_enable_replayable_faults_t)(uvm_parent_gpu_t *);

typedef void (*uvm_hal_disable_replayable_faults_t)(uvm_parent_gpu_t *);

typedef void (*uvm_hal_clear_replayable_faults_t)(uvm_parent_gpu_t *, NvU32);

typedef NvU32 (*uvm_hal_fault_buffer_read_put_t)(uvm_parent_gpu_t *);

typedef NvU32 (*uvm_hal_fault_buffer_read_get_t)(uvm_parent_gpu_t *);

typedef void (*uvm_hal_fault_buffer_write_get_t)(uvm_parent_gpu_t *, NvU32);

typedef NvU8 (*uvm_hal_fault_buffer_get_ve_id_t)(NvU16, uvm_mmu_engine_type_t);

typedef uvm_mmu_engine_type_t (*uvm_hal_fault_buffer_get_mmu_engine_type_t)(NvU16, uvm_fault_client_type_t, NvU16);

typedef NV_STATUS (*uvm_hal_fault_buffer_parse_replayable_entry_t)(uvm_parent_gpu_t *, NvU32, uvm_fault_buffer_entry_t *);

typedef bool (*uvm_hal_fault_buffer_entry_is_valid_t)(uvm_parent_gpu_t *, NvU32);

typedef void (*uvm_hal_fault_buffer_entry_clear_valid_t)(uvm_parent_gpu_t *, NvU32);

typedef NvU32 (*uvm_hal_fault_buffer_entry_size_t)(uvm_parent_gpu_t *);

typedef void (*uvm_hal_fault_buffer_parse_non_replayable_entry_t)(uvm_parent_gpu_t *, void *, uvm_fault_buffer_entry_t *);

typedef uvm_fault_type_t (*uvm_hal_fault_buffer_get_fault_type_t)(const NvU32 *);

struct uvm_fault_buffer_hal_struct {
	uvm_hal_enable_replayable_faults_t enable_replayable_faults;
	uvm_hal_disable_replayable_faults_t disable_replayable_faults;
	uvm_hal_clear_replayable_faults_t clear_replayable_faults;
	uvm_hal_fault_buffer_read_put_t read_put;
	uvm_hal_fault_buffer_read_get_t read_get;
	uvm_hal_fault_buffer_write_get_t write_get;
	uvm_hal_fault_buffer_get_ve_id_t get_ve_id;
	uvm_hal_fault_buffer_get_mmu_engine_type_t get_mmu_engine_type;
	uvm_hal_fault_buffer_parse_replayable_entry_t parse_replayable_entry;
	uvm_hal_fault_buffer_entry_is_valid_t entry_is_valid;
	uvm_hal_fault_buffer_entry_clear_valid_t entry_clear_valid;
	uvm_hal_fault_buffer_entry_size_t entry_size;
	uvm_hal_fault_buffer_parse_non_replayable_entry_t parse_non_replayable_entry;
	uvm_hal_fault_buffer_get_fault_type_t get_fault_type;
};

typedef struct uvm_fault_buffer_hal_struct uvm_fault_buffer_hal_t;

struct uvm_access_counter_buffer_struct;

typedef struct uvm_access_counter_buffer_struct uvm_access_counter_buffer_t;

typedef void (*uvm_hal_enable_access_counter_notifications_t)(uvm_access_counter_buffer_t *);

typedef void (*uvm_hal_disable_access_counter_notifications_t)(uvm_access_counter_buffer_t *);

typedef void (*uvm_hal_clear_access_counter_notifications_t)(uvm_access_counter_buffer_t *, NvU32);

typedef void (*uvm_hal_access_counter_buffer_parse_entry_t)(uvm_access_counter_buffer_t *, NvU32, uvm_access_counter_buffer_entry_t *);

typedef bool (*uvm_hal_access_counter_buffer_entry_is_valid_t)(uvm_access_counter_buffer_t *, NvU32);

typedef void (*uvm_hal_access_counter_buffer_entry_clear_valid_t)(uvm_access_counter_buffer_t *, NvU32);

typedef NvU32 (*uvm_hal_access_counter_buffer_entry_size_t)(uvm_parent_gpu_t *);

struct uvm_access_counter_buffer_hal_struct {
	uvm_hal_enable_access_counter_notifications_t enable_access_counter_notifications;
	uvm_hal_disable_access_counter_notifications_t disable_access_counter_notifications;
	uvm_hal_clear_access_counter_notifications_t clear_access_counter_notifications;
	uvm_hal_access_counter_buffer_parse_entry_t parse_entry;
	uvm_hal_access_counter_buffer_entry_is_valid_t entry_is_valid;
	uvm_hal_access_counter_buffer_entry_clear_valid_t entry_clear_valid;
	uvm_hal_access_counter_buffer_entry_size_t entry_size;
};

typedef struct uvm_access_counter_buffer_hal_struct uvm_access_counter_buffer_hal_t;

typedef void (*uvm_hal_sec2_decrypt_t)(uvm_push_t *, NvU64, NvU64, NvU32, NvU64);

struct uvm_sec2_hal_struct {
	uvm_hal_init_t init;
	uvm_hal_sec2_decrypt_t decrypt;
	uvm_hal_semaphore_release_t semaphore_release;
	uvm_hal_semaphore_timestamp_t semaphore_timestamp;
	uvm_hal_semaphore_target_is_valid_t semaphore_target_is_valid;
};

typedef struct uvm_sec2_hal_struct uvm_sec2_hal_t;

typedef struct {
	NvU32 id;
	NvU32 parent_id;
	union {
		uvm_host_hal_t host_ops;
		uvm_ce_hal_t ce_ops;
		uvm_arch_hal_t arch_ops;
		uvm_fault_buffer_hal_t fault_buffer_ops;
		uvm_access_counter_buffer_hal_t access_counter_buffer_ops;
		uvm_sec2_hal_t sec2_ops;
	} u;
} uvm_hal_class_ops_t;

struct uvm_va_block_retry_struct;

typedef struct uvm_va_block_retry_struct uvm_va_block_retry_t;

typedef struct {
	uvm_processor_id_t processor_id;
	uvm_va_block_t *va_block;
	uvm_va_block_retry_t *va_block_retry;
	uvm_service_block_context_t *service_context;
	uvm_page_mask_t page_mask;
	uvm_page_mask_t same_devmem_page_mask;
} uvm_hmm_devmem_fault_context_t;

typedef struct {
	uvm_processor_id_t processor_id;
	uvm_processor_id_t new_residency;
	uvm_va_block_t *va_block;
	uvm_va_block_retry_t *va_block_retry;
	uvm_service_block_context_t *service_context;
	uvm_page_mask_t page_mask;
	uvm_page_mask_t same_devmem_page_mask;
} uvm_hmm_gpu_fault_event_t;

typedef struct {
	uvm_va_block_t *va_block;
	uvm_va_block_retry_t *va_block_retry;
	uvm_service_block_context_t *service_context;
	uvm_va_block_region_t region;
	uvm_processor_id_t dest_id;
	uvm_make_resident_cause_t cause;
	uvm_page_mask_t page_mask;
	uvm_page_mask_t same_devmem_page_mask;
} uvm_hmm_migrate_event_t;

typedef struct {
	uvm_range_tree_t blocks;
	uvm_mutex_t blocks_lock;
} uvm_hmm_va_space_t;

struct cpumask {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

typedef struct {
	uvm_semaphore_t service_lock;
	nv_kthread_q_item_t bottom_half_q_item;
	union {
		struct {
			bool handling;
			bool was_handling;
		};
		NvU64 handling_ref_count;
	};
	struct {
		NvU64 bottom_half_count;
		struct cpumask cpus_used_mask;
		NvU64 *cpu_exec_count;
	} stats;
	NvU64 disable_intr_ref_count;
} uvm_intr_handler_t;

struct task_struct;

struct nv_kthread_q {
	struct list_head q_list_head;
	spinlock_t q_lock;
	long: 0;
	struct semaphore q_sem;
	atomic_t main_loop_should_exit;
	struct task_struct *q_kthread;
	bool is_unload_flush_ongoing;
};

typedef struct nv_kthread_q nv_kthread_q_t;

typedef struct {
	spinlock_t lock;
	long unsigned int irq_flags;
} uvm_spinlock_irqsave_t;

typedef struct {
	bool is_suspended;
	nv_kthread_q_t bottom_half_q;
	uvm_spinlock_irqsave_t interrupts_lock;
	uvm_intr_handler_t replayable_faults;
	uvm_intr_handler_t non_replayable_faults;
	uvm_intr_handler_t *access_counters;
	nv_kthread_q_t kill_channel_q;
	NvU64 interrupt_count;
} uvm_isr_info_t;

typedef struct {
	const char *file;
	const char *function;
	int line;
	uvm_rb_tree_node_t node;
} uvm_kvmalloc_info_t;

typedef struct {
	NvU64 map_offset;
	UvmGpuMappingType mapping_type;
	UvmGpuCachingType caching_type;
	UvmGpuFormatType format_type;
	UvmGpuFormatElementBits element_bits;
	UvmGpuCompressionType compression_type;
} uvm_map_rm_params_t;

typedef struct {
	uvm_gpu_t *backing_gpu;
	uvm_gpu_t *dma_owner;
	NvU64 size;
	struct mm_struct *mm;
	NvU64 page_size;
	bool zero;
} uvm_mem_alloc_params_t;

typedef struct {
	uvm_prot_t protection;
	bool is_cacheable;
} uvm_mem_gpu_mapping_attrs_t;

typedef struct {
	uvm_processor_mask_t mapped_on;
	uvm_page_table_range_vec_t *range_vecs[256];
	uvm_va_space_t *va_space;
	void *addr;
} uvm_mem_user_mapping_t;

struct mem_cgroup;

typedef struct {
	struct mem_cgroup *new_memcg;
	struct mem_cgroup *old_memcg;
} uvm_memcg_context_t;

typedef struct {
	uvm_gpu_phys_address_t addr;
	NvU64 size;
	union {
		struct page *page;
		uvm_gpu_chunk_t *chunk;
	} handle;
} uvm_mmu_page_table_alloc_t;

typedef struct {
	NvU32 val;
} uvm_parent_processor_id_t;

typedef uvm_parent_processor_id_t uvm_parent_gpu_id_t;

typedef struct {
	NvU64 ref_count;
	NvU8 optimalNvlinkWriteCEs[2];
	NvU8 peer_ids[2];
	NvU8 egm_peer_ids[2];
	uvm_gpu_link_type_t link_type;
	NvU32 total_link_line_rate_mbyte_per_s;
	NvHandle p2p_handle;
	struct {
		struct proc_dir_entry *peer_file[2];
		struct proc_dir_entry *peer_symlink_file[2];
		uvm_parent_gpu_t *pairs[4];
	} procfs;
	uvm_gpu_peer_t gpu_peers[36];
} uvm_parent_gpu_peer_t;

typedef struct {
	void *data;
} uvm_perf_module_data_desc_t;

typedef struct {
	uvm_perf_event_t event_id;
	uvm_perf_event_callback_t callback;
} uvm_perf_module_event_callback_desc_t;

typedef struct {
	s8 level_idx;
	uvm_page_index_t node_idx;
} uvm_perf_prefetch_bitmap_tree_iter_t;

typedef struct {
	uvm_perf_thrashing_hint_type_t type;
	union {
		struct {
			uvm_processor_id_t residency;
			uvm_processor_mask_t processors;
		} pin;
		struct {
			NvU64 end_time_stamp;
		} throttle;
	};
} uvm_perf_thrashing_hint_t;

typedef struct {
	ssize_t node_idx;
	s8 level_idx;
	size_t level_offset;
} uvm_perf_tree_iter_t;

typedef struct {
	size_t leaf_count;
	u8 level_count;
	size_t node_count;
	size_t pow2_leaf_count;
	void *nodes;
} uvm_perf_tree_t;

typedef struct {
	uvm_rw_semaphore_t lock;
	struct list_head event_callbacks[9];
	uvm_va_space_t *va_space;
} uvm_perf_va_space_events_t;

struct dev_pagemap {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

typedef struct {
	struct list_head list_node;
	long unsigned int size;
	struct dev_pagemap pagemap;
} uvm_pmm_gpu_devmem_t;

struct UvmGpuExternalMappingInfo_tag {
	UvmRmGpuCachingType cachingType;
	UvmRmGpuMappingType mappingType;
	UvmRmGpuFormatType formatType;
	UvmRmGpuFormatElementBits elementBits;
	UvmRmGpuCompressionType compressionType;
	NvU64 pteBufferSize;
	NvU64 mappingPageSize;
	NvU64 *pteBuffer;
	NvU64 numWrittenPtes;
	NvU64 numRemainingPtes;
	NvU32 pteSize;
};

typedef struct UvmGpuExternalMappingInfo_tag UvmGpuExternalMappingInfo;

typedef struct {
	uvm_va_range_t *va_range;
	uvm_gpu_t *gpu;
	UvmGpuExternalMappingInfo mapping_info;
	size_t buffer_size;
	NvU64 page_size;
	NvU32 pte_size;
	size_t max_pte_offset;
	size_t num_ptes;
	size_t pte_offset;
} uvm_pte_buffer_t;

typedef struct {
	NvU32 next_push_start;
	long: 0;
	struct list_head pending_gpfifos;
	uvm_push_t *current_push;
} uvm_pushbuffer_chunk_t;

typedef struct {
	int rm_control_fd;
	NvHandle user_client;
	NvHandle user_object;
} uvm_rm_user_object_t;

typedef struct {
	NvU64 start_time_ns;
	NvU64 print_time_ns;
} uvm_spin_loop_t;

struct xarray {
	long: 64;
	long: 64;
};

typedef struct {
	struct xarray page_tree;
	uvm_mutex_t mutex;
} uvm_test_file_t;

typedef struct {
	bool access_counters_alloc_buffer;
	bool access_counters_alloc_block_context;
	bool isr_access_counters_alloc;
	bool isr_access_counters_alloc_stats_cpu;
	bool access_counters_batch_context_notifications;
	bool access_counters_batch_context_notification_cache;
} uvm_test_parent_gpu_inject_error_t;

struct uvm_push_struct {
	NvU32 *begin;
	NvU32 *next;
	uvm_gpu_t *gpu;
	uvm_channel_t *channel;
	NvU64 channel_tracking_value;
	NvU32 push_info_index;
	long unsigned int flags[1];
	UvmCslIv launch_iv;
	uvm_channel_t *launch_channel;
};

struct uvm_gpu_semaphore_pool_page_struct;

typedef struct uvm_gpu_semaphore_pool_page_struct uvm_gpu_semaphore_pool_page_t;

struct uvm_gpu_semaphore_struct {
	uvm_gpu_semaphore_pool_page_t *page;
	NvU16 index;
	struct {
		UvmCslIv *ivs;
		NvU32 cached_payload;
		uvm_gpu_semaphore_notifier_t last_pushed_notifier;
		uvm_gpu_semaphore_notifier_t last_observed_notifier;
	} conf_computing;
};

typedef struct uvm_gpu_semaphore_struct uvm_gpu_semaphore_t;

typedef struct {
	uvm_push_t push;
	uvm_tracker_t tracker;
	uvm_gpu_semaphore_t semaphore;
	NvU32 queued_counter_value;
	NvU32 queued_counter_repeat;
	uvm_rm_mem_t *counter_mem;
	uvm_rm_mem_t *counter_snapshots_mem;
	uvm_rm_mem_t *other_stream_counter_snapshots_mem;
	NvU32 *counter_snapshots;
	NvU32 *other_stream_counter_snapshots;
	NvU32 *other_stream_counter_expected;
} uvm_test_stream_t;

struct uvm_thread_context_struct;

typedef struct uvm_thread_context_struct uvm_thread_context_t;

typedef struct {
	atomic64_t task;
	uvm_thread_context_t *thread_context;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
} uvm_thread_context_array_entry_t;

typedef struct {
	void *acquired[38];
} uvm_thread_context_lock_acquired_t;

typedef struct {
	uvm_thread_context_array_entry_t array[8];
	struct rb_root tree;
	spinlock_t tree_lock;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
} uvm_thread_context_table_entry_t;

typedef struct {
	struct list_head counter_nodes[10];
	NvU64 subscribed_counters;
	struct page **counter_buffer_pages;
	NvU64 *counters;
	bool all_processors;
	NvProcessorUuid processor;
} uvm_tools_counter_t;

struct UvmEventControlData_tag;

typedef struct UvmEventControlData_tag UvmToolsEventControlData;

typedef struct {
	uvm_spinlock_t lock;
	NvU64 subscribed_queues;
	struct list_head queue_nodes[64];
	struct page **queue_buffer_pages;
	void *queue_buffer;
	NvU32 queue_buffer_count;
	NvU32 notification_threshold;
	struct page **control_buffer_pages;
	UvmToolsEventControlData *control;
	wait_queue_head_t wait_queue;
	bool is_wakeup_get_valid;
	NvU32 wakeup_get;
} uvm_tools_queue_t;

struct file;

typedef struct {
	size_t entry_size;
	bool is_queue;
	struct file *uvm_file;
	union {
		uvm_tools_queue_t queue;
		uvm_tools_counter_t counter;
	};
} uvm_tools_event_tracker_t;

typedef struct {
	NvU32 get_ahead;
	NvU32 get_behind;
	NvU32 put_ahead;
	NvU32 put_behind;
} uvm_tools_queue_snapshot_t;

struct uvm_gpu_va_space_struct;

typedef struct uvm_gpu_va_space_struct uvm_gpu_va_space_t;

typedef struct {
	NvU32 total_refcount;
	NvU32 smc_engine_id;
	struct {
		uvm_gpu_va_space_t *gpu_va_space;
		NvU32 refcount;
	} *subctxs;
	uvm_rb_tree_node_t node;
} uvm_user_channel_subctx_info_t;

typedef struct {
	uvm_page_mask_t resident;
	uvm_page_mask_t allocated;
	long unsigned int chunks;
} uvm_va_block_cpu_node_state_t;

struct uvm_page_directory_struct;

typedef struct uvm_page_directory_struct uvm_page_directory_t;

struct uvm_page_table_range_struct {
	uvm_page_directory_t *table;
	NvU32 start_index;
	NvU32 entry_count;
	NvU64 page_size;
};

typedef struct {
	uvm_page_mask_t resident;
	uvm_page_mask_t evicted;
	uvm_gpu_chunk_t **chunks;
	uvm_page_table_range_t page_table_range_2m;
	uvm_page_table_range_t page_table_range_big;
	uvm_page_table_range_t page_table_range_4k;
	bool activated_big;
	bool activated_4k;
	bool initialized_big;
	bool force_4k_ptes;
	bool pte_is_2m;
	long unsigned int big_ptes[1];
	uvm_page_mask_t pte_bits[3];
	uvm_page_mask_t egm_pages;
} uvm_va_block_gpu_state_t;

typedef struct {
	struct vm_area_struct *vma;
	uvm_rw_semaphore_t lock;
} uvm_vma_wrapper_t;

typedef struct {
	size_t alloc_size;
	uint8_t ptr[0];
} uvm_vmalloc_hdr_t;

typedef struct {
	atomic_t enable_migrations;
	uvm_va_space_t *va_space;
} va_space_access_counters_info_t;

struct delayed_work {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

typedef struct {
	struct {
		struct delayed_work dwork;
		struct list_head list;
		uvm_spinlock_t lock;
		uvm_va_block_context_t *va_block_context;
		bool in_va_space_teardown;
	} pinned_pages;
	struct {
		bool enable;
		bool test_overrides;
		unsigned int threshold;
		unsigned int pin_threshold;
		NvU64 lapse_ns;
		NvU64 nap_ns;
		NvU64 epoch_ns;
		unsigned int max_resets;
		NvU64 pin_ns;
	} params;
	uvm_va_space_t *va_space;
} va_space_thrashing_info_t;

struct NvNotificationRec {
	struct {
		NvU32 nanoseconds[2];
	} timeStamp;
	NvV32 info32;
	NvV16 info16;
	NvV16 status;
};

typedef volatile struct NvNotificationRec NvNotification;

struct NvStatusCodeString {
	NV_STATUS statusCode;
	const char *statusString;
};

struct UvmEventControlData_tag {
	volatile NvU32 get_ahead;
	volatile NvU32 get_behind;
	volatile NvU32 put_ahead;
	volatile NvU32 put_behind;
	NvU64 dropped[64];
};

union UvmFaultMetadataPacket_tag {
	struct {
		NvU8 authTag[16];
		NvBool valid;
	};
	NvU8 _padding[32];
};

struct UvmGpuAccessCntrConfig_tag {
	NvU32 granularity;
	NvU32 threshold;
};

typedef struct UvmGpuAccessCntrConfig_tag UvmGpuAccessCntrConfig;

struct UvmGpuAccessCntrInfo_tag {
	volatile NvU32 *pAccessCntrBufferGet;
	volatile NvU32 *pAccessCntrBufferPut;
	volatile NvU32 *pAccessCntrBufferFull;
	volatile NvU32 *pHubIntr;
	volatile NvU32 *pHubIntrEnSet;
	volatile NvU32 *pHubIntrEnClear;
	NvU32 accessCounterMask;
	void *bufferAddress;
	NvU32 bufferSize;
	NvHandle accessCntrBufferHandle;
};

typedef struct UvmGpuAccessCntrInfo_tag UvmGpuAccessCntrInfo;

struct UvmGpuAddressSpaceInfo_tag {
	NvU64 bigPageSize;
	NvBool atsEnabled;
	volatile NvU32 *time0Offset;
	volatile NvU32 *time1Offset;
	NvU32 maxSubctxCount;
	NvBool smcEnabled;
	NvU32 smcSwizzId;
	NvU32 smcGpcCount;
};

typedef struct UvmGpuAddressSpaceInfo_tag UvmGpuAddressSpaceInfo;

struct UvmGpuAllocInfo_tag {
	NvU64 gpuPhysOffset;
	NvU64 pageSize;
	NvU64 alignment;
	NvBool bContiguousPhysAlloc;
	NvBool bMemGrowsDown;
	NvBool bPersistentVidmem;
	NvHandle hPhysHandle;
	NvBool bUnprotected;
};

typedef struct UvmGpuAllocInfo_tag UvmGpuAllocInfo;

struct UvmGpuCaps_tag {
	NvBool numaEnabled;
	NvU32 numaNodeId;
};

typedef struct UvmGpuCaps_tag UvmGpuCaps;

struct UvmGpuChannelAllocParams_tag {
	NvU32 numGpFifoEntries;
	NvU32 gpFifoLoc;
	NvU32 gpPutLoc;
};

typedef struct UvmGpuChannelAllocParams_tag UvmGpuChannelAllocParams;

struct UvmGpuChannelInfo_tag {
	volatile unsigned int *gpGet;
	volatile unsigned int *gpPut;
	UvmGpuPointer *gpFifoEntries;
	unsigned int numGpFifoEntries;
	unsigned int channelClassNum;
	NvNotification *errorNotifier;
	NvNotification *keyRotationNotifier;
	NvU32 hwRunlistId;
	NvU32 hwChannelId;
	volatile unsigned int *dummyBar1Mapping;
	volatile NvU32 *workSubmissionOffset;
	NvU32 workSubmissionToken;
	volatile NvU32 *pWorkSubmissionToken;
	NvU64 gpFifoGpuVa;
	NvU64 gpPutGpuVa;
	NvU64 gpGetGpuVa;
	NvU64 workSubmissionOffsetGpuVa;
};

typedef struct UvmGpuChannelInfo_tag UvmGpuChannelInfo;

typedef void *NvP64;

struct UvmGpuMemoryInfo_tag {
	NvU32 kind;
	NvBool sysmem;
	NvBool egm;
	NvBool deviceDescendant;
	NvU64 pageSize;
	NvBool contig;
	NvU64 physAddr;
	NvU64 size;
	NvProcessorUuid uuid;
};

typedef struct UvmGpuMemoryInfo_tag UvmGpuMemoryInfo;

struct UvmGpuChannelResourceInfo_tag {
	NvP64 resourceDescriptor;
	NvU32 resourceId;
	NvU64 alignment;
	UvmGpuMemoryInfo resourceInfo;
};

typedef struct UvmGpuChannelResourceInfo_tag UvmGpuChannelResourceInfo;

struct UvmGpuChannelInstanceInfo_tag {
	NvU64 base;
	NvBool sysmem;
	NvU32 runlistId;
	NvU32 chId;
	NvBool bInSubctx;
	NvU32 subctxId;
	NvBool bTsgChannel;
	NvU32 tsgId;
	NvU32 tsgMaxSubctxCount;
	UvmGpuChannelResourceInfo resourceInfo[13];
	NvU32 resourceCount;
	NvU32 channelEngineType;
	NvU32 clearFaultedToken;
	volatile NvU32 *pChramChannelRegister;
	volatile NvU32 *pRunlistPRIBaseRegister;
	NvU32 smcEngineId;
	NvU32 smcEngineVeIdOffset;
};

typedef struct UvmGpuChannelInstanceInfo_tag UvmGpuChannelInstanceInfo;

struct UvmGpuChannelResourceBindParams_tag {
	NvU32 resourceId;
	NvU64 resourceVa;
};

typedef struct UvmGpuChannelResourceBindParams_tag UvmGpuChannelResourceBindParams;

struct UvmGpuClientInfo_tag {
	NvHandle hClient;
	NvHandle hSmcPartRef;
};

typedef struct UvmGpuClientInfo_tag UvmGpuClientInfo;

struct UvmGpuConfComputeCaps_tag {
	NvBool bConfComputingEnabled;
	NvBool bKeyRotationEnabled;
};

typedef struct UvmGpuConfComputeCaps_tag UvmGpuConfComputeCaps;

struct UvmGpuCopyEnginesCaps_tag {
	UvmGpuCopyEngineCaps copyEngineCaps[64];
};

typedef struct UvmGpuCopyEnginesCaps_tag UvmGpuCopyEnginesCaps;

struct UvmGpuEccInfo_tag {
	unsigned int eccMask;
	unsigned int eccOffset;
	void *eccReadLocation;
	NvBool *eccErrorNotifier;
	NvBool bEccEnabled;
};

typedef struct UvmGpuEccInfo_tag UvmGpuEccInfo;

struct UvmGpuExternalPhysAddrInfo_tag {
	UvmRmGpuMappingType mappingType;
	NvU64 physAddrBufferSize;
	NvU64 mappingPageSize;
	NvU64 *physAddrBuffer;
	NvU64 numWrittenPhysAddrs;
	NvU64 numRemainingPhysAddrs;
};

typedef struct UvmGpuExternalPhysAddrInfo_tag UvmGpuExternalPhysAddrInfo;

struct UvmGpuFbInfo_tag {
	NvU64 maxAllocatableAddress;
	NvU32 heapSize;
	NvU32 reservedHeapSize;
	NvBool bZeroFb;
	NvU64 maxVidmemPageSize;
	NvBool bStaticBar1Enabled;
	NvU64 staticBar1StartOffset;
	NvU64 staticBar1Size;
	NvU32 heapStart;
};

typedef struct UvmGpuFbInfo_tag UvmGpuFbInfo;

struct UvmGpuInfo_tag {
	char name[64];
	NvProcessorUuid uuid;
	NvU32 gpuArch;
	NvU32 gpuImplementation;
	NvU32 hostClass;
	NvU32 ceClass;
	NvU32 computeClass;
	NvBool gpuInTcc;
	NvU32 subdeviceCount;
	NvU32 virtMode;
	NvBool isSimulated;
	NvU32 gpcCount;
	NvU32 maxGpcCount;
	NvU32 tpcCount;
	NvU32 maxTpcPerGpcCount;
	NvU32 accessCntrBufferCount;
	NvBool smcEnabled;
	NvU32 smcSwizzId;
	UvmGpuClientInfo smcUserClientInfo;
	UvmGpuConfComputeCaps gpuConfComputeCaps;
	NvU32 sysmemLink;
	NvU32 sysmemLinkRateMBps;
	NvU64 systemMemoryWindowStart;
	NvU64 systemMemoryWindowSize;
	NvBool connectedToSwitch;
	NvU64 nvswitchMemoryWindowStart;
	NvBool egmEnabled;
	NvU8 egmPeerId;
	NvU64 egmBaseAddr;
	NvU64 nvswitchEgmMemoryWindowStart;
	NvBool atsSupport;
};

typedef struct UvmGpuInfo_tag UvmGpuInfo;

struct UvmGpuNvlinkInfo_tag {
	unsigned int nvlinkMask;
	unsigned int nvlinkOffset;
	void *nvlinkReadLocation;
	NvBool *nvlinkErrorNotifier;
	NvBool bNvlinkRecoveryEnabled;
};

typedef struct UvmGpuNvlinkInfo_tag UvmGpuNvlinkInfo;

struct UvmGpuP2PCapsParams_tag {
	NvU32 peerIds[2];
	NvU32 egmPeerIds[2];
	NvU32 p2pLink;
	NvU32 optimalNvlinkWriteCEs[2];
	NvU32 totalLinkLineRateMBps;
};

typedef struct UvmGpuP2PCapsParams_tag UvmGpuP2PCapsParams;

struct UvmGpuPagingChannelAllocParams_tag {
	NvU32 engineIndex;
};

typedef struct UvmGpuPagingChannelAllocParams_tag UvmGpuPagingChannelAllocParams;

struct UvmGpuPagingChannelInfo_tag {
	NvNotification *shadowErrorNotifier;
};

typedef struct UvmGpuPagingChannelInfo_tag UvmGpuPagingChannelInfo;

struct UvmGpuPagingChannel_tag;

typedef struct UvmGpuPagingChannel_tag *UvmGpuPagingChannelHandle;

struct gpuDevice;

struct UvmGpuPagingChannel_tag {
	struct gpuDevice *device;
	NvNotification *errorNotifier;
	NvHandle channelHandle;
	NvHandle errorNotifierHandle;
	void *pushStreamSp;
	struct Device *pDevice;
};

struct UvmGpuTsgAllocParams_tag {
	NvU32 engineType;
	NvU32 engineIndex;
};

typedef struct UvmGpuTsgAllocParams_tag UvmGpuTsgAllocParams;

typedef NV_STATUS (*uvmEventSuspend_t)(void);

typedef NV_STATUS (*uvmEventResume_t)(void);

typedef NV_STATUS (*uvmEventStartDevice_t)(const NvProcessorUuid *);

typedef NV_STATUS (*uvmEventStopDevice_t)(const NvProcessorUuid *);

typedef NV_STATUS (*uvmEventIsrTopHalf_t)(const NvProcessorUuid *);

typedef NV_STATUS (*uvmEventDrainP2P_t)(const NvProcessorUuid *);

typedef NV_STATUS (*uvmEventResumeP2P_t)(const NvProcessorUuid *);

struct UvmOpsUvmEvents {
	uvmEventSuspend_t suspend;
	uvmEventResume_t resume;
	uvmEventStartDevice_t startDevice;
	uvmEventStopDevice_t stopDevice;
	uvmEventIsrTopHalf_t isrTopHalf;
	uvmEventDrainP2P_t drainP2P;
	uvmEventResumeP2P_t resumeP2P;
};

struct UvmPlatformInfo_tag {
	NvBool atsSupported;
	NvBool confComputingEnabled;
};

typedef struct UvmPlatformInfo_tag UvmPlatformInfo;

struct UvmPmaAllocationOptions_tag {
	NvU32 flags;
	NvU32 minimumSpeed;
	NvU64 physBegin;
	NvU64 physEnd;
	NvU32 regionId;
	NvU64 alignment;
	NvLength numPagesAllocated;
	NvU32 resultFlags;
};

typedef struct UvmPmaAllocationOptions_tag UvmPmaAllocationOptions;

struct __va_list_tag {
	long: 64;
	long: 64;
	long: 64;
};

struct address_space {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct basic_start_stop_args {
	int value_to_write;
	int *where_to_write;
};

typedef struct basic_start_stop_args basic_start_stop_args_t;

struct bpf_func_proto {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct bpf_insn_access_aux {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct bpf_link {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct bpf_prog {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct bpf_struct_ops_common_value {
	long: 64;
};

struct uvm_gpu_ext {
	int (*uvm_bpf_test_trigger_kfunc)(const char *, int);
	int (*uvm_prefetch_before_compute)(uvm_page_index_t, uvm_perf_prefetch_bitmap_tree_t *, uvm_va_block_region_t *, uvm_va_block_region_t *);
	int (*uvm_prefetch_on_tree_iter)(uvm_page_index_t, uvm_perf_prefetch_bitmap_tree_t *, uvm_va_block_region_t *, uvm_va_block_region_t *, unsigned int, unsigned int);
};

struct bpf_struct_ops_uvm_gpu_ext {
	struct bpf_struct_ops_common_value common;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	struct uvm_gpu_ext data;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct btf {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct btf_member {
	long: 64;
	int: 32;
};

struct btf_type {
	long: 64;
	int: 32;
};

struct file {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct identity_mapping_pte_maker_data_struct {
	NvU64 phys_offset;
	uvm_aperture_t aperture;
};

typedef struct identity_mapping_pte_maker_data_struct identity_mapping_pte_maker_data_t;

struct inode {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct iommu_sva {
	long: 64;
	long: 64;
	long: 64;
};

struct kmem_cache {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct mem_cgroup {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct mm_struct {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct mmu_notifier_range {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct modversion_info {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct multithread_args {
	nv_kthread_q_t *test_q;
	atomic_t *test_wide_accumulator;
	atomic_t per_thread_accumulator;
};

typedef struct multithread_args multithread_args_t;

struct page {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct pci_dev {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct poll_table_struct {
	long: 64;
	long: 64;
};

typedef struct poll_table_struct poll_table;

struct proc_dir_entry {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct proc_ops {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

typedef struct proc_ops nv_proc_ops_t;

struct region {
	unsigned char read_faults: 4;
	unsigned char write_faults: 4;
	unsigned char atomic_faults: 4;
	unsigned char upgrades: 4;
};

struct resched_args {
	nv_kthread_q_t test_q;
	nv_kthread_q_item_t q_item;
	atomic_t accumulator;
	atomic_t stop_rescheduling_callbacks;
	int test_failure;
};

typedef struct resched_args resched_args_t;

struct rtt_state_struct {
	uvm_range_tree_t tree;
	uvm_test_rng_t rng;
	uvm_range_tree_node_t **nodes;
	size_t count;
	size_t max;
	NvU32 shrink_probability;
	NvU32 add_chance;
	NvU32 split_chance;
	struct {
		NvU64 size_sum;
		NvU64 total_adds;
		NvU64 failed_adds;
		NvU64 max_attempts_add;
		NvU64 total_removes;
		NvU64 total_shrinks;
		NvU64 failed_shrinks;
		NvU64 total_splits;
		NvU64 failed_splits;
		NvU64 max_attempts_split;
		NvU64 total_merges;
		NvU64 failed_merges;
		NvU64 max_attempts_merge;
	} stats;
};

typedef struct rtt_state_struct rtt_state_t;

struct same_q_item_args {
	atomic_t test_accumulator;
};

typedef struct same_q_item_args same_q_item_args_t;

struct seq_file {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct task_struct {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct test_range32_struct {
	NvU32 lo;
	NvU32 hi;
};

typedef struct test_range32_struct test_range32_t;

struct test_range64_struct {
	NvU64 lo;
	NvU64 hi;
};

typedef struct test_range64_struct test_range64_t;

struct test_sem_mem_t {
	void *cpu_va;
	NvU64 gpu_va;
	union {
		uvm_mem_t *uvm_mem;
		uvm_rm_mem_t *rm_mem;
	};
};

typedef struct test_sem_mem_t test_sem_mem;

struct uvm_access_counter_buffer_entry_struct {
	NvU64 address;
	uvm_gpu_phys_address_t instance_ptr;
	uvm_mmu_engine_type_t mmu_engine_type;
	NvU32 mmu_engine_id;
	NvU32 ve_id;
	uvm_va_space_t *va_space;
	uvm_gpu_t *gpu;
	NvU32 counter_value;
	NvU32 sub_granularity;
	NvU32 bank;
	NvU32 tag;
};

struct uvm_access_counter_service_batch_context_struct {
	uvm_access_counter_buffer_entry_t *notification_cache;
	NvU32 num_cached_notifications;
	uvm_access_counter_buffer_entry_t **notifications;
	NvU32 num_notifications;
	bool is_single_instance_ptr;
	uvm_page_mask_t accessed_pages;
	uvm_service_block_context_t block_service_context;
	uvm_ats_fault_context_t ats_context;
	NvU32 batch_id;
};

typedef struct uvm_access_counter_service_batch_context_struct uvm_access_counter_service_batch_context_t;

struct uvm_access_counter_buffer_struct {
	uvm_parent_gpu_t *parent_gpu;
	UvmGpuAccessCntrInfo rm_info;
	NvU32 index;
	NvU32 max_notifications;
	NvU32 max_batch_size;
	NvU32 cached_get;
	NvU32 cached_put;
	struct {
		struct {
			UVM_ACCESS_COUNTER_GRANULARITY granularity;
		} rm;
		NvU64 translation_size;
		NvU64 sub_granularity_region_size;
		NvU64 sub_granularity_regions_per_translation;
		NvU32 threshold;
	} current_config;
	struct {
		atomic64_t num_pages_out;
		atomic64_t num_pages_in;
	} stats;
	NvU32 notifications_ignored_count;
	uvm_access_counter_service_batch_context_t batch_service_context;
	struct {
		uvm_va_space_t *reconfiguration_owner;
		bool one_iteration_per_batch;
		NvU32 sleep_per_iteration_us;
	} test;
};

struct uvm_pushbuffer_struct;

typedef struct uvm_pushbuffer_struct uvm_pushbuffer_t;

struct uvm_channel_manager_struct {
	uvm_gpu_t *gpu;
	uvm_pushbuffer_t *pushbuffer;
	uvm_channel_pool_t *channel_pools;
	unsigned int num_channel_pools;
	long unsigned int ce_mask[1];
	struct {
		uvm_channel_pool_t *default_for_type[8];
		uvm_channel_pool_t *gpu_to_gpu[256];
	} pool_to_use;
	struct {
		struct proc_dir_entry *channels_dir;
		struct proc_dir_entry *pending_pushes;
	} procfs;
	struct {
		NvU32 num_gpfifo_entries;
		UVM_BUFFER_LOCATION gpfifo_loc;
		UVM_BUFFER_LOCATION gpput_loc;
		UVM_BUFFER_LOCATION pushbuffer_loc;
	} conf;
	struct {
		bool wlc_ready;
		bool key_rotation_enabled;
	} conf_computing;
};

struct uvm_gpu_tracking_semaphore_struct {
	uvm_gpu_semaphore_t semaphore;
	atomic64_t completed_value;
	union {
		uvm_spinlock_t s_lock;
		uvm_mutex_t m_lock;
	};
	NvU64 queued_value;
};

typedef struct uvm_gpu_tracking_semaphore_struct uvm_gpu_tracking_semaphore_t;

struct uvmGpuChannel_tag;

typedef struct uvmGpuChannel_tag *uvmGpuChannelHandle;

struct uvm_gpfifo_entry_struct;

typedef struct uvm_gpfifo_entry_struct uvm_gpfifo_entry_t;

struct uvm_push_info_struct;

typedef struct uvm_push_info_struct uvm_push_info_t;

struct uvm_push_acquire_info_struct;

typedef struct uvm_push_acquire_info_struct uvm_push_acquire_info_t;

struct uvm_push_crypto_bundle_struct;

typedef struct uvm_push_crypto_bundle_struct uvm_push_crypto_bundle_t;

struct uvm_channel_struct {
	uvm_channel_pool_t *pool;
	char name[64];
	uvm_gpfifo_entry_t *gpfifo_entries;
	NvU32 num_gpfifo_entries;
	NvU32 cpu_put;
	NvU32 gpu_get;
	NvU32 current_gpfifo_count;
	uvm_push_info_t *push_infos;
	uvm_push_acquire_info_t *push_acquire_infos;
	struct list_head available_push_infos;
	uvm_gpu_tracking_semaphore_t tracking_sem;
	struct {
		uvm_mutex_t push_lock;
		UvmCslContext ctx;
		bool is_ctx_initialized;
		long: 0;
		uvm_mutex_t ctx_lock;
	} csl;
	struct {
		volatile NvU32 gpu_put;
		void *static_pb_protected_sysmem;
		uvm_push_crypto_bundle_t *push_crypto_bundles;
	} conf_computing;
	union {
		struct {
			uvmGpuChannelHandle handle;
			UvmGpuChannelInfo channel_info;
		};
		struct {
			UvmGpuPagingChannelHandle handle;
			UvmGpuPagingChannelInfo channel_info;
		} proxy;
	};
	struct {
		struct proc_dir_entry *dir;
		struct proc_dir_entry *info;
		struct proc_dir_entry *pushes;
	} procfs;
	struct {
		struct list_head channel_list_node;
		NvU32 pending_event_count;
		long: 0;
	} tools;
	bool suspended_p2p;
};

struct uvmGpuSession_tag;

typedef struct uvmGpuSession_tag *uvmGpuSessionHandle;

struct uvm_global_struct {
	uvm_processor_mask_t retained_gpus;
	uvm_parent_gpu_t *parent_gpus[32];
	uvmGpuSessionHandle rm_session_handle;
	uvm_parent_gpu_peer_t parent_gpu_peers[496];
	uvm_gpu_peer_copy_mode_t peer_copy_mode;
	atomic_t fatal_error;
	bool disable_fatal_error_assert;
	long: 0;
	uvm_mutex_t global_lock;
	struct {
		uvm_rw_semaphore_t lock;
		bool is_suspended;
		long: 0;
	} pm;
	uvm_spinlock_irqsave_t gpu_table_lock;
	unsigned int num_simulated_devices;
	nv_kthread_q_t global_q;
	nv_kthread_q_t deferred_release_q;
	struct {
		bool supported;
		bool enabled;
	} ats;
	long: 0;
	struct {
		uvm_mutex_t lock;
		struct list_head list;
	} va_spaces;
	struct {
		NvU64 *ptr;
		struct page *page;
	} unload_state;
	bool conf_computing_enabled;
	long: 0;
	struct {
		uvm_mutex_t lock;
		struct list_head list;
	} devmem_ranges;
};

typedef struct uvm_global_struct uvm_global_t;

struct uvm_gpfifo_entry_struct {
	uvm_gpfifo_entry_type_t type;
	NvU64 tracking_semaphore_value;
	union {
		struct {
			NvU32 pushbuffer_offset;
			NvU32 pushbuffer_size;
		};
		NvU64 control_value;
	};
	struct list_head pending_list_node;
	uvm_push_info_t *push_info;
};

struct uvm_pmm_gpu_chunk_suballoc_struct;

typedef struct uvm_pmm_gpu_chunk_suballoc_struct uvm_pmm_gpu_chunk_suballoc_t;

struct uvm_gpu_chunk_struct {
	NvU64 address;
	struct {
		uvm_pmm_gpu_memory_type_t type: 2;
		bool in_eviction: 1;
		bool inject_split_error: 1;
		bool is_zero: 1;
		bool is_referenced: 1;
		uvm_pmm_gpu_chunk_state_t state: 3;
		size_t log2_size: 5;
		short: 2;
		uvm_page_index_t va_block_page_index: 10;
		int: 6;
		NvU32 gpu_index: 9;
	};
	struct list_head list;
	uvm_va_block_t *va_block;
	uvm_gpu_chunk_t *parent;
	uvm_pmm_gpu_chunk_suballoc_t *suballoc;
};

struct uvm_gpu_root_chunk_struct {
	uvm_gpu_chunk_t chunk;
	uvm_tracker_t tracker;
};

typedef struct uvm_gpu_root_chunk_struct uvm_gpu_root_chunk_t;

struct uvm_gpu_semaphore_pool_struct;

typedef struct uvm_gpu_semaphore_pool_struct uvm_gpu_semaphore_pool_t;

struct uvm_gpu_semaphore_pool_page_struct {
	uvm_rm_mem_t *memory;
	struct {
		uvm_rm_mem_t *encrypted_payload_memory;
	} conf_computing;
	uvm_gpu_semaphore_pool_t *pool;
	struct list_head all_pages_node;
	long unsigned int free_semaphores[16];
};

struct uvm_gpu_semaphore_pool_struct {
	uvm_gpu_t *gpu;
	struct list_head pages;
	uvm_aperture_t aperture;
	NvU32 free_semaphores_count;
	uvm_mutex_t mutex;
};

struct uvmGpuAddressSpace_tag;

typedef struct uvmGpuAddressSpace_tag *uvmGpuAddressSpaceHandle;

struct uvm_page_tree_struct {
	uvm_mutex_t lock;
	uvm_gpu_t *gpu;
	uvm_page_directory_t *root;
	uvm_mmu_mode_hal_t *hal;
	uvm_page_tree_type_t type;
	NvU64 big_page_size;
	uvm_gpu_va_space_t *gpu_va_space;
	uvm_aperture_t location;
	bool location_sys_fallback;
	uvm_gpu_phys_address_t pdb_rm_dma_address;
	struct {
		uvm_mmu_page_table_alloc_t ptes_invalid_4k;
		uvm_page_directory_t *pde0;
	} map_remap;
	uvm_page_table_range_t no_ats_ranges[2];
	uvm_tracker_t tracker;
};

struct uvm_pmm_gpu_struct {
	uvm_chunk_sizes_mask_t chunk_sizes[2];
	void *pma;
	const UvmPmaStatistics *pma_stats;
	struct {
		size_t count;
		uvm_gpu_root_chunk_t *array;
		uvm_bit_locks_t bitlocks;
		struct list_head va_block_unused;
		struct list_head va_block_used;
		struct list_head va_block_lazy_free;
		nv_kthread_q_item_t va_block_lazy_free_q_item;
	} root_chunks;
	uvm_rw_semaphore_t pma_lock;
	uvm_mutex_t lock;
	uvm_spinlock_t list_lock;
	long: 0;
	struct list_head free_list[24];
	NvU32 inject_pma_evict_error_after_num_chunks;
	long unsigned int chunk_split_cache_initialized[1];
	bool initialized;
	bool pma_address_cache_initialized;
};

struct uvm_pmm_sysmem_mappings_struct {
	uvm_gpu_t *gpu;
	struct xarray reverse_map_tree;
	uvm_mutex_t reverse_map_lock;
};

typedef struct uvm_pmm_sysmem_mappings_struct uvm_pmm_sysmem_mappings_t;

struct uvmGpuDevice_tag;

typedef struct uvmGpuDevice_tag *uvmGpuDeviceHandle;

struct uvm_gpu_struct {
	uvm_parent_gpu_t *parent;
	NvProcessorUuid uuid;
	char name[90];
	atomic64_t retained_count;
	uvm_gpu_id_t id;
	NvU64 magic;
	struct {
		NvU64 size;
		NvU64 phys_start;
		NvU64 max_allocatable_address;
		NvU64 max_vidmem_page_size;
		struct {
			bool enabled;
			int node_id;
		} numa;
		NvU64 static_bar1_start;
		NvU64 static_bar1_size;
	} mem_info;
	struct {
		NvU32 internal_size;
	} big_page;
	struct {
		volatile NvU32 *time0_register;
		volatile NvU32 *time1_register;
	} time;
	uvm_gpu_identity_mapping_t peer_mappings[256];
	struct {
		uvm_processor_mask_t peer_gpu_mask;
		uvm_spinlock_t peer_gpu_lock;
	} peer_info;
	NvU32 max_subcontexts;
	uvmGpuAddressSpaceHandle rm_address_space;
	uvm_page_tree_t address_space_tree;
	bool rm_address_space_moved_to_page_tree;
	uvm_gpu_semaphore_pool_t *semaphore_pool;
	uvm_gpu_semaphore_pool_t *secure_semaphore_pool;
	uvm_channel_manager_t *channel_manager;
	uvm_pmm_gpu_t pmm;
	union {
		uvm_gpu_identity_mapping_t static_flat_mapping;
		struct {
			uvm_gpu_root_chunk_mapping_t *array;
			size_t count;
			uvm_bit_locks_t bitlocks;
		} root_chunk_mappings;
	};
	struct {
		NvU64 mapping_size;
		uvm_gpu_identity_mapping_t *array;
		size_t count;
		uvm_bit_locks_t bitlocks;
	} sysmem_mappings;
	uvm_pmm_sysmem_mappings_t pmm_reverse_sysmem_mappings;
	struct {
		uvm_conf_computing_dma_buffer_pool_t dma_buffer_pool;
		uvm_mem_t *iv_mem;
		uvm_rm_mem_t *iv_rm_mem;
	} conf_computing;
	struct {
		bool enabled;
		volatile NvU32 *hw_interrupt_tree_location;
		NvU32 mask;
		NvBool *error_notifier;
	} ecc;
	struct {
		bool enabled;
		atomic_t injected_error;
		volatile NvU32 *hw_interrupt_tree_location;
		NvU32 mask;
		NvBool *error_notifier;
	} nvlink_status;
	struct {
		NvU32 swizz_id;
		uvmGpuDeviceHandle rm_device;
	} smc;
	struct {
		struct proc_dir_entry *dir;
		struct proc_dir_entry *dir_symlink;
		struct proc_dir_entry *gpu_instance_uuid_symlink;
		struct proc_dir_entry *info_file;
	} procfs;
	uvm_perf_module_data_desc_t perf_modules_data[3];
	bool uvm_test_force_upper_pushbuffer_segment;
	bool device_p2p_initialised;
	long: 0;
	uvm_mutex_t device_p2p_lock;
};

struct uvm_gpu_va_space_struct {
	uvm_va_space_t *va_space;
	uvm_gpu_t *gpu;
	uvm_gpu_va_space_state_t state;
	uvmGpuAddressSpaceHandle duped_gpu_va_space;
	bool did_set_page_directory;
	uvm_page_tree_t page_tables;
	struct list_head registered_channels;
	struct list_head channel_va_ranges;
	atomic_t disallow_new_channels;
	long: 0;
	uvm_deferred_free_object_t deferred_free;
	nv_kref_t kref;
	uvm_ats_gpu_va_space_t ats;
};

struct uvm_mem_pte_maker_data_struct {
	uvm_mem_t *mem;
	const uvm_mem_gpu_mapping_attrs_t *attrs;
};

typedef struct uvm_mem_pte_maker_data_struct uvm_mem_pte_maker_data_t;

struct uvm_mem_struct {
	uvm_gpu_t *backing_gpu;
	uvm_gpu_t *dma_owner;
	union {
		struct {
			uvm_gpu_chunk_t **chunks;
		} vidmem;
		struct {
			uvm_processor_mask_t mapped_on_phys;
			struct page **pages;
			void **va;
			NvU64 *dma_addrs[256];
		} sysmem;
	};
	size_t chunks_count;
	NvU64 chunk_size;
	NvU64 size;
	uvm_mem_user_mapping_t *user;
	struct {
		uvm_processor_mask_t mapped_on;
		uvm_page_table_range_vec_t *range_vecs[256];
		uvm_range_allocation_t range_alloc;
		void *cpu_addr;
	} kernel;
};

struct uvm_mmu_mode_hal_struct {
	NvU64 (*make_pte)(uvm_aperture_t, NvU64, uvm_prot_t, NvU64);
	NvU64 (*make_sked_reflected_pte)(void);
	NvU64 (*make_sparse_pte)(void);
	NvU64 (*unmapped_pte)(NvU64);
	NvU64 (*poisoned_pte)(void);
	void (*make_pde)(void *, uvm_mmu_page_table_alloc_t **, uvm_page_directory_t *, NvU32);
	NvLength (*entry_size)(NvU32);
	NvU32 (*entries_per_index)(NvU32);
	NvLength (*entry_offset)(NvU32, NvU64);
	NvU32 (*index_bits)(NvU32, NvU64);
	NvU32 (*num_va_bits)(void);
	NvLength (*allocation_size)(NvU32, NvU64);
	NvU32 (*page_table_depth)(NvU64);
	NvU64 (*page_sizes)(void);
};

typedef struct uvm_non_replayable_fault_buffer_struct uvm_non_replayable_fault_buffer_t;

struct uvm_page_directory_struct {
	uvm_page_directory_t *host_parent;
	NvU32 index_in_parent;
	uvm_mmu_page_table_alloc_t phys_alloc;
	NvU32 ref_count;
	NvU32 depth;
	uvm_page_directory_t *entries[0];
};

struct uvm_parent_gpu_struct {
	nv_kref_t gpu_kref;
	NvU32 num_retained_gpus;
	uvm_gpu_t *gpus[8];
	long unsigned int valid_gpus[1];
	NvProcessorUuid uuid;
	char name[115];
	UvmGpuInfo rm_info;
	uvm_parent_gpu_id_t id;
	struct pci_dev *pci_dev;
	int closest_cpu_numa_node;
	uvmGpuDeviceHandle rm_device;
	NvU64 max_allocatable_address;
	uvm_pmm_gpu_devmem_t *devmem;
	NvU64 dma_addressable_start;
	NvU64 dma_addressable_limit;
	atomic64_t mapped_cpu_pages_size;
	uvm_host_hal_t *host_hal;
	uvm_ce_hal_t *ce_hal;
	uvm_arch_hal_t *arch_hal;
	uvm_fault_buffer_hal_t *fault_buffer_hal;
	uvm_access_counter_buffer_hal_t *access_counter_buffer_hal;
	uvm_sec2_hal_t *sec2_hal;
	bool ce_phys_vidmem_write_supported;
	uvm_gpu_peer_copy_mode_t peer_copy_mode;
	UVM_VIRT_MODE virt_mode;
	bool prefetch_fault_supported;
	NvU32 num_hshub_tlb_invalidate_membars;
	bool gpfifo_in_vidmem_supported;
	bool replayable_faults_supported;
	bool non_replayable_faults_supported;
	bool access_counters_supported;
	bool access_counters_can_use_physical_addresses;
	bool fault_cancel_va_supported;
	bool scoped_atomics_supported;
	bool has_clear_faulted_channel_method;
	bool has_clear_faulted_channel_sw_method;
	bool sparse_mappings_supported;
	bool map_remap_larger_page_promotion;
	bool plc_supported;
	bool no_ats_range_required;
	struct {
		NvBool va_invalidate_supported;
		NvBool va_range_invalidate_supported;
		union {
			NvU32 max_pages;
			NvU32 max_ranges;
		};
	} tlb_batch;
	NvU64 max_channel_va;
	NvU64 max_host_va;
	bool can_map_sysmem_with_large_pages;
	bool is_integrated_gpu;
	struct {
		bool per_channel_key_rotation;
	} conf_computing;
	NvU64 rm_va_base;
	NvU64 rm_va_size;
	NvU64 peer_va_base;
	NvU64 peer_va_size;
	NvU64 uvm_mem_va_base;
	NvU64 uvm_mem_va_size;
	NvU64 flat_vidmem_va_base;
	NvU64 flat_sysmem_va_base;
	uvm_chunk_sizes_mask_t mmu_user_chunk_sizes;
	uvm_chunk_sizes_mask_t mmu_kernel_chunk_sizes;
	struct {
		struct proc_dir_entry *dir;
		struct proc_dir_entry *fault_stats_file;
		struct proc_dir_entry *access_counters_file;
		struct proc_dir_entry *dir_peers;
	} procfs;
	uvm_isr_info_t isr;
	uvm_fault_buffer_t fault_buffer;
	nv_kthread_q_t lazy_free_q;
	uvm_access_counter_buffer_t *access_counter_buffer;
	uvm_mutex_t access_counters_enablement_lock;
	uvm_tracker_t access_counters_clear_tracker;
	uvm_mutex_t access_counters_clear_tracker_lock;
	NvU32 utlb_per_gpc_count;
	long: 0;
	uvm_rb_tree_t tsg_table;
	uvm_rb_tree_t instance_ptr_table;
	uvm_spinlock_t instance_ptr_table_lock;
	struct {
		bool supported;
		bool enabled;
	} smc;
	struct {
		NvU64 num_replayable_faults;
		NvU64 num_non_replayable_faults;
		atomic64_t num_pages_out;
		atomic64_t num_pages_in;
	} stats;
	struct {
		bool is_nvswitch_connected;
		NvU64 fabric_memory_window_start;
		NvU64 egm_fabric_memory_window_start;
	} nvswitch_info;
	struct {
		uvm_gpu_link_type_t link;
		NvU32 link_rate_mbyte_per_s;
		NvU64 memory_window_start;
		NvU64 memory_window_end;
	} system_bus;
	struct {
		uvm_mutex_t smmu_lock;
		struct page *smmu_cmdq;
		void *smmu_cmdqv_base;
		long unsigned int smmu_prod;
		long unsigned int smmu_cons;
	} smmu_war;
	struct {
		bool enabled;
		NvU8 local_peer_id;
		NvU64 base_address;
	} egm;
	uvm_test_parent_gpu_inject_error_t test;
};

struct uvm_perf_module_struct {
	const char *name;
	uvm_perf_module_type_t type;
	uvm_perf_event_callback_t callbacks[9];
};

struct uvm_pmm_gpu_chunk_suballoc_struct {
	NvU32 allocated;
	NvU32 pinned_leaf_chunks;
	uvm_gpu_chunk_t *subchunks[0];
};

struct uvm_push_acquire_info_struct {
	struct {
		NvU64 value;
		uvm_gpu_id_t gpu_id;
		bool is_proxy;
		union {
			struct {
				NvU32 runlist_id;
				NvU32 channel_id;
			};
			struct {
				NvU32 pool_index;
			} proxy;
		};
	} values[16];
	NvU32 num_values;
};

struct uvm_push_crypto_bundle_struct {
	UvmCslIv iv;
	NvU32 key_version;
	NvU32 push_size;
	void *auth_tag;
};

struct uvm_push_info_struct {
	struct list_head available_list_node;
	const char *filename;
	int line;
	const char *function;
	char description[128];
	void (*on_complete)(void *);
	void *on_complete_data;
};

struct uvm_pushbuffer_struct {
	uvm_channel_manager_t *channel_manager;
	uvm_rm_mem_t *memory;
	uvm_rm_mem_t *memory_unprotected_sysmem;
	void *memory_protected_sysmem;
	uvm_pushbuffer_chunk_t chunks[16];
	long unsigned int available_chunks[1];
	long unsigned int idle_chunks[1];
	uvm_spinlock_t lock;
	long: 0;
	uvm_semaphore_t concurrent_pushes_sema;
	struct {
		struct proc_dir_entry *info_file;
	} procfs;
};

struct uvm_range_group_range_struct;

typedef struct uvm_range_group_range_struct uvm_range_group_range_t;

struct uvm_range_group_range_iter_struct {
	NvU64 start;
	NvU64 end;
	bool migratable;
	bool valid;
	bool is_current;
	uvm_range_group_range_t *node;
};

typedef struct uvm_range_group_range_iter_struct uvm_range_group_range_iter_t;

struct uvm_range_group_struct;

typedef struct uvm_range_group_struct uvm_range_group_t;

struct uvm_range_group_range_struct {
	uvm_range_tree_node_t node;
	struct list_head range_group_list_node;
	struct list_head range_group_migrated_list_node;
	uvm_range_group_t *range_group;
};

struct uvm_range_group_struct {
	NvU64 id;
	atomic_t allow_migration;
	long: 0;
	struct list_head ranges;
	struct list_head migrated_ranges;
	uvm_spinlock_t migrated_ranges_lock;
};

typedef struct uvm_replayable_fault_buffer_struct uvm_replayable_fault_buffer_t;

struct uvm_reverse_map_struct {
	uvm_va_block_t *va_block;
	uvm_va_block_region_t region;
	uvm_processor_id_t owner;
};

struct uvm_rm_mem_struct {
	uvm_rm_mem_type_t type;
	uvm_processor_mask_t mapped_on;
	NvU64 vas[257];
	NvU64 *proxy_vas;
	uvm_gpu_t *gpu_owner;
	NvLength size;
};

struct uvm_thread_context_lock_struct {
	NvU32 skip_lock_tracking;
	long unsigned int acquired_lock_orders[1];
	long unsigned int exclusive_acquired_lock_orders[1];
	long unsigned int out_of_order_acquired_lock_orders[1];
	void **acquired;
};

typedef struct uvm_thread_context_lock_struct uvm_thread_context_lock_t;

struct uvm_thread_context_struct {
	struct task_struct *task;
	NvU32 array_index;
	uvm_va_block_t *ignore_hmm_invalidate_va_block;
	long unsigned int hmm_invalidate_seqnum;
	struct rb_node node;
};

struct uvm_thread_context_wrapper_struct {
	uvm_thread_context_t context;
	uvm_thread_context_lock_t context_lock;
};

typedef struct uvm_thread_context_wrapper_struct uvm_thread_context_wrapper_t;

struct uvm_va_range_channel_struct;

typedef struct uvm_va_range_channel_struct uvm_va_range_channel_t;

struct uvm_user_channel_struct {
	uvm_gpu_va_space_t *gpu_va_space;
	uvm_gpu_t *gpu;
	uvm_rm_user_object_t user_rm_channel;
	UVM_GPU_CHANNEL_ENGINE_TYPE engine_type;
	bool in_subctx;
	NvU32 subctx_id;
	struct {
		bool valid;
		NvU32 id;
		NvU32 max_subctx_count;
	} tsg;
	NvU32 clear_faulted_token;
	uvm_tracker_t clear_faulted_tracker;
	volatile NvU32 *chram_channel_register;
	volatile NvU32 *runlist_pri_base_register;
	NvU32 smc_engine_id;
	NvU32 smc_engine_ve_id_offset;
	uvm_user_channel_subctx_info_t *subctx_info;
	size_t num_resources;
	UvmGpuChannelResourceInfo *resources;
	uvm_va_range_channel_t **channel_ranges;
	struct {
		uvm_gpu_phys_address_t addr;
		uvm_rb_tree_node_t node;
	} instance_ptr;
	void *rm_retained_channel;
	NvU32 hw_runlist_id;
	NvU32 hw_channel_id;
	struct list_head list_node;
	atomic_t is_bound;
	long: 0;
	uvm_deferred_free_object_t deferred_free;
	nv_kref_t kref;
	struct {
		bool scheduled;
		nv_kthread_q_item_t kill_channel_q_item;
		uvm_va_space_t *va_space;
		char fault_packet[32];
	} kill_channel;
};

struct uvm_va_block_retry_struct {
	uvm_tracker_t tracker;
	struct list_head free_chunks;
	struct list_head used_chunks;
};

struct uvm_va_block_struct {
	nv_kref_t kref;
	long: 0;
	uvm_mutex_t lock;
	uvm_va_range_managed_t *managed_range;
	NvU64 start;
	NvU64 end;
	uvm_processor_mask_t resident;
	uvm_processor_mask_t mapped;
	uvm_processor_mask_t evicted_gpus;
	struct {
		uvm_va_block_cpu_node_state_t **node_state;
		uvm_page_mask_t allocated;
		uvm_page_mask_t resident;
		uvm_page_mask_t pte_bits[2];
		NvU8 ever_mapped: 1;
		struct {
			NvU64 first_fault_stamp;
			pid_t first_pid;
			uvm_page_index_t page_index;
		} fault_authorized;
	} cpu;
	uvm_va_block_gpu_state_t *gpus[256];
	uvm_page_mask_t read_duplicated_pages;
	uvm_page_mask_t maybe_mapped_pages;
	uvm_tracker_t tracker;
	nv_kthread_q_item_t eviction_mappings_q_item;
	uvm_perf_module_data_desc_t perf_modules_data[3];
	struct {
		uvm_processor_id_t last_migration_proc_id;
		NvU16 fault_migrations_to_last_proc;
	} prefetch_info;
	struct {
		struct mmu_interval_notifier notifier;
		uvm_mutex_t migrate_lock;
		long unsigned int changed;
		uvm_va_space_t *va_space;
		uvm_range_tree_t va_policy_tree;
		uvm_range_tree_node_t node;
	} hmm;
};

struct uvm_va_block_test_struct {
	NvU32 page_table_allocation_retry_force_count;
	NvU32 user_pages_allocation_retry_force_count;
	NvU32 cpu_chunk_allocation_size_mask;
	NvU32 inject_cpu_chunk_allocation_error_count;
	int cpu_chunk_allocation_target_id;
	int cpu_chunk_allocation_actual_id;
	bool inject_eviction_error;
	bool inject_populate_error;
	bool inject_split_error;
};

typedef struct uvm_va_block_test_struct uvm_va_block_test_t;

struct uvm_va_block_wrapper_struct {
	uvm_va_block_t block;
	struct uvm_va_block_test_struct test;
};

typedef struct uvm_va_block_wrapper_struct uvm_va_block_wrapper_t;

struct uvm_va_policy_struct {
	uvm_read_duplication_policy_t read_duplication;
	uvm_processor_id_t preferred_location;
	int preferred_nid;
	uvm_processor_mask_t accessed_by;
};

typedef struct uvm_va_policy_struct uvm_va_policy_t;

struct uvm_va_policy_node_struct {
	uvm_range_tree_node_t node;
	uvm_va_policy_t policy;
};

typedef struct uvm_va_policy_node_struct uvm_va_policy_node_t;

struct uvm_va_range_struct {
	uvm_va_space_t *va_space;
	uvm_range_tree_node_t node;
	bool inject_split_error;
	bool inject_add_gpu_va_space_error;
	uvm_processor_mask_t uvm_lite_gpus;
	atomic_long_t *blocks;
	uvm_va_range_type_t type;
};

struct uvm_va_range_channel_struct {
	uvm_va_range_t va_range;
	uvm_gpu_va_space_t *gpu_va_space;
	uvm_page_table_range_vec_t pt_range_vec;
	uvm_aperture_t aperture;
	NvP64 rm_descriptor;
	NvU32 rm_id;
	NvU32 hw_runlist_id;
	struct {
		bool valid;
		NvU32 id;
	} tsg;
	NvU64 ref_count;
	struct list_head list_node;
};

struct uvm_va_range_device_p2p_struct {
	uvm_va_range_t va_range;
	uvm_gpu_t *gpu;
	NvU64 offset;
	uvm_device_p2p_mem_t *p2p_mem;
};

typedef struct uvm_va_range_device_p2p_struct uvm_va_range_device_p2p_t;

struct uvm_va_range_external_struct {
	uvm_va_range_t va_range;
	uvm_processor_mask_t mapped_gpus;
	uvm_ext_gpu_range_tree_t gpu_ranges[256];
	uvm_processor_mask_t *retained_mask;
};

typedef struct uvm_va_range_external_struct uvm_va_range_external_t;

struct uvm_va_range_managed_struct {
	uvm_va_range_t va_range;
	uvm_vma_wrapper_t *vma_wrapper;
	uvm_va_policy_t policy;
	uvm_perf_module_data_desc_t perf_modules_data[3];
};

struct uvm_va_range_semaphore_pool_struct {
	uvm_va_range_t va_range;
	uvm_mem_t *mem;
	uvm_gpu_t *owner;
	uvm_mem_gpu_mapping_attrs_t gpu_attrs[256];
	uvm_mem_gpu_mapping_attrs_t default_gpu_attrs;
	uvm_tracker_t tracker;
	uvm_mutex_t tracker_lock;
};

typedef struct uvm_va_range_semaphore_pool_struct uvm_va_range_semaphore_pool_t;

struct uvm_va_range_sked_reflected_struct {
	uvm_va_range_t va_range;
	uvm_gpu_va_space_t *gpu_va_space;
	uvm_page_table_range_vec_t pt_range_vec;
};

typedef struct uvm_va_range_sked_reflected_struct uvm_va_range_sked_reflected_t;

struct uvm_va_space_mm_struct {
	struct mm_struct *mm;
	uvm_spinlock_t lock;
	uvm_va_space_mm_state_t state;
	NvU32 retained_count;
	long: 0;
	wait_queue_head_t last_retainer_wait_queue;
	uvm_processor_mask_t scratch_processor_mask;
};

typedef struct uvm_va_space_mm_struct uvm_va_space_mm_t;

struct uvm_va_space_struct {
	uvm_processor_mask_t registered_gpus;
	uvm_processor_mask_t faultable_processors;
	uvm_processor_mask_t non_faultable_processors;
	NvU32 num_non_faultable_gpu_va_spaces;
	NvU32 num_integrated_gpus;
	uvm_rw_semaphore_t lock;
	uvm_mutex_t serialize_writers_lock;
	uvm_mutex_t read_acquire_write_release_lock;
	uvm_range_tree_t va_range_tree;
	struct address_space *mapping;
	struct list_head list_node;
	atomic64_t range_group_id_counter;
	struct xarray range_groups;
	uvm_range_tree_t range_group_ranges;
	long unsigned int enabled_peers[510];
	long unsigned int enabled_peers_teardown[510];
	uvm_egm_numa_node_info_t egm_numa_nodes[1024];
	uvm_processor_mask_t can_access[257];
	uvm_processor_mask_t accessible_from[257];
	uvm_processor_mask_t can_copy_from[257];
	uvm_processor_mask_t has_fast_link[257];
	uvm_processor_mask_t has_native_atomics[257];
	uvm_processor_mask_t registered_gpu_va_spaces;
	uvm_processor_mask_t gpu_unregister_in_progress;
	uvm_processor_mask_t system_wide_atomics_enabled_processors;
	uvm_processor_mask_t registered_gpus_teardown;
	uvm_processor_mask_t *peers_to_release[257];
	uvm_processor_mask_t unmap_mask;
	uvm_processor_mask_t scratch_processor_mask;
	uvm_parent_processor_mask_t access_counters_enabled_processors;
	uvm_cpu_gpu_affinity_t gpu_cpu_numa_affinity[256];
	uvm_conf_computing_dma_buffer_t *gpu_unregister_dma_buffer[256];
	uvm_gpu_va_space_t *gpu_va_spaces[256];
	struct {
		atomic_t num_pending;
		long: 0;
		wait_queue_head_t wait_queue;
	} gpu_va_space_deferred_free;
	uvm_perf_va_space_events_t perf_events;
	uvm_perf_module_data_desc_t perf_modules_data[3];
	uvm_perf_module_t *perf_modules[3];
	struct {
		bool enabled;
		long: 0;
		uvm_rw_semaphore_t lock;
		struct list_head counters[10];
		struct list_head queues[64];
		struct list_head queues_v2[64];
		struct list_head node;
	} tools;
	atomic_t user_channels_stopped;
	bool disallow_new_registers;
	bool user_channel_stops_are_immediate;
	uvm_va_block_context_t *va_block_context;
	NvU64 initialization_flags;
	uvm_va_space_mm_t va_space_mm;
	union {
		uvm_ats_va_space_t ats;
		uvm_hmm_va_space_t hmm;
	};
	struct {
		uvm_processor_mask_t mask;
		uvm_mutex_t mask_mutex;
	} closest_processors;
	struct {
		bool page_prefetch_enabled;
		bool skip_migrate_vma;
		atomic_t migrate_vma_allocation_fail_nth;
		atomic_t va_block_allocation_fail_nth;
		uvm_thread_context_wrapper_t *dummy_thread_context_wrappers;
		size_t num_dummy_thread_context_wrappers;
		atomic64_t destroy_gpu_va_space_delay_us;
		atomic64_t split_invalidate_delay_us;
		bool force_cpu_to_cpu_copy_with_ce;
		bool allow_allocation_from_movable;
		uvm_test_parent_gpu_inject_error_t parent_gpu_error;
	} test;
	nv_kthread_q_item_t deferred_release_q_item;
};

struct vm_area_struct {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct vm_fault {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

struct work_struct {
	long: 64;
	long: 64;
	long: 64;
	long: 64;
};

typedef NV_STATUS (*chunk_walk_func_t)(uvm_pmm_gpu_t *, uvm_gpu_chunk_t *, void *);

typedef NV_STATUS (*entry_test_page_size_func)(uvm_gpu_t *, size_t);

typedef NV_STATUS (*uvmPmaEvictPagesCallback)(void *, NvU64, NvU64 *, NvU32, NvU64, NvU64, UVM_PMA_GPU_MEMORY_TYPE);

typedef NV_STATUS (*uvmPmaEvictRangeCallback)(void *, NvU64, NvU64, UVM_PMA_GPU_MEMORY_TYPE);

typedef NvU64 (*uvm_page_table_range_pte_maker_t)(uvm_page_table_range_vec_t *, NvU64, void *);

typedef bool (*uvm_va_policy_is_split_needed_t)(const uvm_va_policy_t *, void *);


/* BPF kfuncs */
#ifndef BPF_NO_KFUNC_PROTOTYPES
extern void bpf_uvm_set_va_block_region(uvm_va_block_region_t *region, uvm_page_index_t first, uvm_page_index_t outer) __weak __ksym;
extern int bpf_uvm_strstr(const char *str, u32 str__sz, const char *substr, u32 substr__sz) __weak __ksym;
#endif

#ifndef BPF_NO_PRESERVE_ACCESS_INDEX
#pragma clang attribute pop
#endif

#endif /* __UVM_TYPES_GEN_H__ */
