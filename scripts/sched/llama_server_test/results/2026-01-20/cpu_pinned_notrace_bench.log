INFO 01-20 16:09:10 [__init__.py:216] Automatically detected platform cuda.
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x78946dc1e480>, seed=0, num_prompts=100, dataset_name='sharegpt', no_stream=False, dataset_path='/home/yunwei37/workspace/gpu/schedcp/workloads/vllm/datasets/ShareGPT_V3_unfiltered_cleaned_split.json', no_oversample=False, custom_output_len=256, custom_skip_chat_template=False, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 0}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', endpoint_type=None, base_url='http://127.0.0.1:8013', host='127.0.0.1', port=8000, endpoint='/v1/completions', header=None, max_concurrency=1, model='Qwen/Qwen3-30B-A3B-FP8', tokenizer=None, use_beam_search=False, logprobs=None, request_rate=1.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics='ttft,tpot,itl', metric_percentiles='99', goodput=None, request_id_prefix='benchmark-serving', top_p=None, top_k=None, min_p=None, temperature=None, tokenizer_mode='auto', served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
 |          | 00:00 elapsed, ? remaining |          | 00:00 elapsed, 00:01 remaining |          | 00:00 elapsed, 17:34:57 remaining
Initial test run completed. Starting main benchmark run...
Traffic request rate: 1.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 1
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<02:35,  1.57s/it]  2%|▏         | 2/100 [00:05<04:28,  2.74s/it]  3%|▎         | 3/100 [00:05<02:56,  1.82s/it]  4%|▍         | 4/100 [00:06<02:14,  1.40s/it]  5%|▌         | 5/100 [00:06<01:38,  1.03s/it]  6%|▌         | 6/100 [00:09<02:29,  1.59s/it]  7%|▋         | 7/100 [00:09<01:43,  1.11s/it]  8%|▊         | 8/100 [00:10<01:16,  1.21it/s]  9%|▉         | 9/100 [00:12<02:16,  1.50s/it] 10%|█         | 10/100 [00:14<02:12,  1.48s/it] 11%|█         | 11/100 [00:15<01:53,  1.28s/it] 12%|█▏        | 12/100 [00:17<02:08,  1.46s/it] 13%|█▎        | 13/100 [00:17<01:36,  1.11s/it] 14%|█▍        | 14/100 [00:20<02:29,  1.73s/it] 15%|█▌        | 15/100 [00:20<01:46,  1.25s/it] 16%|█▌        | 16/100 [00:21<01:32,  1.10s/it] 17%|█▋        | 17/100 [00:22<01:31,  1.11s/it] 18%|█▊        | 18/100 [00:23<01:34,  1.16s/it] 20%|██        | 20/100 [00:27<02:00,  1.50s/it] 21%|██        | 21/100 [00:31<02:34,  1.96s/it] 22%|██▏       | 22/100 [00:31<02:11,  1.68s/it] 24%|██▍       | 24/100 [00:33<01:45,  1.39s/it] 26%|██▌       | 26/100 [00:37<01:47,  1.46s/it] 27%|██▋       | 27/100 [00:37<01:31,  1.25s/it] 28%|██▊       | 28/100 [00:39<01:39,  1.39s/it] 30%|███       | 30/100 [00:39<01:03,  1.11it/s] 31%|███       | 31/100 [00:39<00:52,  1.32it/s] 32%|███▏      | 32/100 [00:43<01:40,  1.47s/it] 34%|███▍      | 34/100 [00:45<01:20,  1.22s/it] 36%|███▌      | 36/100 [00:45<00:50,  1.26it/s] 37%|███▋      | 37/100 [00:46<00:48,  1.29it/s] 39%|███▉      | 39/100 [00:49<01:06,  1.10s/it] 40%|████      | 40/100 [00:50<01:09,  1.15s/it] 41%|████      | 41/100 [00:52<01:09,  1.18s/it] 43%|████▎     | 43/100 [00:55<01:14,  1.30s/it] 44%|████▍     | 44/100 [00:55<01:07,  1.20s/it] 45%|████▌     | 45/100 [00:56<00:56,  1.03s/it] 46%|████▌     | 46/100 [00:56<00:43,  1.24it/s] 47%|████▋     | 47/100 [00:57<00:44,  1.19it/s] 48%|████▊     | 48/100 [00:57<00:34,  1.50it/s] 49%|████▉     | 49/100 [00:58<00:36,  1.41it/s] 50%|█████     | 50/100 [00:58<00:27,  1.82it/s] 51%|█████     | 51/100 [00:59<00:29,  1.67it/s] 52%|█████▏    | 52/100 [00:59<00:25,  1.91it/s] 53%|█████▎    | 53/100 [01:04<01:25,  1.82s/it] 54%|█████▍    | 54/100 [01:07<01:37,  2.11s/it] 56%|█████▌    | 56/100 [01:07<00:54,  1.25s/it] 58%|█████▊    | 58/100 [01:09<00:47,  1.14s/it] 60%|██████    | 60/100 [01:10<00:36,  1.10it/s] 62%|██████▏   | 62/100 [01:12<00:31,  1.22it/s] 64%|██████▍   | 64/100 [01:12<00:23,  1.56it/s] 66%|██████▌   | 66/100 [01:12<00:15,  2.15it/s] 68%|██████▊   | 68/100 [01:13<00:13,  2.35it/s] 70%|███████   | 70/100 [01:13<00:09,  3.20it/s] 71%|███████   | 71/100 [01:18<00:30,  1.06s/it] 72%|███████▏  | 72/100 [01:18<00:27,  1.03it/s] 73%|███████▎  | 73/100 [01:21<00:37,  1.41s/it] 74%|███████▍  | 74/100 [01:25<00:53,  2.04s/it] 76%|███████▌  | 76/100 [01:27<00:39,  1.66s/it] 77%|███████▋  | 77/100 [01:28<00:30,  1.33s/it] 78%|███████▊  | 78/100 [01:29<00:27,  1.24s/it] 80%|████████  | 80/100 [01:30<00:21,  1.07s/it] 82%|████████▏ | 82/100 [01:31<00:13,  1.33it/s] 84%|████████▍ | 84/100 [01:31<00:08,  1.92it/s] 86%|████████▌ | 86/100 [01:32<00:07,  1.88it/s] 88%|████████▊ | 88/100 [01:34<00:07,  1.62it/s] 90%|█████████ | 90/100 [01:34<00:04,  2.09it/s] 92%|█████████▏| 92/100 [01:37<00:06,  1.20it/s] 93%|█████████▎| 93/100 [01:39<00:06,  1.05it/s] 94%|█████████▍| 94/100 [01:40<00:06,  1.13s/it] 95%|█████████▌| 95/100 [01:41<00:04,  1.08it/s] 96%|█████████▌| 96/100 [01:42<00:04,  1.10s/it] 97%|█████████▋| 97/100 [01:44<00:03,  1.19s/it] 98%|█████████▊| 98/100 [01:45<00:02,  1.32s/it] 99%|█████████▉| 99/100 [01:46<00:00,  1.01it/s]100%|██████████| 100/100 [01:46<00:00,  1.06s/it]
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     76        
Maximum request concurrency:             1         
Request rate configured (RPS):           1.00      
Benchmark duration (s):                  106.03    
Total input tokens:                      17175     
Total generated tokens:                  19257     
Request throughput (req/s):              0.72      
Output token throughput (tok/s):         181.62    
Peak output token throughput (tok/s):    331.00    
Peak concurrent requests:                4.00      
Total Token throughput (tok/s):          343.60    
---------------Time to First Token----------------
Mean TTFT (ms):                          87.09     
Median TTFT (ms):                        86.05     
P99 TTFT (ms):                           151.07    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          3.96      
Median TPOT (ms):                        3.55      
P99 TPOT (ms):                           6.50      
---------------Inter-token Latency----------------
Mean ITL (ms):                           3.65      
Median ITL (ms):                         3.05      
P99 ITL (ms):                            8.29      
==================================================
